<!doctype html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>datasc_notes.ctb</title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="res/styles4.css" type="text/css" />
</head>
<body>
<div class='page'><h1 class='title level-1'>OS with Python</h1><br/></div><div class='page'><h1 class='title level-2'>OS Basics</h1><br/><p></p><p></p><p></p><p><h2>Reading Text files in bulk</h2></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> files:<br />    <span style="color:#ff9d00;font-weight:700">if</span> i!= <span style="color:#3ad900;font-weight:400">&#39;.DS_Store&#39;</span>:<br />        fd=<span style="color:#ff9d00;font-weight:700">open</span>(<span style="color:#3ad900;font-weight:400">&#39;Files/&#39;</span>+i,<span style="color:#3ad900;font-weight:400">&#39;r&#39;</span>)<br />        <span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&#39;Files/&#39;</span>+i,fd.read())<br />        fd.close()</pre></div></p><p></p></div><div class='page'><h1 class='title level-3'>OS Basics</h1><br/><p><strong><h3>OS Basics  </h3></strong></p><p><strong>import os</strong> : used to import the os library</p><p><strong>os.getcwd</strong> : used to get the current working directory(cwd).</p><p><strong>os.path</strong>:the entry&#39;s full path name; equivalent to os.path.join(scandir_path, entry.name)</p><p><strong>os.chdir(“directory_name”)</strong> : To go inside a folder.</p><p><strong>os.chdir(“..”)</strong> : To go back to the previous directory.</p><p><strong>os.mkdir(“file_name”)</strong> : To create a directory in the cwd.</p><p><strong>os.mkdirs(“filename/filename1/filename2”)</strong>: Used to create directories within directories.</p><p><strong>os.remove(“File_Name”):</strong> can be used to remove a folder but if folder is empty if it contains anything it can’t be used.</p><p></p><p><strong>os.rmdir(“parent_name/sub_directory_name”):</strong></p><p></p><p>Example os.rmdir(“Test/Test1”) then os.rmdir(“Test”)</p><p></p><p><strong>os.rename(‘old_file_name’,’new_file_name’)</strong> : used to rename a file</p><p><strong>os.getsize(“folder_name”)</strong> : gives size of folder in kbs.</p><p> </p><p></p><p>To use CLI commands in jupyter : ! is added </p><p> </p><p>for ex.. <strong>!touchfile.txt</strong> <strong>!ls</strong></p><p></p><p><span style="color:#8ff0a4;">in python,</span></p><p><span style="color:#8ff0a4;"></span>help(object)<span style="color:#8ff0a4;"> give the complete documentation with all methods </span></p><p><span style="color:#8ff0a4;">--this gets too long and complicated</span></p><p><span style="color:#8ff0a4;">using </span>dir(object) <span style="color:#8ff0a4;">is better</span></p><p><span style="color:#8ff0a4;">--this gives list of all methods which can be used and the help(object can be used on it)</span></p><p><span style="color:#8ff0a4;"></span></p><p></p><p>For a better documentation <a href="https://data-flair.training/blogs/python-os-module/">https://data-flair.training/blogs/python-os-module/</a></p><p></p><p>													OS Methods(extras+other methods)</p><p></p><p><strong>os.symlink()</strong>:	Create a symbolic link</p><p><strong>os.uname()</strong> :	Gives current version info on Operating System</p><p>os.chmod(path,mode):Alters mode of path to passed numeric mode</p><p>os.getenv[]</p><p></p><p><strong><span style="text-decoration:underline;"></span></strong></p><p><strong><span style="text-decoration:underline;"></span></strong><strong><span style="text-decoration:underline;indent:4;">List of important os methods in python </span></strong></p><p></p><p>The following is derived from chatgpt most important os methods:</p><p></p><p><strong>os.listdir(path=&#39;.&#39;)</strong>					:Return a list of files and directories in the specified path.</p><p><strong>os.path.isdir(path)</strong>					:Check if the path is directory </p><p><strong>os.path.isfile(path)</strong>				:Check if path is a file</p><p><strong>os.path.join(path, *paths)</strong>		:Join one or more paths intelligently</p><p><strong>os.path.(abspath basename dirname </strong></p><p><strong>os.path.splitext(path)	</strong>		:Split extension from a path</p><p><strong>os.path.getsize(path)			</strong>:Get size of file in bytes</p><p></p><p></p></div><div class='page'><h1 class='title level-4'>OS Basics Extras</h1><br/><p></p><p></p><p><strong><h3>To see all the sub-directories contained in a directory</h3></strong></p><p><h3>Let’s say we have a folder Imgs and want to check all the sub-directories contained in the directory Imgs we can automate this by:</h3></p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> os.listdir(<span style="color:#3ad900;font-weight:400">&#39;Imgs&#39;</span>):<br />    <span style="color:#ff9d00;font-weight:700">if</span> i != <span style="color:#3ad900;font-weight:400">&#39;.DS_Store&#39;</span>:  <span style="color:#0088ff;font-weight:400">##System</span><br />        <span style="color:#ff9d00;font-weight:700">print</span>(i)</pre></div></p><p></p><p><strong><h3>To check If a path exists or not:</h3></strong></p><p><strong><h3>os.path.exists(“path”):</h3></strong><h3> </h3>This will return a bool result </p><p>To check if a folder exists:</p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">if</span> os.path.exists(<span style="color:#3ad900;font-weight:400">&quot;Imgs/G&quot;</span>):<br />	<span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;Folder Already Exists&quot;</span>)<br /><span style="color:#ff9d00;font-weight:700">else</span>:<br />	os.mkdir(<span style="color:#3ad900;font-weight:400">&#39;Imgs/G&#39;</span>)</pre></div><ol><li>Example 1 : Join Path components</li></ol></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> os<br /><br />base_path = <span style="color:#3ad900;font-weight:400">&quot;/path/to/base&quot;</span><br />file_name = <span style="color:#3ad900;font-weight:400">&quot;file.txt&quot;</span><br />full_path = os.path.join(base_path, file_name)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;Full Path:&quot;</span>, full_path)<br /></pre></div></p><p></p><p>2.Example 2 : List Files and Directories in a Directory</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> os<br />directory=<span style="color:#3ad900;font-weight:400">&quot;/path/to/directory&quot;</span><br />file_list=os.listdir(directory)<br /><span style="color:#ff9d00;font-weight:700">for</span> <span style="color:#ff9d00;font-weight:700">file</span> <span style="color:#ff9d00;font-weight:700">in</span> file_list:<br />	<span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#ff9d00;font-weight:700">file</span>)</pre></div></p></div><div class='page'><h1 class='title level-3'>Sub Directories</h1><br/><p><span style="indent:5;"> </span><strong><span style="text-decoration:underline;indent:5;">Creating Sub Directories in Bulk</span></strong></p><p></p><p><div class="codebox"><pre>n=<span style="color:#3ad900;font-weight:400">&#39;GFG&#39;</span><br />os.mkdir(n)<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1000</span>):<br />	name=n+<span style="color:#3ad900;font-weight:400">&#39;/&#39;</span>+n+<span style="color:#3ad900;font-weight:400">&quot;&quot;</span>+<span style="color:#ff9d00;font-weight:700">str</span>(i+<span style="color:#ff0044;font-weight:400">1</span>) <br />	os.mkdir(name)</pre></div></p><p></p><p><strong><span style="text-decoration:underline;indent:5;">Hierarchal Bulk Directory Creation:</span></strong></p><p><div class="codebox"><pre>master=<span style="color:#3ad900;font-weight:400">&#39;GFG&#39;</span><br />os.mkdir(master)<br />n=<span style="color:#ff0044;font-weight:400">5</span><br />m=<span style="color:#ff0044;font-weight:400">5</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(n):<br />	name=master+<span style="color:#3ad900;font-weight:400">&#39;/&#39;</span>+master+<span style="color:#3ad900;font-weight:400">&quot;&quot;</span>+<span style="color:#ff9d00;font-weight:700">str</span>(i+<span style="color:#ff0044;font-weight:400">1</span>)<br />	os.mkdir(name)<br />	<span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(m):<br />		name=master+<span style="color:#3ad900;font-weight:400">&#39;/&#39;</span>+master+<span style="color:#3ad900;font-weight:400">&quot;&quot;</span>+<span style="color:#ff9d00;font-weight:700">str</span>(i+<span style="color:#ff0044;font-weight:400">1</span>)+<span style="color:#3ad900;font-weight:400">&quot;/&quot;</span>+master+<span style="color:#3ad900;font-weight:400">&quot;&quot;</span>+<span style="color:#ff9d00;font-weight:700">str</span>(j+<span style="color:#ff0044;font-weight:400">1</span>)<br />		os.mkdir(name)<br /><span style="color:#ff9d00;font-weight:700">print</span>(n*m+n+<span style="color:#ff0044;font-weight:400">1</span>)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;The outer loop n will be used to create main 5 folders GFG 1 GFG 2 so on up-to GFG 5 then the inner m loop will be used to create 5 sub directories.</span><br /><span style="color:#3ad900;font-weight:400"><br />Hence Each directory will be having 5 sub directories<br /><br />Master directory i.e., GFG = 1<br /><br />Child directories = 5 {GFG1 GFG2 … GFG5}<br /><br />Number of inner directories = 25<br /><br />Hence 31 directories will be created for this code changing values of m and n will change the number of directories created.&#39;&#39;&#39;</span></pre></div></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Reading Text files in Bulk</h1><br/><p></p><p></p><p></p><p><h2>Reading Text files in bulk</h2></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> files:<br />    <span style="color:#ff9d00;font-weight:700">if</span> i!= <span style="color:#3ad900;font-weight:400">&#39;.DS_Store&#39;</span>:<br />        fd=<span style="color:#ff9d00;font-weight:700">open</span>(<span style="color:#3ad900;font-weight:400">&#39;Files/&#39;</span>+i,<span style="color:#3ad900;font-weight:400">&#39;r&#39;</span>)<br />        <span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&#39;Files/&#39;</span>+i,fd.read())<br />        fd.close()</pre></div></p><p></p><p>Files/1 in read mode then print it useing fd.read()</p><p>This will be done for all the files</p></div><div class='page'><h1 class='title level-1'>NumPy mastery</h1><br/><p></p><p>												<h2>Getting started with Numpy</h2>		</p><p><strong>Numpy</strong> is basically for array processing.</p><p></p><p><strong>List vs Array</strong> : 		</p><p> <table class="table"><tr><th>List </th><th>Array</th></tr><tr><td>heterogeneous elements/ undeclared</td><td>homogeneous </td></tr><tr><td>flexible to shrink and grow</td><td>require less memory</td></tr></table></p><p> </p><p><strong> </strong></p></div><div class='page'><h1 class='title level-2'>Getting Started with Numpy</h1><br/><p><strong>Converting list to an array : </strong></p><p> np.array()</p><p> <div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />l=[<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">5</span>]<br /><span style="color:#ff9d00;font-weight:700">print</span>(l)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#ff9d00;font-weight:700">type</span>(l))<br /><span style="color:#ff9d00;font-weight:700">print</span>()<br />arr=np.array(l)<br /><span style="color:#ff9d00;font-weight:700">print</span>(arr)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#ff9d00;font-weight:700">type</span>(arr))</pre></div></p><p> </p><p> <strong>numpy.ndarray.ndim(arr)</strong> returns number of dimensions of an array</p><p> </p><p><strong>np.array.</strong> </p><p>			<strong>shape</strong>	: Total number of rows and colums in tuple format</p><p>			<strong>size</strong>		: number of values present</p><p>			<strong>dtype</strong> 	: data type of values in array</p><p></p><p><div class="codebox"><pre>a=np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>])<br />b=np.array([[<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>],[<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>]])<br /><span style="color:#ff9d00;font-weight:700">print</span>(a.ndim)  <span style="color:#0088ff;font-weight:400">#1</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(b.ndim)  <span style="color:#0088ff;font-weight:400">#2</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(b.size)  <span style="color:#0088ff;font-weight:400">#8</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(a.shape) <span style="color:#0088ff;font-weight:400">#(1,4)</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(a.dtype) <span style="color:#0088ff;font-weight:400">#int32</span></pre></div></p><p></p><p><strong>numpy.zeros()</strong>: returns new array of shape and size with zeroes</p><p><strong>Syntax</strong>:</p><p></p><p><span style="color:#57e389;">numpy.zeros(shape,dtype=None,order=&#39;C)</span></p><p></p><p>Parameters:</p><p></p><p><strong>shape</strong>: integer or sequence of integers</p><p><strong>order</strong>: C_contiguous or F_contiguous</p><p>		  C-contiguous order in memory(last index varies fastest)</p><p>		 C order means that operating row-rise on the array will be slightly quicker</p><p>         FORTRAN-contiguous order in memory (first index varies the fastest).</p><p>         F order means that column-wise operations will be faster. </p><p><strong>dtype</strong>:[optional, float(byDeafult)] Data type of returned array.  </p><p></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Python Program illustrating</span><br /><span style="color:#0088ff;font-weight:400"># numpy.zeros method</span><br /> <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br /> <br />b = geek.zeros(<span style="color:#ff0044;font-weight:400">2</span>, dtype = <span style="color:#ff9d00;font-weight:700">int</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;Matrix b : \n&quot;</span>, b)<br /> <br />a = geek.zeros([<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>], dtype = <span style="color:#ff9d00;font-weight:700">int</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;\nMatrix a : \n&quot;</span>, a)<br /> <br />c = geek.zeros([<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">3</span>])<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;\nMatrix c : \n&quot;</span>, c)</pre></div></p><p></p><p>Output:</p><p></p><p><div class="codebox"><pre>Matrix b : <br /> [0 0]<br /><br />Matrix a : <br /> [[0 0]<br /> [0 0]]<br /><br />Matrix c : <br /> <span style="color:#000000;font-weight:400">[</span>[ 0.  0.  0.]<br /> [ 0.  0.  0.]<br /> [ 0.  0.  0.]<span style="color:#000000;font-weight:400">]</span></pre></div></p><p></p><p><h3>The </h3><strong>numpy.ones() </strong><h3>function returns a new array of given shape and type, with ones.</h3></p><p></p><p><strong>Syntax:</strong> numpy.ones(shape, dtype = None, order = &#39;C&#39;) </p><p></p><p>Parameters : Same as numpy.zeros</p></div><div class='page'><h1 class='title level-3'>w3schools practice notes</h1><br/><p><ul><li>ta Types in Numpy</p><p>• <code>i</code></li><li> integer</p><p>• <code>b</code></li><li> boolean</p><p>• <code>u</code></li><li> unsigned integer</p><p>• <code>f</code></li><li> float</p><p>• <code>c</code></li><li> complex float</p><p>• <code>m</code></li><li> timedelta</p><p>• <code>M</code></li><li> datetime</p><p>• <code>O</code></li><li> object</p><p>• <code>S</code></li><li> string</p><p>• <code>U</code></li><li> unicode string</p><p>• <code>V</code></li></ul> - fixed chunk of memory for other type ( void )</p><p></p><p><strong>astype(&#39;&#39;)</strong>: changes datatype</p><p></p><p><strong>Syntax</strong>:</p><p></p><p><div class="codebox"><pre>newarr=arr.astype(<span style="color:#3ad900;font-weight:400">&#39;datatype&#39;</span>)</pre></div></p><p></p><p></p><p><h1>NumPy Array Copy vs View</h1></p><p> </p><p>numpy.copy() makes shallow copy (changes in main array do not affect copy)</p><p></p><p>numpy.vew() makes deep copy (same changes take affect in view)</p><p></p><p><h2>Check if array Owns its Data</h2>:</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>])<br /><br />x = arr.copy()<br />y = arr.view()<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x.base) <span style="color:#0088ff;font-weight:400">#Output: None</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(y.base) <span style="color:#0088ff;font-weight:400">#Output: [1,2,3,4,5]</span></pre></div></p><p></p><p>,dtype=&#39;S&#39; to specify datatype string</p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Reshape and Random Number Generator</h1><br/><p><h2>Reshape and Random Number Generator</h2></p><p></p><p><strong>numpy.random.random()</strong> : random sampling fills in range [0.0,1.0]</p><p></p><p><em><strong><h3>Syntax :</h3></strong></em><em><h3> numpy.random.random(size=None)</h3></em></p><p><em><strong><h3>Parameters :</h3></strong></em><h3></h3></p><p><h3></h3><em><strong><h3>size :</h3></strong></em><em><h3> [int or tuple of ints, optional] Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned.</h3></em></p><p><em><strong><h3>Return :</h3></strong></em><em><h3> Array of random floats in the interval [0.0, 1.0). or a single such random float if size not provided.</h3></em></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># numpy.random.random() function</span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing numpy</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br />  <br /><span style="color:#0088ff;font-weight:400"># output array</span><br />out_arr = geek.random.random(<span style="color:#ff0044;font-weight:400">3</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;Output 1D Array filled with random floats : &quot;</span>, out_arr) </pre></div></p><p></p><p><h3>The </h3><strong>arange([start,] stop[, step,][, dtype]) : </strong><h3>Returns an array with evenly spaced elements as per the interval. The interval mentioned is half-opened i.e. [Start, Stop</h3></p><p></p><p><strong>Parameters : </strong></p><p><div class="codebox"><pre>start : [optional] start of interval range. By default start = 0<br />stop  : end of interval range<br />step  : [optional] step size of interval. By default step size = 1,  <br />For any output out, this is the distance between two adjacent values, out[i+1] - out[i]. <br />dtype : type of output array</pre></div></p><p></p><p><strong><h3>Return:</h3></strong><h3> </h3></p><p>Array of evenly spaced values.</p><p>Length of array being generated  = <strong>Ceil((Stop - Start) / Step)</strong> </p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python Programming illustrating</span><br /><span style="color:#0088ff;font-weight:400"># numpy.arange method</span><br /> <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br /> <br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;A\n&quot;</span>, geek.arange(<span style="color:#ff0044;font-weight:400">4</span>).reshape(<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>), <span style="color:#3ad900;font-weight:400">&quot;\n&quot;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;A\n&quot;</span>, geek.arange(<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">10</span>), <span style="color:#3ad900;font-weight:400">&quot;\n&quot;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;A\n&quot;</span>, geek.arange(<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">20</span>, <span style="color:#ff0044;font-weight:400">3</span>), <span style="color:#3ad900;font-weight:400">&quot;\n&quot;</span>)</pre></div></p><p></p><p><strong>Output</strong>:</p><p><div class="codebox"><pre><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;A<br /> [[0 1]<br /> [2 3]]<br /><br />A<br /> [4 5 6 7 8 9]<br /><br />A<br /> [ 4  7 10 13 16 19]&#39;&#39;&#39;</span></pre></div></p><p></p><p><h3>The </h3><strong>numpy.reshape</strong>() changes shape of an array without changing data</p><p></p><p><strong><h3>Syntax:</h3></strong></p><p>numpy.reshape(array, shape, order = &#39;C&#39;)</p><p></p><p><strong><h3>Parameters : </h3></strong></p><p><strong>array : </strong>[array_like]Input array</p><p><strong>shape : </strong>[int or tuples of int] </p><p><strong>order  : </strong>[C-contiguous, F-contiguous, A-contiguous; optional]         </p><p>         C-contiguous order in memory(last index varies the fastest)</p><p>         C order means that operating row-rise on the array will be slightly quicker</p><p>         FORTRAN-contiguous order in memory (first index varies the fastest).</p><p>         F order means that column-wise operations will be faster. </p><p>         ‘A’ means to read / write the elements in Fortran-like index order if,</p><p>         array is Fortran contiguous in memory, C-like order otherwise</p><p>         </p><p>        </p></div><div class='page'><h1 class='title level-3'>numpy.linspace()</h1><br/><p><h3>The </h3><strong>numpy.linspace()</strong><h3> function returns number spaces evenly w.r.t interval. Similar to </h3><a href="https://www.geeksforgeeks.org/numpy-arange-python/">numpy.arange() function</a><h3> but instead of step it uses sample number. </h3></p><p><strong>Syntax : </strong></p><p><div class="codebox"><pre>numpy.linspace<span style="color:#000000;font-weight:400">(</span>start,<br />               stop,<br />               num = 50,<br />               endpoint = True,<br />               retstep = False,<br />               dtype = None<span style="color:#000000;font-weight:400">)</span></pre></div></p><p>               </p><p><strong><h3>Parameters : </h3></strong></p><p>-&gt; <strong>start  : </strong>[optional] start of interval range. By default start = 0</p><p>-&gt; <strong>stop   : </strong>end of interval range</p><p>-&gt; <strong>restep : </strong>If True, return (samples, step). By default restep = False</p><p>-&gt; <strong>num    : </strong>[int, optional] No. of samples to generate</p><p>-&gt; <strong>dtype  : </strong>type of output array</p><p></p><p><strong><h3>Return : </h3></strong><h3></h3></p><p><h3> </h3></p><p>-&gt; <strong>ndarray</strong></p><p>-&gt; <strong>step : </strong>[float, optional], if restep = True</p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python Programming illustrating</span><br /><span style="color:#0088ff;font-weight:400"># numpy.linspace method</span><br /> <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br /> <br /><span style="color:#0088ff;font-weight:400"># restep set to True</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;B\n&quot;</span>, geek.linspace(<span style="color:#ff0044;font-weight:400">2.0</span>, <span style="color:#ff0044;font-weight:400">3.0</span>, num=<span style="color:#ff0044;font-weight:400">5</span>, retstep=<span style="color:#ff0044;font-weight:400">True</span>), <span style="color:#3ad900;font-weight:400">&quot;\n&quot;</span>)<br /> <br /><span style="color:#0088ff;font-weight:400"># To evaluate sin() in long range</span><br />x = geek.linspace(<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">10</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;A\n&quot;</span>, geek.sin(x))</pre></div></p><p></p><p><strong><h3>Output : </h3></strong></p><p>B</p><p> (array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)</p><p></p><p>A</p><p> [ 0.          0.22039774  0.42995636  0.6183698   0.77637192  0.8961922</p><p>  0.9719379   0.99988386  0.9786557   0.90929743]</p></div><div class='page'><h1 class='title level-3'>reshape example</h1><br/><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python Program illustrating</span><br /><span style="color:#0088ff;font-weight:400"># numpy.reshape() method</span><br /> <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br /> <br /><span style="color:#0088ff;font-weight:400"># array = geek.arrange(8)</span><br /><span style="color:#0088ff;font-weight:400"># The &#39;numpy&#39; module has no attribute &#39;arrange&#39;</span><br />array1 = geek.arange(<span style="color:#ff0044;font-weight:400">8</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;Original array : \n&quot;</span>, array1)<br /> <br /><span style="color:#0088ff;font-weight:400"># shape array with 2 rows and 4 columns</span><br />array2 = geek.arange(<span style="color:#ff0044;font-weight:400">8</span>).reshape(<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">4</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;\narray reshaped with 2 rows and 4 columns : \n&quot;</span>,<br />      array2)<br /> <br /><span style="color:#0088ff;font-weight:400"># shape array with 4 rows and 2 columns</span><br />array3 = geek.arange(<span style="color:#ff0044;font-weight:400">8</span>).reshape(<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">2</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;\narray reshaped with 4 rows and 2 columns : \n&quot;</span>,<br />      array3)<br /> <br /><span style="color:#0088ff;font-weight:400"># Constructs 3D array</span><br />array4 = geek.arange(<span style="color:#ff0044;font-weight:400">8</span>).reshape(<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;\nOriginal array reshaped to 3D : \n&quot;</span>,<br />      array4)</pre></div></p><p></p><p><strong><h3>Output : </h3></strong></p><p><div class="codebox"><pre><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Original array : <br /> [0 1 2 3 4 5 6 7]<br /><br />array reshaped with 2 rows and 4 columns : <br /> [[0 1 2 3]<br /> [4 5 6 7]]<br /><br />array reshaped with 4 rows and 2 columns : <br /> [[0 1]<br /> [2 3]<br /> [4 5]<br /> [6 7]]<br /></span><br /><span style="color:#3ad900;font-weight:400">Original array reshaped to 3D : <br /> [[[0 1]<br />  [2 3]]<br /> [[4 5]<br />  [6 7]]]<br />  <br /> <br /> [[0 1 2 3]<br /> [4 5 6 7]]&#39;&#39;&#39;</span></pre></div></p></div><div class='page'><h1 class='title level-3'>array examples</h1><br/><p></p><p><img src="images/32-1.png" alt="images/32-1.png" /></p><p></p><p></p><p>randn takes Normallized normal distribution</p><p></p><p>full() function takes shape and value argumetns</p><p></p><p><strong>array.dot()</strong>:</p><p>					 This function returns the dot prodcut of 2 arrays</p><p>					</p><p>					for 2-D it is matrix multiplication</p><p>					<strong></strong></p><p><strong>					for 1-D it is single product</strong></p><p>					</p><p><strong><h3>Transpose</h3></strong><h3>:</h3></p><p></p><p>arr.transpose()</p><p>arr.T</p><p></p><p>Reverse: </p><p>			 </p><p><strong>			numpy.flipud(arr)</strong></p><p>			</p><p>numpy.sort(array)[::-1]</p><p>reverses using reversal method ::-1</p><p></p></div><div class='page'><h1 class='title level-2'>Arithmetic Operations on Array</h1><br/><p><small>Arithmetic Operations on Array</small></p><p>NumPy achieves its fast implementation using <a href="https://www.geeksforgeeks.org/vectorization-in-python/">vectorization</a>. One of the important features of NumPy arrays is that a developer can perform the same mathematical operation on every element with a single command.</p><p>Let us understand arithmetic operations using NumPy.</p><p></p><p><strong>Addition</strong>:</p><p></p><p><div class="codebox"><pre>a=np.array()<br />b=np.array()<br /><span style="color:#ff9d00;font-weight:700">sum</span>=a+b<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#ff9d00;font-weight:700">sum</span>)<br /><br />sub_ans = a-b<br /><span style="color:#ff9d00;font-weight:700">print</span>(sub_ans)<br /><br />sub_ans = a-b<br /><span style="color:#ff9d00;font-weight:700">print</span>(sub_ans)</pre></div></p><p></p><p><strong>numpy.min(array) and max</strong></p><p></p><p><strong><h3>Example 3: </h3></strong><h3>Now, if we want to find the maximum or minimum from the rows or the columns then we have to add </h3><strong><h3>0</h3></strong><h3> or </h3><strong><h3>1</h3></strong><h3>. See how it works: </h3></p><p><h3>maximum_element = numpy.max(arr, 0)</h3></p><p><h3></h3></p><p><h3></h3><code><h3>[[11, 2, 3],</h3></code></p><p><code><h3>[4, 5, 16],</h3></code></p><p><code><h3>[7, 81, 22]]</h3></code><h3></h3></p><p><h3></h3></p><p><h3>maximum_element = numpy.max(arr, 1)If we use 0 it will give us a list containing the maximum or minimum values from each column. Here we will get a list like [11 81 22] which have all the maximum numbers each column. </h3></p><p><h3></h3></p><p><h3>If we use 1 instead of 0, will get a list like [11 16 81], which contain the maximum number from each row.</h3></p><p><h3></h3></p><p><h3></h3></p></div><div class='page'><h1 class='title level-2'>Array Sorting</h1><br/><p><small>Array Sorting</small></p><p>There are multiple ways in Numpy to sort an array, based on the requirement using <a href="https://www.geeksforgeeks.org/python-programming-language/">Python</a>. </p><p></p><p><strong><h2>Sort a Numpy Array using the sort()</h2></strong></p><p>Here we sort the given array based on the axis using the <a href="https://www.geeksforgeeks.org/python-list-sort-method/">sort() method</a> i.e. create a sorted copy of the given numpy array. </p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br /><span style="color:#0088ff;font-weight:400"># sort along the first axis</span><br />a = np.array([[<span style="color:#ff0044;font-weight:400">12</span>, <span style="color:#ff0044;font-weight:400">15</span>],<br />				[<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">1</span>]])<br />arr1 = np.sort(a, axis = <span style="color:#ff0044;font-weight:400">0</span>)       <br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;Along first axis : \n&quot;</span>, arr1)       <br /> <br /> <br /><span style="color:#0088ff;font-weight:400"># sort along the last axis</span><br />a = np.array([[<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">15</span>], [<span style="color:#ff0044;font-weight:400">12</span>, <span style="color:#ff0044;font-weight:400">1</span>]])<br />arr2 = np.sort(a, axis = -<span style="color:#ff0044;font-weight:400">1</span>)       <br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;\nAlong first axis : \n&quot;</span>, arr2)<br /> <br /> <br />a = np.array([[<span style="color:#ff0044;font-weight:400">12</span>, <span style="color:#ff0044;font-weight:400">15</span>], [<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">1</span>]])<br />arr1 = np.sort(a, axis = <span style="color:#ff0044;font-weight:700">None</span>)       <br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;\nAlong none axis : \n&quot;</span>, arr1)<br /><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output: <br /><br />Along first axis : <br /> [[10  1]<br /> [12 15]]<br /><br />Along first axis : <br /> [[10 15]<br /> [ 1 12]]<br /><br />Along none axis : <br /> [ 1 10 12 15]&#39;&#39;&#39;</span></pre></div></p><p></p><p><h3> quicksort, mergesort and heapsort.</h3></p><p></p><p><div class="codebox"><pre>arr = np.array([[<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">4</span>], [<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">6</span>],[<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">1</span>]])<br /><span style="color:#ff9d00;font-weight:700">print</span>(np.sort(arr , axis = <span style="color:#ff0044;font-weight:400">0</span>, kind = <span style="color:#3ad900;font-weight:400">&#39;mergesort&#39;</span>))<br /><span style="color:#ff9d00;font-weight:700">print</span>()<br /><span style="color:#ff9d00;font-weight:700">print</span>(np.sort(arr , axis = <span style="color:#ff0044;font-weight:400">1</span>, kind = <span style="color:#3ad900;font-weight:400">&#39;quicksort&#39;</span>))<br /><span style="color:#ff9d00;font-weight:700">print</span>()<br /><span style="color:#ff9d00;font-weight:700">print</span>(np.sort(arr , kind = <span style="color:#3ad900;font-weight:400">&#39;heapsort&#39;</span>))<br /><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output:<br /><br />[[5 2 2 3 1]<br /> [7 3 8 6 4]<br /> [7 4 9 8 6]]<br /></span><br /><span style="color:#3ad900;font-weight:400">[[3 4 6 7 8]<br /> [2 6 7 8 9]<br /> [1 2 3 4 5]]<br /><br />[[3 4 6 7 8]<br /> [2 6 7 8 9]<br /> [1 2 3 4 5]]```</span></pre></div></p><p></p><p></p><p><h1>NumPy Filter Array</h1></p><p> </p><p> <div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr=np.array([<span style="color:#ff0044;font-weight:400">42</span>,<span style="color:#ff0044;font-weight:400">23</span>,<span style="color:#ff0044;font-weight:400">43</span>,<span style="color:#ff0044;font-weight:400">22</span>])<br /><br />filter_arr=(<span style="color:#ff0044;font-weight:400">True</span>,<span style="color:#ff0044;font-weight:400">False</span>,<span style="color:#ff0044;font-weight:400">True</span>,<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />newarr=arr[filter_arr]<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(newarr)</pre></div></p><p> </p><p> indexing : true</p><p> </p><p> <div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr=np.array([<span style="color:#ff0044;font-weight:400">41</span>,<span style="color:#ff0044;font-weight:400">42</span>,<span style="color:#ff0044;font-weight:400">43</span>,<span style="color:#ff0044;font-weight:400">44</span>])<br /><br />filter_arr = []<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />	<span style="color:#ff9d00;font-weight:700">if</span> i &gt; <span style="color:#ff0044;font-weight:400">42</span>:<br />		filter_arr.append(<span style="color:#ff0044;font-weight:400">True</span>)<br />	<span style="color:#ff9d00;font-weight:700">else</span>:<br />		filter_arr.append(<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />newarr=arr[filter_arr]<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(filter_arr)<br /><span style="color:#ff9d00;font-weight:700">print</span>(newarr)</pre></div></p><p> </p><p> </p><p><h2>Creating Filter Directly From Array</h2></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = numpy.array([<span style="color:#ff0044;font-weight:400">41</span>,<span style="color:#ff0044;font-weight:400">42</span>,<span style="color:#ff0044;font-weight:400">43</span>,<span style="color:#ff0044;font-weight:400">44</span>])<br /><br />filter_arr = arr%<span style="color:#ff0044;font-weight:400">2</span> == <span style="color:#ff0044;font-weight:400">0</span><br /><br />newarr = arr[filter_arr]<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(filter_arr)<br /><span style="color:#ff9d00;font-weight:700">print</span>(newarr)</pre></div></p><p></p><p></p><p> </p></div><div class='page'><h1 class='title level-2'>Array Merging</h1><br/><p></p><p><h2>Array Merging</h2></p><p><strong>numpy.vstack() </strong>Stack the sequence of input arrays vertically </p><p><em><strong>Syntax :</strong></em><em> numpy.vstack(tup)</em></p><p><em><strong>Parameters :</strong></em></p><p><em><strong>tup : </strong></em><em>[sequence of ndarrays] Tuple containing arrays to be stacked. The arrays must have the same shape along all but the first axis.</em></p><p></p><p><em><strong>Return : </strong></em><em>[stacked ndarray] The stacked array of the input arrays.</em></p><p></p><p><strong>Code #1 :</strong></p><p><code>#</code><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># vstack() function</span><br />  <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br /><span style="color:#0088ff;font-weight:400"># input array</span><br />in_arr1 = geek.array([ <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;1st Input array : \n&quot;</span>, in_arr1) <br />  <br />in_arr2 = geek.array([ <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;2nd Input array : \n&quot;</span>, in_arr2) <br />  <br /><span style="color:#0088ff;font-weight:400"># Stacking the two arrays vertically</span><br />out_arr = geek.vstack((in_arr1, in_arr2))<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;Output vertically stacked array:\n &quot;</span>, out_arr)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output:<br />1st Input array : <br /> [1 2 3]<br />2nd Input array : <br /> [4 5 6]<br />Output vertically stacked array:<br />  [[1 2 3]<br /> [4 5 6]] &#39;&#39;&#39;</span></pre></div></p><p></p><p></p><p><strong>Code #2 :</strong></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># vstack() function</span><br />  <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br /><span style="color:#0088ff;font-weight:400"># input array</span><br />in_arr1 = geek.array([[ <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>], [ -<span style="color:#ff0044;font-weight:400">1</span>, -<span style="color:#ff0044;font-weight:400">2</span>, -<span style="color:#ff0044;font-weight:400">3</span>]] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;1st Input array : \n&quot;</span>, in_arr1) <br />  <br />in_arr2 = geek.array([[ <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>], [ -<span style="color:#ff0044;font-weight:400">4</span>, -<span style="color:#ff0044;font-weight:400">5</span>, -<span style="color:#ff0044;font-weight:400">6</span>]] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;2nd Input array : \n&quot;</span>, in_arr2) <br />  <br /><span style="color:#0088ff;font-weight:400"># Stacking the two arrays vertically</span><br />out_arr = geek.vstack((in_arr1, in_arr2))<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;Output stacked array :\n &quot;</span>, out_arr)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output:<br />1st Input array : <br /> [[ 1  2  3]<br /> [-1 -2 -3]]<br />2nd Input array : <br /> [[ 4  5  6]<br /> [-4 -5 -6]]<br />Output stacked array :<br />  [[ 1  2  3]<br /> [-1 -2 -3]<br /> [ 4  5  6]<br /> [-4 -5 -6]] &#39;&#39;&#39;</span></pre></div></p><p> </p><p><strong>numpy.hstack() </strong>function is used to stack the sequence of input arrays horizontally (i.e. column wise) to make a single array.</p><p><em><strong>Syntax :</strong></em><em> numpy.hstack(tup)</em></p><p><em><strong>Parameters :</strong></em></p><p><em><strong>tup : </strong></em><em>[sequence of ndarrays] Tuple containing arrays to be stacked. The arrays must have the same shape along all but the second axis.</em></p><p><em><strong>Return : </strong></em><em>[stacked ndarray] The stacked array of the input arrays.</em></p><p><strong>Code #1 :</strong></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># hstack() function</span><br />  <br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br /><span style="color:#0088ff;font-weight:400"># input array</span><br />in_arr1 = geek.array([ <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;1st Input array : \n&quot;</span>, in_arr1) <br />  <br />in_arr2 = geek.array([ <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>] )<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;2nd Input array : \n&quot;</span>, in_arr2) <br />  <br /><span style="color:#0088ff;font-weight:400"># Stacking the two arrays horizontally</span><br />out_arr = geek.hstack((in_arr1, in_arr2))<br /><span style="color:#ff9d00;font-weight:700">print</span> (<span style="color:#3ad900;font-weight:400">&quot;Output horizontally stacked array:\n &quot;</span>, out_arr)Output:<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />1st Input array : <br /> [1 2 3]<br />2nd Input array : <br /> [4 5 6]<br />Output horizontally stacked array:<br />  [1 2 3 4 5 6] <br />&#39;&#39;&#39;</span></pre></div></p><p></p><p><strong>numpy.dstack() </strong>function is used to stack the sequence of input arrays along axis 0 to make a single array.</p><p><em><strong>Syntax :</strong></em><em> numpy.dstack(tup)</em></p><p><em><strong>Parameters :</strong></em></p><p><em><strong>tup : </strong></em><em>[sequence of ndarrays] Tuple containing arrays to be stacked. The arrays must have the same shape along all but the second axis.</em></p><p><em><strong>Return : </strong></em><em>[stacked ndarray] The stacked array of the input arrays</em></p><p> </p><p><div class="codebox"><pre>numpy.dstack((arr_1,arr_2))<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />[1,4]<br />[2,5]<br />[3,6]</span></pre></div></p><p></p><p><strong><h2>numpy.concatenate()</h2></strong><h2> function concatenate a sequence of arrays along an existing axis.</h2></p><p></p><p><em><strong>Syntax :</strong></em><em> numpy.concatenate((arr1, arr2, …), axis=0, out=None)</em></p><p></p><p><em><strong>Parameters :</strong></em></p><p></p><p><em><strong>arr1, arr2, … : </strong></em><em>[sequence of array_like] The arrays must have the same shape, except in the dimension corresponding to axis.</em></p><p><em><strong>axis : </strong></em><em>[int, optional] The axis along which the arrays will be joined. If axis is None, arrays are flattened before use. Default is 0.</em></p><p><em><strong>out : </strong></em><em>[ndarray, optional] If provided, the destination to place the result. The shape must be correct, matching that of what concatenate would have returned if no out argument were specified.</em></p><p></p><p><em><strong>Return : </strong></em><em>[ndarray] The concatenated array.</em></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># numpy.concatenate() function</span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing numpy as geek </span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br />arr1 = geek.array([[<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">4</span>], [<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">8</span>]])<br />arr2 = geek.array([[<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>], [<span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">9</span>]])<br />  <br />gfg = geek.concatenate((arr1, arr2), axis = <span style="color:#ff0044;font-weight:400">0</span>)<br />  <br /><span style="color:#ff9d00;font-weight:700">print</span> (gfg)<br /><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output :<br />[[2 4]<br /> [6 8]<br /> [3 5]<br /> [7 9]] <br />&#39;&#39;&#39;</span></pre></div> </p></div><div class='page'><h1 class='title level-3'>Split</h1><br/><p><strong>numpy.vsplit()</strong> function split an array into multiple sub-arrays vertically (row-wise). vsplit is equivalent to split with axis=0 (default), the array is always split along the first axis regardless of the array dimension.</p><p><em><strong>Syntax :</strong></em><em> numpy.vsplit(arr, indices_or_sections)</em></p><p><em><strong>Parameters :</strong></em></p><p><em><strong>arr : </strong></em><em>[ndarray] Array to be divided into sub-arrays.</em></p><p></p><p><em><strong>indices_or_sections : </strong></em><em>[int or 1-D array] If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.</em></p><p><em>If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split</em></p><p></p><p>basically the arange gives a set of numbers it adds a comma to separate the indices</p><p></p><p><em><strong>Return : </strong></em><em>[ndarray] A list of sub-arrays.</em></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># numpy.vsplit() function</span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing numpy as geek </span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br />arr = geek.arange(<span style="color:#ff0044;font-weight:400">9.0</span>).reshape(<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">3</span>)<br />  <br />gfg = geek.vsplit(arr, <span style="color:#ff0044;font-weight:400">1</span>)<br />  <br /><span style="color:#ff9d00;font-weight:700">print</span> (gfg)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;Output :<br />[array([[ 0.,  1.,  2.],<br />       [ 3.,  4.,  5.],<br />       [ 6.,  7.,  8.]])] &#39;&#39;&#39;</span></pre></div></p><p> </p><p> </p><p><strong>numpy.hsplit()</strong> function split an array into multiple sub-arrays horizontally (column-wise). hsplit is equivalent to split with axis=1, the array is always split along the second axis regardless of the array dimension.</p><p><em><strong>Syntax :</strong></em><em> numpy.hsplit(arr, indices_or_sections)</em></p><p><em><strong>Parameters :</strong></em></p><p></p><p><em><strong>arr : </strong></em><em>[ndarray] Array to be divided into sub-arrays.</em></p><p></p><p><em><strong>indices_or_sections : </strong></em><em>[int or 1-D array] If indices_or_sections is an integer, N, the array will be divided into N equal arrays along axis.</em></p><p><em>If indices_or_sections is a 1-D array of sorted integers, the entries indicate where along axis the array is split</em></p><p></p><p>splits horizontally</p><p></p><p></p><p><em><strong>Return : </strong></em><em>[ndarray] A list of sub-arrays.</em></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python program explaining</span><br /><span style="color:#0088ff;font-weight:400"># numpy.hsplit() function</span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing numpy as geek </span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> geek<br />  <br />arr = geek.arange(<span style="color:#ff0044;font-weight:400">16.0</span>).reshape(<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">4</span>)<br />  <br />gfg = geek.hsplit(arr, <span style="color:#ff0044;font-weight:400">2</span>)<br />  <br /><span style="color:#ff9d00;font-weight:700">print</span> (gfg)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;</span><br /><span style="color:#3ad900;font-weight:400"><br />Output :<br />[array([[  0.,   1.],<br />       [  4.,   5.],<br />       [  8.,   9.],<br />       [ 12.,  13.]]), array([[  2.,   3.],<br />       [  6.,   7.],<br />       [ 10.,  11.],<br />       [ 14.,  15.]])]<br />&#39;&#39;&#39;</span></pre></div></p><p>here, it splits horizontally to give 2 separate arrays</p><p></p><p><h3>Splitting is reverse operation of Joining.</h3></p><p><h3>Joining merges multiple arrays into one and Splitting breaks one array into multiple.</h3></p><p><h3>We use </h3><strong><h3>array_split()</h3></strong><h3> for splitting arrays, we pass it the array we want to split and the number of splits.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>], [<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>], [<span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>], [<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">11</span>, <span style="color:#ff0044;font-weight:400">12</span>], [<span style="color:#ff0044;font-weight:400">13</span>, <span style="color:#ff0044;font-weight:400">14</span>, <span style="color:#ff0044;font-weight:400">15</span>], [<span style="color:#ff0044;font-weight:400">16</span>, <span style="color:#ff0044;font-weight:400">17</span>, <span style="color:#ff0044;font-weight:400">18</span>]])<br /><br />newarr = np.array_split(arr, <span style="color:#ff0044;font-weight:400">3</span>, axis=<span style="color:#ff0044;font-weight:400">1</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(newarr)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />[array([[ 1],<br />       [ 4],<br />       [ 7],<br />       [10],<br />       [13],</span><br /><span style="color:#3ad900;font-weight:400">       [16]]), array([[ 2],<br />       [ 5],<br />       [ 8],<br />       [11],<br />       [14],<br />       [17]]), array([[ 3],<br />       [ 6],<br />       [ 9],<br />       [12],<br />       [15],<br />       [18]])]</span></pre></div>]</p></div><div class='page'><h1 class='title level-2'>Array Slicing</h1><br/><p></p><p><h2>Arrays Slicing - DAP</h2></p><p></p><p></p><p><strong>Array[</strong> Initial <strong>:</strong> End <strong>:</strong> IndexJump <strong>]</strong></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>])<br />arr[<span style="color:#ff0044;font-weight:400">3</span>: ]</pre></div></p><p></p><p><h3>Let us see an example now.</h3></p><p><div class="codebox"><pre>arr = np.array([[<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>],[<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>],[<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">5</span>],[<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">1</span>]])<br />arr<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(arr[ <span style="color:#ff0044;font-weight:400">3</span> , <span style="color:#ff0044;font-weight:400">1</span>])<br /><span style="color:#ff9d00;font-weight:700">print</span>()<br /><span style="color:#ff9d00;font-weight:700">print</span>(arr[ <span style="color:#ff0044;font-weight:400">1</span>: , <span style="color:#ff0044;font-weight:400">1</span>:])<br /></pre></div><code></code></p><p><code></code><strong><h3>Output:</h3></strong></p><p>array([[1, 2, 3, 4],</p><p>       [5, 6, 7, 8],</p><p>       [8, 7, 6, 5],</p><p>       [4, 3, 2, 1]])<h3>This is the 2D array which we will be using.</h3></p><p><code></code></p><p><code></code><strong><h3>Output:</h3></strong></p><p>3</p><p></p><p>[[6 7 8]</p><p> [7 6 5]</p><p> [3 2 1]]<h3>The first output we </h3><strong><h3>3</h3></strong><h3> because we were trying to get the 4th row(index 3) and 2nd column(index 1)</h3></p><p><h3>The second output is a combination with slicing where we printed the array starting from the 2nd row(index 1) and 2nd column(index 1) and the rest of the elements which are coming in the upcoming indexes.</h3></p></div><div class='page'><h1 class='title level-2'>Array automation</h1><br/><p></p><p><h2>Automating using Numpy</h2></p><p></p><p></p><p><h3>Now if we convert the list into an array we can do it simply in a single line.</h3></p><p></p><p><div class="codebox"><pre>lst = np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">10</span>])<br /><span style="color:#ff9d00;font-weight:700">print</span>(lst[lst&gt;<span style="color:#ff0044;font-weight:400">5</span>])<span style="color:#0088ff;font-weight:400">#in a single line without using the for loop</span><br /><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />Output :<br />[ 6  7  8  9 10]<br />&#39;&#39;&#39;</span></pre></div></p><p></p><p><h3>Iterate on each scalar element of the 2-D array:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>], [<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>]])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> x <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />  <span style="color:#ff9d00;font-weight:700">for</span> y <span style="color:#ff9d00;font-weight:700">in</span> x:<br />    <span style="color:#ff9d00;font-weight:700">print</span>(y)<br /><br /></pre></div></p><p></p><p></p><p><h2>Iterating 3-D Arrays</h2></p><p><h3>In a 3-D array it will go through all the 2-D arrays.</h3></p><p></p><p><h3>Example</h3></p><p><h3>Iterate on the elements of the following 3-D array:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>], [<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>]], [[<span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>], [<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">11</span>, <span style="color:#ff0044;font-weight:400">12</span>]]])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> x <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />  <span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><h3>To return the actual values, the scalars, we have to iterate the arrays in each dimension.</h3></p><p></p><p><h3>Example</h3></p><p><h3>Iterate down to the scalars:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>], [<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>]], [[<span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>], [<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">11</span>, <span style="color:#ff0044;font-weight:400">12</span>]]])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> x <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />  <span style="color:#ff9d00;font-weight:700">for</span> y <span style="color:#ff9d00;font-weight:700">in</span> x:<br />    <span style="color:#ff9d00;font-weight:700">for</span> z <span style="color:#ff9d00;font-weight:700">in</span> y:<br />      <span style="color:#ff9d00;font-weight:700">print</span>(z)</pre></div></p><p></p><p><h3>The function </h3><code>nditer()</code><h3> is a helping function that can be used from very basic to very advanced iterations. It solves some basic issues which we face in iteration, lets go through it with examples.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>], [<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>]], [[<span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>], [<span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>]]])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> x <span style="color:#ff9d00;font-weight:700">in</span> np.nditer(arr):<br />  <span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><h3>We can use</h3> <strong>op_datatypes </strong><h3>argument and pass it the expected datatype to change the datatype of elements while iterating.</h3></p><p></p><p><h3>NumPy does not change the data type of the element in-place (where the element is in array) so it needs some other space to perform this action, that extra space is called buffer, and in order to enable it in </h3><code>nditer()</code><h3> we pass </h3><code>flags=[&#39;buffered&#39;]</code><h3>.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> x <span style="color:#ff9d00;font-weight:700">in</span> np.nditer(arr, flags=[<span style="color:#3ad900;font-weight:400">&#39;buffered&#39;</span>], op_dtypes=[<span style="color:#3ad900;font-weight:400">&#39;S&#39;</span>]):<br />  <span style="color:#ff9d00;font-weight:700">print</span>(x)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />b&#39;1<br />b&#39;2<br />b&#39;3</span></pre></div></p></div><div class='page'><h1 class='title level-3'>ndenumerate()\</h1><br/><p></p><p><h2>Enumerated Iteration Using ndenumerate()</h2></p><p><h3>Enumeration means mentioning sequence number of somethings one by one.</h3></p><p><h3>Sometimes we require corresponding index of the element while iterating, the </h3><code><h3>ndenumerate()</h3></code><h3> method can be used for those usecases.</h3></p><p></p><p><h3>Example</h3></p><p><h3>Enumerate on following 1D arrays elements:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> idx, x <span style="color:#ff9d00;font-weight:700">in</span> np.ndenumerate(arr):<br />  <span style="color:#ff9d00;font-weight:700">print</span>(idx, x)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />(0,) 1<br />(1,) 2<br />(2,) 3</span></pre></div></p><p></p><p></p><p><h3>Enumerate on following 2D array&#39;s elements:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([[<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>], [<span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>]])<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> idx, x <span style="color:#ff9d00;font-weight:700">in</span> np.ndenumerate(arr):<br />  <span style="color:#ff9d00;font-weight:700">print</span>(idx, x)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />(0, 0) 1<br />(0, 1) 2<br />(0, 2) 3<br />(0, 3) 4<br />(1, 0) 5<br />(1, 1) 6</span><br /><span style="color:#3ad900;font-weight:400">(1, 2) 7<br />(1, 3) 8</span><br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Array Search</h1><br/><p></p><p><h1>NumPy Searching Arrays</h1></p><p></p><p><strong>where</strong>() method</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">4</span>])<br /><br />x = np.where(arr == <span style="color:#ff0044;font-weight:400">4</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<span style="color:#0088ff;font-weight:400">#(array([3, 5, 6]),)</span></pre></div></p><p></p><p>Find even numbers:</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>])<br /><br />x = np.where(arr%<span style="color:#ff0044;font-weight:400">2</span> == <span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p><h2>Search Sorted</h2></p><p><h3>There is a method called </h3><code><h3>searchsorted()</h3></code><h3> which performs a binary search in the array, and returns the index where the specified value would be inserted to maintain the search order.</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>])<br /><br />x = np.searchsorted(arr, <span style="color:#ff0044;font-weight:400">7</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<br /><span style="color:#0088ff;font-weight:400">#1</span></pre></div></p><p></p><p></p><p><h3>Search From the Right Side</h3></p><p><h3>By default the left most index is returned, but we can give </h3><code><h3>side=&#39;right&#39;</h3></code><h3> to return the right most index instead.</h3></p><p></p><p><h3>Example</h3></p><p><h3>Find the indexes where the value 7 should be inserted, starting from the right:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>])<br /><br />x = np.searchsorted(arr, <span style="color:#ff0044;font-weight:400">7</span>, side=<span style="color:#3ad900;font-weight:400">&#39;right&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<br /></pre></div></p><p></p><p>Search where to insert the numbers:</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">7</span>])<br /><br />x = np.searchsorted(arr, [<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">6</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<br /><span style="color:#0088ff;font-weight:400">#[1 2 3]</span></pre></div></p><p></p></div><div class='page'><h1 class='title level-2'>Random</h1><br/><p></p><p></p><p><h2>Pseudo Random and True Random</h2></p><p></p><p><h3>Computers work on programs, and programs are definitive set of instructions. So it means there must be some algorithm to generate a random number as well.</h3></p><p><h3>If there is a program to generate random number it can be predicted, thus it is not truly random.</h3></p><p><h3>Random numbers generated through a generation algorithm are called </h3><em><h3>pseudo random</h3></em><h3>.</h3></p><p><h3>Can we make truly random numbers?</h3></p><p><h3>Yes. In order to generate a truly random number on our computers we need to get the random data from some outside source. This outside source is generally our keystrokes, mouse movements, data on network etc.</h3></p><p><h3>We do not need truly random numbers, unless its related to security (e.g. encryption keys) or the basis of application is the randomness (e.g. Digital roulette wheels).</h3></p><p><h3>In this tutorial we will be using pseudo random numbers.</h3></p><p></p><p><div class="codebox"><pre><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.randint(<span style="color:#ff0044;font-weight:400">100</span>, size=(<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.choice([<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">9</span>], size=(<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><h2>What is Data Distribution?</h2></p><p><h3>Data Distribution is a list of all possible values, and how often each value occurs.</h3></p><p><h3>Such lists are important when working with statistics and data science.</h3></p><p><h3>The random module offer methods that returns randomly generated data distributions.</h3></p><p></p><p></p><p><strong>Probability Density Function:</strong><h3> A function that describes a continuous probability. i.e. probability of all values in an array.</h3></p><p></p><p><h3>The </h3><code><h3>choice()</h3></code><h3> method allows us to specify the probability for each value.</h3></p><p><h3>The probability is set by a number between 0 and 1, where 0 means that the value will never occur and 1 means that the value will always occur.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.choice([<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">9</span>], p=[<span style="color:#ff0044;font-weight:400">0.1</span>, <span style="color:#ff0044;font-weight:400">0.3</span>, <span style="color:#ff0044;font-weight:400">0.6</span>, <span style="color:#ff0044;font-weight:400">0.0</span>], size=(<span style="color:#ff0044;font-weight:400">100</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />[5 7 7 7 7 7 7 5 5 7 7 7 5 5 7 7 7 7 7 7 5 7 7 5 5 5 5 7 7 7 5 7 7 7 7 7 7<br /> 7 7 5 7 3 5 7 7 7 7 5 5 7 7 7 7 7 7 3 3 3 7 7 7 7 7 7 7 5 3 7 3 5 7 7 7 7<br /> 3 5 3 7 7 5 7 7 7 7 3 7 7 5 5 7 7 7 5 7 5 3 3 7 7 5]&#39;&#39;&#39;</span></pre></div></p><p></p><p><h3>The sum of all probability numbers should be 1.</h3></p><p></p><p></p><p>T<h3>he main difference between random. sample() and random. choice() is: </h3><strong><h3>sample() function gives us a specified number of distinct results whereas the choice() function gives us a single value out of the given sequence</h3></strong><h3>.</h3></p><p></p><p>random.randint(34)</p><p></p></div><div class='page'><h1 class='title level-3'>Random Permutations</h1><br/><p><h2>Random Permutations of Elements</h2></p><p>A permutation refers to an arrangement of elements. e.g. [3, 2, 1] is a permutation of [1, 2, 3] and vice-versa.</p><p></p><p>The NumPy Random module provides two methods for this:<strong> shuffle() </strong>and <strong>permutation().</strong></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>])<br /><br />random.shuffle(arr)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(arr)</pre></div></p><p></p><p>Generating random permutation:</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />arr = np.array([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(random.permutation(arr))<br /></pre></div></p><p></p><p><h3>The </h3><code>permutation()</code><h3> method </h3><em>returns</em><h3> a re-arranged array (and leaves the original array un-changed).</h3></p><p><h3>The </h3><code>shuffle()</code><h3> method makes changes to the original array.</h3></p><p></p></div><div class='page'><h1 class='title level-3'>Seaborn</h1><br/><p>Seaborn is a library that uses Matplotlib to plot graphs. Used to visualize random distributions</p><p></p><p>Plotting a Distplot</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot([<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>])<br /><br />plt.show()<br /></pre></div></p><p></p><p>distplot has deprecated and displot is used instead</p><p></p><p>hist=<strong>False</strong> to remove histogram</p><p></p><p></p><p></p><p></p><p><h1>Normal (Gaussian) Distribution</h1></p><p></p><p><h3>The Normal Distribution is one of the most important distributions.</h3></p><p><h3>It is also called the Gaussian Distribution after the German mathematician Carl Friedrich Gauss.</h3></p><p><h3>It fits the probability distribution of many events, eg. IQ Scores, Heartbeat etc.</h3></p><p><h3>Use the </h3><code><h3>random.normal()</h3></code><h3> method to get a Normal Data Distribution.</h3></p><p></p><p><h3>It has three parameters:</h3></p><p></p><p><code><h3>loc</h3></code><h3> - (Mean) where the peak of the bell exists.</h3></p><p><code><h3>scale</h3></code><h3> - (Standard Deviation) how flat the graph distribution should be.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.normal(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/normal1.png"><img src="images/39-1.png" alt="images/39-1.png" /></a></p></div><div class='page'><h1 class='title level-3'>Binomial Distribution</h1><br/><p></p><p><h2>Binomial Distribution</h2></p><p></p><p><h3>Binomial Distribution is a </h3><em><h3>Discrete Distribution</h3></em><h3>.</h3></p><p><h3>It describes the outcome of binary scenarios, e.g. toss of a coin, it will either be head or tails.</h3></p><p><h3>It has three parameters:</h3></p><p><code><h3>n</h3></code><h3> - number of trials.</h3></p><p><code><h3>p</h3></code><h3> - probability of occurence of each trial (e.g. for toss of a coin 0.5 each).</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><strong>Discrete Distribution:</strong><h3>The distribution is defined at separate set of events, e.g. a coin toss&#39;s result is discrete as it can be only head or tails whereas height of people is continuous as it can be 170, 170.1, 170.11 and so on.</h3></p><p></p><p><h3>Given 10 trials for coin toss generate 10 data points:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.binomial(n=<span style="color:#ff0044;font-weight:400">10</span>, p=<span style="color:#ff0044;font-weight:400">0.5</span>, size=<span style="color:#ff0044;font-weight:400">10</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)<br /><br /></pre></div></p><p></p><p></p><p><h2>Visualization of Binomial Distribution</h2></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.binomial(n=<span style="color:#ff0044;font-weight:400">10</span>, p=<span style="color:#ff0044;font-weight:400">0.5</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">True</span>, kde=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()<br /></pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/bionomial1.png"><img src="images/40-1.png" alt="images/40-1.png" /></a></p><p></p><p></p><p><h2>Difference Between Normal and Binomial Distribution</h2></p><p><h3>The main difference is that normal distribution is continous whereas binomial is discrete, but if there are enough data points it will be quite similar to normal distribution with certain loc and scale.</h3></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.normal(loc=<span style="color:#ff0044;font-weight:400">50</span>, scale=<span style="color:#ff0044;font-weight:400">5</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;normal&#39;</span>)<br />sns.distplot(random.binomial(n=<span style="color:#ff0044;font-weight:400">100</span>, p=<span style="color:#ff0044;font-weight:400">0.5</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;binomial&#39;</span>)<br /><br />plt.show()<br /></pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/bionomial2.png"><img src="images/40-2.png" alt="images/40-2.png" /></a></p></div><div class='page'><h1 class='title level-4'>Multinomial Distribution</h1><br/><p></p><p></p><p><h2>Multinomial Distribution</h2></p><p></p><p><h3>Multinomial distribution is a generalization of binomial distribution.</h3></p><p><h3>It describes outcomes of multi-nomial scenarios unlike binomial where scenarios must be only one of two. e.g. Blood type of a population, dice roll outcome.</h3></p><p><h3>It has three parameters:</h3></p><p><code><h3>n</h3></code><h3> - number of possible outcomes (e.g. 6 for dice roll).</h3></p><p><code><h3>pvals</h3></code><h3> - list of probabilties of outcomes (e.g. [1/6,</h3></p><p><code>size</code><h3> - The shape of the returned array.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.multinomial(n=<span style="color:#ff0044;font-weight:400">6</span>, pvals=[<span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>/<span style="color:#ff0044;font-weight:400">6</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><strong><h3>Note:</h3></strong><h3> Multinomial samples will NOT produce a single value! They will produce one value for each </h3><code><h3>pval</h3></code><h3>.</h3></p><p></p><p><strong><h3>Note:</h3></strong><h3> As they are generalization of binomial distribution their visual representation and similarity of normal distribution is same as that of multiple binomial distributions.</h3></p><p></p></div><div class='page'><h1 class='title level-3'>Poisson Distribution</h1><br/><p></p><p><h2>Poisson Distribution</h2></p><p><h3>Poisson Distribution is a </h3><em><h3>Discrete Distribution</h3></em><h3>.</h3></p><p><h3>It estimates how many times an event can happen in a specified time. e.g. If someone eats twice a day what is the probability he will eat thrice?</h3></p><p><h3>It has two parameters:</h3></p><p><code><h3>lam</h3></code><h3> - rate or known number of occurrences e.g. 2 for above problem.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><h3>Generate a random 1x10 distribution for occurrence 2:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.poisson(lam=<span style="color:#ff0044;font-weight:400">2</span>, size=<span style="color:#ff0044;font-weight:400">10</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.poisson(lam=<span style="color:#ff0044;font-weight:400">2</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), kde=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/poisson1.png"><img src="images/42-1.png" alt="images/42-1.png" /></a></p><p></p><p></p><p><h2>Difference Between Normal and Poisson Distribution</h2></p><p></p><p><h3>Normal distribution is continuous whereas poisson is discrete.</h3></p><p><h3>But we can see that similar to binomial for a large enough poisson distribution it will become similar to normal distribution with certain std dev and mean.</h3></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.normal(loc=<span style="color:#ff0044;font-weight:400">50</span>, scale=<span style="color:#ff0044;font-weight:400">7</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;normal&#39;</span>)<br />sns.distplot(random.poisson(lam=<span style="color:#ff0044;font-weight:400">50</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;poisson&#39;</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/poisson2.png"><img src="images/42-2.png" alt="images/42-2.png" /></a></p><p></p><p></p><p></p><p><h2>Difference Between Binomial and Poisson Distribution</h2></p><p></p><p><h3>Binomial distribution only has two possible outcomes, whereas poisson distribution can have unlimited possible outcomes.</h3></p><p><h3>But for very large </h3><code><h3>n</h3></code><h3> and near-zero </h3><code><h3>p</h3></code><h3> binomial distribution is near identical to poisson distribution such that </h3><code><h3>n * p</h3></code><h3> is nearly equal to </h3><code><h3>lam</h3></code><h3>.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.binomial(n=<span style="color:#ff0044;font-weight:400">1000</span>, p=<span style="color:#ff0044;font-weight:400">0.01</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;binomial&#39;</span>)<br />sns.distplot(random.poisson(lam=<span style="color:#ff0044;font-weight:400">10</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;poisson&#39;</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/poisson4.png"><img src="images/42-3.png" alt="images/42-3.png" /></a></p><p></p></div><div class='page'><h1 class='title level-4'>Exponential Distribution</h1><br/><p></p><p><h2>Exponential Distribution</h2></p><p><h3>Exponential distribution is used for describing time till next event e.g. failure/success etc.</h3></p><p></p><p><h3>It has two parameters:</h3></p><p><code><h3>scale</h3></code><h3> - inverse of rate ( see lam in poisson distribution ) defaults to 1.0.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.exponential(scale=<span style="color:#ff0044;font-weight:400">2</span>, size=(<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.exponential(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p>Result:</p><p><a href="https://www.w3schools.com/python/numpy/exponential1.png"><img src="images/44-1.png" alt="images/44-1.png" /></a></p></div><div class='page'><h1 class='title level-3'>Uniform Distribution</h1><br/><p></p><p><h2>Uniform Distribution</h2></p><p><h3>Used to describe probability where every event has equal chances of occuring.</h3></p><p><h3>E.g. Generation of random numbers.</h3></p><p><h3>It has three parameters:</h3></p><p><code><h3>a</h3></code><h3> - lower bound - default 0 .0.</h3></p><p><code><h3>b</h3></code><h3> - upper bound - default 1.0.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.uniform(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()<br /></pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/uniform1.png"><img src="images/43-1.png" alt="images/43-1.png" /></a></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Logistic Distribution</h1><br/><p><h2>Logistic Distribution</h2></p><p></p><p><h3>Logistic Distribution is used to describe growth.</h3></p><p><h3>Used extensively in machine learning in</h3><h3> logistic regression</h3><h3>, neural networks etc.</h3></p><p></p><p><h3>It has three parameters:</h3></p><p></p><p><code><h3>loc</h3></code><h3> - mean, where the peak is. Default 0.</h3></p><p><code><h3>scale</h3></code><h3> - standard deviation, the flatness of distribution. Default 1.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><br />x = random.logistic(loc=<span style="color:#ff0044;font-weight:400">1</span>, scale=<span style="color:#ff0044;font-weight:400">2</span>, size=(<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(x)</pre></div></p><p></p><p></p><p><h2>Visualization of Logistic Distribution</h2></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.logistic(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()<br /></pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/logistic1.png"><img src="images/45-1.png" alt="images/45-1.png" /></a></p><p></p><p></p><p><h2>Difference Between Logistic and Normal Distribution</h2></p><p><h3>Both distributions are near identical, but logistic distribution has more area under the tails, meaning it represents more possibility of occurrence of an event further away from mean.</h3></p><p><h3>For higher value of scale (standard deviation) the normal and logistic distributions are near identical apart from the peak.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.normal(scale=<span style="color:#ff0044;font-weight:400">2</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;normal&#39;</span>)<br />sns.distplot(random.logistic(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>, label=<span style="color:#3ad900;font-weight:400">&#39;logistic&#39;</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/logistic2.png"><img src="images/45-2.png" alt="images/45-2.png" /></a></p><p></p><p></p><p><h2>Chi Square Distribution</h2></p><p></p><p><h3>Chi Square distribution is used as a basis to verify the hypothesis.</h3></p><p></p><p><h3>It has two parameters:</h3></p><p><code><h3>df</h3></code><h3> - (degree of freedom).</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.chisquare(df=<span style="color:#ff0044;font-weight:400">1</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/chisquare1.png"><img src="images/45-3.png" alt="images/45-3.png" /></a></p></div><div class='page'><h1 class='title level-3'>Rayleigh and Pareto Distribution</h1><br/><p></p><p><h2>Rayleigh Distribution</h2></p><p><h3>Rayleigh distribution is used in signal processing.</h3></p><p><h3>It has two parameters:</h3></p><p><code><h3>scale</h3></code><h3> - (standard deviation) decides how flat the distribution will be default 1.0).</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p></p><p><h2>Visualization of Rayleigh Distribution</h2></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.rayleigh(size=<span style="color:#ff0044;font-weight:400">1000</span>), hist=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><a href="https://www.w3schools.com/python/numpy/rayleigh1.png"><img src="images/46-1.png" alt="images/46-1.png" /></a></p><p></p><p></p><p></p><p><h1>Pareto Distribution</h1></p><p></p><p><h3>A distribution following Pareto&#39;s law i.e. 80-20 distribution (20% factors cause 80% outcome).</h3></p><p></p><p><h3>It has two parameter:</h3></p><p></p><p><code><h3>a</h3></code><h3> - shape parameter.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p><h2>Visualization of Pareto Distribution</h2></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />sns.distplot(random.pareto(a=<span style="color:#ff0044;font-weight:400">2</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>), kde=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><h3>Result</h3></p><p><a href="https://www.w3schools.com/python/numpy/pareto1.png"><img src="images/46-2.png" alt="images/46-2.png" /></a></p><p></p><p> </p><p><h1>Zipf Distribution</h1></p><p></p><p><h3>Zipf distritutions are used to sample data based on zipf&#39;s law.</h3></p><p><strong><h3>Zipf&#39;s Law:</h3></strong><h3> In a collection, the nth common term is 1/n times of the most common term. E.g. the 5th most common word in English occurs nearly 1/5 times as often as the most common word.</h3></p><p></p><p><h3>It has two parameters:</h3></p><p><code><h3>a</h3></code><h3> - distribution parameter.</h3></p><p><code><h3>size</h3></code><h3> - The shape of the returned array.</h3></p><p></p><p></p><p><h2>Visualization of Zipf Distribution</h2></p><p></p><p><h3>Sample 1000 points but plotting only ones with value &lt; 10 for more meaningful chart.</h3></p><p></p><p><h3>Example</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">numpy</span> <span style="color:#333333;font-weight:400">import</span> random<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br />x = random.zipf(a=<span style="color:#ff0044;font-weight:400">2</span>, size=<span style="color:#ff0044;font-weight:400">1000</span>)<br />sns.distplot(x[x&lt;<span style="color:#ff0044;font-weight:400">10</span>], kde=<span style="color:#ff0044;font-weight:400">False</span>)<br /><br />plt.show()</pre></div></p><p></p><p><h3>Result</h3></p><p><a href="https://www.w3schools.com/python/numpy/zipf1.png"><img src="images/46-3.png" alt="images/46-3.png" /></a></p><p></p></div><div class='page'><h1 class='title level-2'>ufunc</h1><br/><p></p><p><h2>What are ufuncs?</h2></p><p><h3>ufuncs stands for &quot;Universal Functions&quot; and they are NumPy functions that operate on the </h3><code><h3>ndarray</h3></code><h3> object.</h3></p><p></p><p><h2>Why use ufuncs?</h2></p><p><h3>ufuncs are used to implement </h3><em><h3>vectorization</h3></em><h3> in NumPy which is way faster than iterating over elements.</h3></p><p><h3>They also provide broadcasting and additional methods like reduce, accumulate etc. that are very helpful for computation.</h3></p><p><h3>ufuncs also take additional arguments, like:</h3></p><p></p><p><code><h3>where</h3></code><h3> boolean array or condition defining where the operations should take place.</h3></p><p><code><h3>dtype</h3></code><h3> defining the return type of elements.</h3></p><p><code><h3>out</h3></code><h3> output array where the return value should be copied.</h3></p><p></p><p></p><p>Addition using <strong>zip()</strong> method in python:</p><p></p><p><div class="codebox"><pre>x = [<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>]<br />y = [<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>]<br />z = []<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> i, j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">zip</span>(x, y):<br />  z.append(i + j)<br /><span style="color:#ff9d00;font-weight:700">print</span>(z)</pre></div></p><p></p><p></p><p></p><p><h2>How To Create Your Own ufunc</h2></p><p><h3>To create your own ufunc, you have to define a function, like you do with normal functions in Python, then you add it to your NumPy ufunc library with the </h3><code><h3>frompyfunc()</h3></code><h3> method.</h3></p><p><h3>The </h3><code><h3>frompyfunc()</h3></code><h3> method takes the following arguments:</h3><ol><li><em><code>function</code></em></li><li>the name of the function.</p><p>2. <em><code>inputs</code></em></li><li>the number of input arguments (arrays).</p><p>3. <em><code>outputs</code></em></li></ol> - the number of output arrays.</p><p></p><p><h2>Create your own ufunc </h2><strong><h2>for</h2></strong><h2> addition:</h2></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myadd</span>(x, y):<br />  <span style="color:#ff9d00;font-weight:700">return</span> x+y<br /><br />myadd = np.frompyfunc(myadd, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">1</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(myadd([<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">4</span>], [<span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>]))</pre></div></p></div><div class='page'><h1 class='title level-1'>Data Analysis with Python</h1><br/><p><h2>Getting Started with Pandas</h2></p><p></p><p><strong>Pandas</strong><h3> is an open-source library that is built on top of NumPy library. It is a Python package that offers various data structures and operations for manipulating numerical data and time series. It is mainly popular for importing and analyzing data much easier. Pandas is fast and it has high-performance &amp; productivity for users.</h3></p><p></p><p><h3>Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). The axis labels are collectively called </h3><em>index</em><h3>. Pandas Series is nothing but a column in an excel sheet.</h3></p><p><h3>Labels need not be unique but must be a hashable type. The object supports both integer and label-based indexing and provides a host of methods for performing operations involving the index</h3></p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/dataSER-1.png"><img src="images/20-1.png" alt="images/20-1.png" /></a></p></div><div class='page'><h1 class='title level-2'>Getting Started with Pandas</h1><br/><p></p><p><h2>																														</h2><strong><h2>GETTING STARTED</h2></strong></p><p></p><p><h4>Creating a Pandas Series</h4></p><p></p><p><h3>In the real world, a Pandas Series will be created by loading the datasets from existing storage, storage can be SQL Database, CSV file, and Excel file.</h3></p><p><h3> Pandas Series can be created from the lists, dictionary, and from a scalar value etc. Series can be created in different ways, here are some ways by which we create a series:</h3></p><p></p><p><strong><h3>Creating a series from array:</h3></strong><h3> In order to create a series from array, we have to import a numpy module and have to use array() function.</h3></p><p></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># import pandas as pd</span><br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br /><span style="color:#0088ff;font-weight:400"># import numpy as np</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br /><span style="color:#0088ff;font-weight:400"># simple array</span><br />data = np.array([<span style="color:#3ad900;font-weight:400">&#39;g&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;e&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;e&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;k&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;s&#39;</span>])<br /><br />ser = pd.Series(data)<br /><span style="color:#ff9d00;font-weight:700">print</span>(ser)<br /><br /><span style="color:#0088ff;font-weight:400">#pd.series(list/other datatype)</span><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />Output: <br /><br />0    g<br />1    e<br />2    e<br />3    k<br />4    s<br />dtype: object</span></pre></div></p><p></p><p></p><p><h2>Create Labels</h2></p><p><h3>With the </h3><code><h3>index</h3></code><h3> argument, you can name your own labels.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />a=[<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">23</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">5</span>]<br /><br />myvar = pd.Series(a, index = [<span style="color:#3ad900;font-weight:400">&quot;x&quot;</span>,<span style="color:#3ad900;font-weight:400">&quot;y&quot;</span>,<span style="color:#3ad900;font-weight:400">&quot;z&quot;</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(myvar)</pre></div></p><p></p><p>From a dictionary, keys becoming index labels</p><p>fills the rest of the data with NaN</p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />calories = {<span style="color:#3ad900;font-weight:400">&quot;day1&quot;</span>: <span style="color:#ff0044;font-weight:400">420</span>, <span style="color:#3ad900;font-weight:400">&quot;day2&quot;</span>: <span style="color:#ff0044;font-weight:400">380</span>, <span style="color:#3ad900;font-weight:400">&quot;day3&quot;</span>: <span style="color:#ff0044;font-weight:400">390</span>}<br /><br />myvar = pd.Series(calories, index = [<span style="color:#3ad900;font-weight:400">&quot;day1&quot;</span>, <span style="color:#3ad900;font-weight:400">&quot;day2&quot;</span>])<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(myvar)</pre></div></p><p></p></div><div class='page'><h1 class='title level-3'>Dataset Walkthrough</h1><br/><p><h2>Dataset Walkthrough</h2></p><p></p><p>read_csv</p><p></p><p></p><p><strong><h2>Syntax of read_csv() </h2></strong></p><p><em><strong><h3>Syntax: pd.read_csv</h3></strong></em><em><h3>(filepath_or_buffer, sep=’ ,’ , header=’infer’,  index_col=None, usecols=None, engine=None, skiprows=None, nrows=None) </h3></em></p><p><em><strong><h3>Parameters:</h3></strong></em><em><h3> </h3></em><ul><li><em><strong>filepath_or_buffer</strong></em><em>: It is the location of the file which is to be retrieved using this function. It accepts any string path or URL of the file.</em></li><li><em><strong>sep</strong></em><em>: It stands for separator, default is ‘, ‘ as in CSV(comma separated values).</em></li><li><em><strong>header</strong></em><em>: It accepts int, a list of int, row numbers to use as the column names, and the start of the data. If no names are passed, i.e., header=None, then,  it will display the first column as 0, the second as 1, and so on.</em></li><li><em><strong>usecols</strong></em><em>: It is used to retrieve only selected columns from the CSV file.</em></li><li><em><strong>nrows</strong></em><em>: It means a number of rows to be displayed from the dataset.</em></li><li><em><strong>index_col</strong></em><em>: If None, there are no index numbers displayed along with records.  </em></li><li><em><strong>skiprows</strong></em><em>: Skips passed rows in the new data frame.</em></li></ul></p><p></p><p><h3>If we want to see the data of a specific column we can store the dataset in a variable and print it enclosing the column name inside the square brackets.</h3></p><p></p><p><div class="codebox"><pre>df=pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;example1.csv&#39;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(df[<span style="color:#3ad900;font-weight:400">&#39;Magnitude&#39;</span>])</pre></div></p><p><span style="color:#3ad900;">&#39;&#39;&#39;</span></p><p><span style="color:#3ad900;">Output</span></p><p><span style="color:#3ad900;"></span></p><p><span style="color:#3ad900;">0        6.0</span></p><p><span style="color:#3ad900;">1        5.8</span></p><p><span style="color:#3ad900;">2        6.2</span></p><p><span style="color:#3ad900;">3        5.8</span></p><p><span style="color:#3ad900;">4        5.8</span></p><p><span style="color:#3ad900;">        ... </span></p><p><span style="color:#3ad900;">23407    5.6</span></p><p><span style="color:#3ad900;">23408    5.5</span></p><p><span style="color:#3ad900;">23409    5.9</span></p><p><span style="color:#3ad900;">23410    6.3</span></p><p><span style="color:#3ad900;">23411    5.5</span></p><p><span style="color:#3ad900;">Name: Magnitude, Length: 23412, dtype: float64</span></p><p></p><p><h3>If we want to select multiple columns we need to give double square brackets</h3></p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">print</span>(df[[<span style="color:#3ad900;font-weight:400">&#39;Magnitude&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;Latitude&#39;</span>]])<br /><br /><br /><br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />    Magnitude  Latitude<br />0            6.0   19.2460<br />1            5.8    1.8630<br />2            6.2  -20.5790<br />3            5.8  -59.0760<br />4            5.8   11.9380<br />...          ...       ...<br />23407        5.6   38.3917</span><br /><span style="color:#3ad900;font-weight:400">23408        5.5   38.3777<br />23409        5.9   36.9179<br />23410        6.3   -9.0283<br />23411        5.5   37.3973<br /><br />[23412 rows x 2 columns]&#39;&#39;&#39;</span></pre></div></p><p></p><p></p><p>Pandas will only return the first 5 rows and last 5 rows</p><p><strong>to_string()</strong> to print entire DataFrame</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;data.csv&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(df.to_string()) </pre></div></p><p></p><p></p><p><h2>max_rows</h2></p><p><h3>The number of rows returned is defined in Pandas option settings.</h3></p><p><h3>You can check your system&#39;s maximum rows with the </h3><code><h3>pd.options.display.max_rows</h3></code><h3> statement.</h3></p><p></p><p><h3>Example</h3></p><p><h3>Check the number of maximum returned rows:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(pd.options.display.max_rows) </pre></div></p><p></p></div><div class='page'><h1 class='title level-3'>DataFrame</h1><br/><p><h3>Data sets in Pandas are usually multi-dimensional tables, called DataFrames.</h3></p><p><h3>Series is like a column, a DataFrame is the whole table.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />data = {<br />  <span style="color:#3ad900;font-weight:400">&quot;calories&quot;</span>: [<span style="color:#ff0044;font-weight:400">420</span>, <span style="color:#ff0044;font-weight:400">380</span>, <span style="color:#ff0044;font-weight:400">390</span>],<br />  <span style="color:#3ad900;font-weight:400">&quot;duration&quot;</span>: [<span style="color:#ff0044;font-weight:400">50</span>, <span style="color:#ff0044;font-weight:400">40</span>, <span style="color:#ff0044;font-weight:400">45</span>]<br />}<br /><br />myvar = pd.DataFrame(data)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(myvar)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />   calories  duration<br />0       420        50</span><br /><span style="color:#3ad900;font-weight:400">1       380        40<br />2       390        45</span></pre></div></p><p></p><p><h3>Pandas</h3><strong> DataFrame.columns</strong><h3> attribute return the column labels of the given Dataframe.</h3></p><p></p><p><code>print(df.columns)</code></p><p></p><p><strong><h3>Output</h3></strong></p><p>Index([&#39;Date&#39;, &#39;Latitude&#39;, &#39;Longitude&#39;, &#39;Magnitude&#39;], dtype=&#39;object&#39;)</p><p></p><p>data label associated is index</p><p></p><p><strong>df.loc</strong>[]		- Locate column indexes and give column name</p><p></p><p><strong>df.drop</strong>()	- Delete column</p><p></p><p><div class="codebox"><pre>df.column.str.replace(<span style="color:#3ad900;font-weight:400">&quot;old_colun&quot;</span>,<span style="color:#3ad900;font-weight:400">&quot;new_column&quot;</span>)<br />df.rename()</pre></div></p></div><div class='page'><h1 class='title level-4'>Dataframe methods</h1><br/><p><table class="table"><tr><th>Property/Method</th><th>Description</th></tr><tr><td>abs()</td><td>Return a DataFrame with the absolute value of each value</td></tr><tr><td>add()</td><td>Adds the values of a DataFrame with the specified value(s)</td></tr><tr><td>add_prefix()</td><td>Prefix all labels</td></tr><tr><td>add_suffix()</td><td>Suffix all labels</td></tr><tr><td>agg()</td><td>Apply a function or a function name to one of the axis of the DataFrame</td></tr><tr><td>aggregate()</td><td>Apply a function or a function name to one of the axis of the DataFrame</td></tr><tr><td>align()</td><td>Aligns two DataFrames with a specified join method</td></tr><tr><td>all()</td><td>Return True if all values in the DataFrame are True, otherwise False</td></tr><tr><td>any()</td><td>Returns True if any of the values in the DataFrame are True, otherwise False</td></tr><tr><td>append()</td><td>Append new columns</td></tr><tr><td>applymap()</td><td>Execute a function for each element in the DataFrame</td></tr><tr><td>apply()</td><td>Apply a function to one of the axis of the DataFrame</td></tr><tr><td>assign()</td><td>Assign new columns</td></tr><tr><td>astype()</td><td>Convert the DataFrame into a specified dtype</td></tr><tr><td>at</td><td>Get or set the value of the item with the specified label</td></tr><tr><td>axes</td><td>Returns the labels of the rows and the columns of the DataFrame</td></tr><tr><td>bfill()</td><td>Replaces NULL values with the value from the next row</td></tr><tr><td>bool()</td><td>Returns the Boolean value of the DataFrame</td></tr><tr><td>columns</td><td>Returns the column labels of the DataFrame</td></tr><tr><td>combine()</td><td>Compare the values in two DataFrames, and let a function decide which values to keep</td></tr><tr><td>combine_first()</td><td>Compare two DataFrames, and if the first DataFrame has a NULL value, it will be filled with the respective value from the second DataFrame</td></tr><tr><td>compare()</td><td>Compare two DataFrames and return the differences</td></tr><tr><td>convert_dtypes()</td><td>Converts the columns in the DataFrame into new dtypes</td></tr><tr><td>corr()</td><td>Find the correlation (relationship) between each column</td></tr><tr><td>count()</td><td>Returns the number of not empty cells for each column/row</td></tr><tr><td>cov()</td><td>Find the covariance of the columns</td></tr><tr><td>copy()</td><td>Returns a copy of the DataFrame</td></tr><tr><td>cummax()</td><td>Calculate the cumulative maximum values of the DataFrame</td></tr><tr><td>cummin()</td><td>Calculate the cumulative minmum values of the DataFrame</td></tr><tr><td>cumprod()</td><td>Calculate the cumulative product over the DataFrame</td></tr><tr><td>cumsum()</td><td>Calculate the cumulative sum over the DataFrame</td></tr><tr><td>describe()</td><td>Returns a description summary for each column in the DataFrame</td></tr><tr><td>diff()</td><td>Calculate the difference between a value and the value of the same column in the previous row</td></tr><tr><td>div()</td><td>Divides the values of a DataFrame with the specified value(s)</td></tr><tr><td>dot()</td><td>Multiplies the values of a DataFrame with values from another array-like object, and add the result</td></tr><tr><td>drop()</td><td>Drops the specified rows/columns from the DataFrame</td></tr><tr><td>drop_duplicates()</td><td>Drops duplicate values from the DataFrame</td></tr><tr><td>droplevel()</td><td>Drops the specified index/column(s)</td></tr><tr><td>dropna()</td><td>Drops all rows that contains NULL values</td></tr><tr><td>dtypes</td><td>Returns the dtypes of the columns of the DataFrame</td></tr><tr><td>duplicated()</td><td>Returns True for duplicated rows, otherwise False</td></tr><tr><td>empty</td><td>Returns True if the DataFrame is empty, otherwise False</td></tr><tr><td>eq()</td><td>Returns True for values that are equal to the specified value(s), otherwise False</td></tr><tr><td>equals()</td><td>Returns True if two DataFrames are equal, otherwise False</td></tr><tr><td>eval</td><td>Evaluate a specified string</td></tr><tr><td>explode()</td><td>Converts each element into a row</td></tr><tr><td>ffill()</td><td>Replaces NULL values with the value from the previous row</td></tr><tr><td>fillna()</td><td>Replaces NULL values with the specified value</td></tr><tr><td>filter()</td><td>Filter the DataFrame according to the specified filter</td></tr><tr><td>first()</td><td>Returns the first rows of a specified date selection</td></tr><tr><td>floordiv()</td><td>Divides the values of a DataFrame with the specified value(s), and floor the values</td></tr><tr><td>ge()</td><td>Returns True for values greater than, or equal to the specified value(s), otherwise False</td></tr><tr><td>get()</td><td>Returns the item of the specified key</td></tr><tr><td>groupby()</td><td>Groups the rows/columns into specified groups</td></tr><tr><td>gt()</td><td>Returns True for values greater than the specified value(s), otherwise False</td></tr><tr><td>head()</td><td>Returns the header row and the first 10 rows, or the specified number of rows</td></tr><tr><td>iat</td><td>Get or set the value of the item in the specified position</td></tr><tr><td>idxmax()</td><td>Returns the label of the max value in the specified axis</td></tr><tr><td>idxmin()</td><td>Returns the label of the min value in the specified axis</td></tr><tr><td>iloc</td><td>Get or set the values of a group of elements in the specified positions</td></tr><tr><td>index</td><td>Returns the row labels of the DataFrame</td></tr><tr><td>infer_objects()</td><td>Change the dtype of the columns in the DataFrame</td></tr><tr><td>info()</td><td>Prints information about the DataFrame</td></tr><tr><td>insert()</td><td>Insert a column in the DataFrame</td></tr><tr><td>interpolate()</td><td>Replaces not-a-number values with the interpolated method</td></tr><tr><td>isin()</td><td>Returns True if each elements in the DataFrame is in the specified value</td></tr><tr><td>isna()</td><td>Finds not-a-number values</td></tr><tr><td>isnull()</td><td>Finds NULL values</td></tr><tr><td>items()</td><td>Iterate over the columns of the DataFrame</td></tr><tr><td>iteritems()</td><td>Iterate over the columns of the DataFrame</td></tr><tr><td>iterrows()</td><td>Iterate over the rows of the DataFrame</td></tr><tr><td>itertuples()</td><td>Iterate over the rows as named tuples</td></tr><tr><td>join()</td><td>Join columns of another DataFrame</td></tr><tr><td>last()</td><td>Returns the last rows of a specified date selection</td></tr><tr><td>le()</td><td>Returns True for values less than, or equal to the specified value(s), otherwise False</td></tr><tr><td>loc</td><td>Get or set the value of a group of elements specified using their labels</td></tr><tr><td>lt()</td><td>Returns True for values less than the specified value(s), otherwise False</td></tr><tr><td>keys()</td><td>Returns the keys of the info axis</td></tr><tr><td>kurtosis()</td><td>Returns the kurtosis of the values in the specified axis</td></tr><tr><td>mask()</td><td>Replace all values where the specified condition is True</td></tr><tr><td>max()</td><td>Return the max of the values in the specified axis</td></tr><tr><td>mean()</td><td>Return the mean of the values in the specified axis</td></tr><tr><td>median()</td><td>Return the median of the values in the specified axis</td></tr><tr><td>melt()</td><td>Reshape the DataFrame from a wide table to a long table</td></tr><tr><td>memory_usage()</td><td>Returns the memory usage of each column</td></tr><tr><td>merge()</td><td>Merge DataFrame objects</td></tr><tr><td>min()</td><td>Returns the min of the values in the specified axis</td></tr><tr><td>mod()</td><td>Modules (find the remainder) of the values of a DataFrame</td></tr><tr><td>mode()</td><td>Returns the mode of the values in the specified axis</td></tr><tr><td>mul()</td><td>Multiplies the values of a DataFrame with the specified value(s)</td></tr><tr><td>ndim</td><td>Returns the number of dimensions of the DataFrame</td></tr><tr><td>ne()</td><td>Returns True for values that are not equal to the specified value(s), otherwise False</td></tr><tr><td>nlargest()</td><td>Sort the DataFrame by the specified columns, descending, and return the specified number of rows</td></tr><tr><td>notna()</td><td>Finds values that are not not-a-number</td></tr><tr><td>notnull()</td><td>Finds values that are not NULL</td></tr><tr><td>nsmallest()</td><td>Sort the DataFrame by the specified columns, ascending, and return the specified number of rows</td></tr><tr><td>nunique()</td><td>Returns the number of unique values in the specified axis</td></tr><tr><td>pct_change()</td><td>Returns the percentage change between the previous and the current value</td></tr><tr><td>pipe()</td><td>Apply a function to the DataFrame</td></tr><tr><td>pivot()</td><td>Re-shape the DataFrame</td></tr><tr><td>pivot_table()</td><td>Create a spreadsheet pivot table as a DataFrame</td></tr><tr><td>pop()</td><td>Removes an element from the DataFrame</td></tr><tr><td>pow()</td><td>Raise the values of one DataFrame to the values of another DataFrame</td></tr><tr><td>prod()</td><td>Returns the product of all values in the specified axis</td></tr><tr><td>product()</td><td>Returns the product of the values in the specified axis</td></tr><tr><td>quantile()</td><td>Returns the values at the specified quantile of the specified axis</td></tr><tr><td>query()</td><td>Query the DataFrame</td></tr><tr><td>radd()</td><td>Reverse-adds the values of one DataFrame with the values of another DataFrame</td></tr><tr><td>rdiv()</td><td>Reverse-divides the values of one DataFrame with the values of another DataFrame</td></tr><tr><td>reindex()</td><td>Change the labels of the DataFrame</td></tr><tr><td>reindex_like()</td><td>??</td></tr><tr><td>rename()</td><td>Change the labels of the axes</td></tr><tr><td>rename_axis()</td><td>Change the name of the axis</td></tr><tr><td>reorder_levels()</td><td>Re-order the index levels</td></tr><tr><td>replace()</td><td>Replace the specified values</td></tr><tr><td>reset_index()</td><td>Reset the index</td></tr><tr><td>rfloordiv()</td><td>Reverse-divides the values of one DataFrame with the values of another DataFrame</td></tr><tr><td>rmod()</td><td>Reverse-modules the values of one DataFrame to the values of another DataFrame</td></tr><tr><td>rmul()</td><td>Reverse-multiplies the values of one DataFrame with the values of another DataFrame</td></tr><tr><td>round()</td><td>Returns a DataFrame with all values rounded into the specified format</td></tr><tr><td>rpow()</td><td>Reverse-raises the values of one DataFrame up to the values of another DataFrame</td></tr><tr><td>rsub()</td><td>Reverse-subtracts the values of one DataFrame to the values of another DataFrame</td></tr><tr><td>rtruediv()</td><td>Reverse-divides the values of one DataFrame with the values of another DataFrame</td></tr><tr><td>sample()</td><td>Returns a random selection elements</td></tr><tr><td>sem()</td><td>Returns the standard error of the mean in the specified axis</td></tr><tr><td>select_dtypes()</td><td>Returns a DataFrame with columns of selected data types</td></tr><tr><td>shape</td><td>Returns the number of rows and columns of the DataFrame</td></tr><tr><td>set_axis()</td><td>Sets the index of the specified axis</td></tr><tr><td>set_flags()</td><td>Returns a new DataFrame with the specified flags</td></tr><tr><td>set_index()</td><td>Set the Index of the DataFrame</td></tr><tr><td>size</td><td>Returns the number of elements in the DataFrame</td></tr><tr><td>skew()</td><td>Returns the skew of the values in the specified axis</td></tr><tr><td>sort_index()</td><td>Sorts the DataFrame according to the labels</td></tr><tr><td>sort_values()</td><td>Sorts the DataFrame according to the values</td></tr><tr><td>squeeze()</td><td>Converts a single column DataFrame into a Series</td></tr><tr><td>stack()</td><td>Reshape the DataFrame from a wide table to a long table</td></tr><tr><td>std()</td><td>Returns the standard deviation of the values in the specified axis</td></tr><tr><td>sum()</td><td>Returns the sum of the values in the specified axis</td></tr><tr><td>sub()</td><td>Subtracts the values of a DataFrame with the specified value(s)</td></tr><tr><td>swaplevel()</td><td>Swaps the two specified levels</td></tr><tr><td>T</td><td>Turns rows into columns and columns into rows</td></tr><tr><td>tail()</td><td>Returns the headers and the last rows</td></tr><tr><td>take()</td><td>Returns the specified elements</td></tr><tr><td>to_xarray()</td><td>Returns an xarray object</td></tr><tr><td>transform()</td><td>Execute a function for each value in the DataFrame</td></tr><tr><td>transpose()</td><td>Turns rows into columns and columns into rows</td></tr><tr><td>truediv()</td><td>Divides the values of a DataFrame with the specified value(s)</td></tr><tr><td>truncate()</td><td>Removes elements outside of a specified set of values</td></tr><tr><td>update()</td><td>Update one DataFrame with the values from another DataFrame</td></tr><tr><td>value_counts()</td><td>Returns the number of unique rows</td></tr><tr><td>values</td><td>Returns the DataFrame as a NumPy array</td></tr><tr><td>var()</td><td>Returns the variance of the values in the specified axis</td></tr><tr><td>where()</td><td>Replace all values where the specified condition is False</td></tr><tr><td>xs()</td><td>Returns the cross-section of the DataFrame</td></tr><tr><td>__iter__()</td><td>Returns an iterator of the info axes</td></tr></table></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Pandas Read JSON</h1><br/><p></p><p><h2>Read JSON</h2></p><p><h3>Big data sets are often stored, or extracted as JSON.</h3></p><p><h3>JSON is plain text, but has the format of an object, and is well known in the world of programming, including Pandas.</h3></p><p><h3>In our examples we will be using a JSON file called &#39;data.json&#39;.</h3></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />df=pandas.read_json(<span style="color:#3ad900;font-weight:400">&#39;data.json&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(df.to_string())</pre></div></p><p></p><p><h3>Load a Python Dictionary into a DataFrame:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />data = {<br />  <span style="color:#3ad900;font-weight:400">&quot;Duration&quot;</span>:{<br />    <span style="color:#3ad900;font-weight:400">&quot;0&quot;</span>:<span style="color:#ff0044;font-weight:400">60</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;1&quot;</span>:<span style="color:#ff0044;font-weight:400">60</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;2&quot;</span>:<span style="color:#ff0044;font-weight:400">60</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;3&quot;</span>:<span style="color:#ff0044;font-weight:400">45</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;4&quot;</span>:<span style="color:#ff0044;font-weight:400">45</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;5&quot;</span>:<span style="color:#ff0044;font-weight:400">60</span><br />  },<br />  <span style="color:#3ad900;font-weight:400">&quot;Pulse&quot;</span>:{<br />    <span style="color:#3ad900;font-weight:400">&quot;0&quot;</span>:<span style="color:#ff0044;font-weight:400">110</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;1&quot;</span>:<span style="color:#ff0044;font-weight:400">117</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;2&quot;</span>:<span style="color:#ff0044;font-weight:400">103</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;3&quot;</span>:<span style="color:#ff0044;font-weight:400">109</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;4&quot;</span>:<span style="color:#ff0044;font-weight:400">117</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;5&quot;</span>:<span style="color:#ff0044;font-weight:400">102</span><br />  },<br />  <span style="color:#3ad900;font-weight:400">&quot;Maxpulse&quot;</span>:{<br />    <span style="color:#3ad900;font-weight:400">&quot;0&quot;</span>:<span style="color:#ff0044;font-weight:400">130</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;1&quot;</span>:<span style="color:#ff0044;font-weight:400">145</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;2&quot;</span>:<span style="color:#ff0044;font-weight:400">135</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;3&quot;</span>:<span style="color:#ff0044;font-weight:400">175</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;4&quot;</span>:<span style="color:#ff0044;font-weight:400">148</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;5&quot;</span>:<span style="color:#ff0044;font-weight:400">127</span><br />  },<br />  <span style="color:#3ad900;font-weight:400">&quot;Calories&quot;</span>:{<br />    <span style="color:#3ad900;font-weight:400">&quot;0&quot;</span>:<span style="color:#ff0044;font-weight:400">409</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;1&quot;</span>:<span style="color:#ff0044;font-weight:400">479</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;2&quot;</span>:<span style="color:#ff0044;font-weight:400">340</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;3&quot;</span>:<span style="color:#ff0044;font-weight:400">282</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;4&quot;</span>:<span style="color:#ff0044;font-weight:400">406</span>,<br />    <span style="color:#3ad900;font-weight:400">&quot;5&quot;</span>:<span style="color:#ff0044;font-weight:400">300</span><br />  }<br />}<br /><br />df = pd.DataFrame(data)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(df) <br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Analyzing DataFrames</h1><br/><p></p><p><h1>Pandas - Analyzing DataFrames</h1></p><p></p><p></p><p><h2>Viewing the Data</h2></p><p></p><p><h3>The </h3><code><h3>head()</h3></code><h3> method returns the headers and a specified number of rows, starting from the top.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><br />df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;data.csv&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(df.head(<span style="color:#ff0044;font-weight:400">10</span>))</pre></div></p><p></p><p><h3>The </h3><code>tail()</code><h3> method returns the headers and a specified number of rows, starting from the bottom.</h3></p><p></p><p><h3>The DataFrames object has a method called </h3><code>info()</code><h3>, that gives you more information about the data set.</h3></p><p></p><p><div class="codebox"><pre><br />  &lt;<span style="color:#ff9d00;font-weight:700">class</span> <span style="color:#3ad900;font-weight:400">&#39;pandas.core.frame.DataFrame&#39;</span>&gt;<br />  RangeIndex: <span style="color:#ff0044;font-weight:400">169</span> entries, <span style="color:#ff0044;font-weight:400">0</span> to <span style="color:#ff0044;font-weight:400">168</span><br />  Data columns (total <span style="color:#ff0044;font-weight:400">4</span> columns):<br />   <span style="color:#0088ff;font-weight:400">#   Column    Non-Null Count  Dtype  </span><br />  ---  ------    --------------  -----  <br />   <span style="color:#ff0044;font-weight:400">0</span>   Duration  <span style="color:#ff0044;font-weight:400">169</span> non-null    int64  <br />   <span style="color:#ff0044;font-weight:400">1</span>   Pulse     <span style="color:#ff0044;font-weight:400">169</span> non-null    int64  <br />   <span style="color:#ff0044;font-weight:400">2</span>   Maxpulse  <span style="color:#ff0044;font-weight:400">169</span> non-null    int64  <br />   <span style="color:#ff0044;font-weight:400">3</span>   Calories  <span style="color:#ff0044;font-weight:400">164</span> non-null    float64<br />  dtypes: float64(<span style="color:#ff0044;font-weight:400">1</span>), int64(<span style="color:#ff0044;font-weight:400">3</span>)<br />  memory usage: <span style="color:#ff0044;font-weight:400">5.4</span> KB<br />  <span style="color:#ff0044;font-weight:700">None</span></pre></div></p></div><div class='page'><h1 class='title level-2'>Statistics</h1><br/><p><strong>np.mean(arr,axis)</strong></p><p></p><p></p><p></p><p><strong><h3>Weighted Average</h3></strong><ul><li>In weighted average, each quantity is assigned a weight, which is multiplied by the quantity to calculate the average. </li></ul></p><p></p><p><h3>For given quantities X</h3><sub>1</sub><h3>, X</h3><sub>2</sub><h3>, X</h3><sub>3</sub><h3>, X</h3><sub>4</sub><h3>, …… X</h3><sub>n</sub><h3>. Each associated with weights w</h3><sub>1</sub><h3>, w</h3><sub>2</sub><h3>, w</h3><sub>3</sub><h3>, w</h3><sub>4</sub><h3>, …… w</h3><sub>n</sub></p><p><em><strong>Weighted Average = ( w</strong></em><em><strong><sub>1</sub></strong></em><em><strong> × X</strong></em><em><strong><sub>1 </sub></strong></em><em><strong>+ w</strong></em><em><strong><sub>2</sub></strong></em><em><strong> × X</strong></em><em><strong><sub>2</sub></strong></em><em><strong> + w</strong></em><em><strong><sub>3</sub></strong></em><em><strong> × X</strong></em><em><strong><sub>3</sub></strong></em><em><strong> + w</strong></em><em><strong><sub>4</sub></strong></em><em><strong> × X</strong></em><em><strong><sub>4</sub></strong></em><em><strong> +…..+ w</strong></em><em><strong><sub>n</sub></strong></em><em><strong> × X</strong></em><em><strong><sub>n</sub></strong></em><em><strong>)/(w</strong></em><em><strong><sub>1</sub></strong></em><em><strong> + w</strong></em><em><strong><sub>2</sub></strong></em><em><strong> + w</strong></em><em><strong><sub>3 </sub></strong></em><em><strong>+ w</strong></em><em><strong><sub>4</sub></strong></em><em><strong> +…….+ w</strong></em><em><strong><sub>n</sub></strong></em><em><strong>)</strong></em></p><p><em>or</em></p><p><em><strong>W = ∑w</strong></em><em><strong><sub>i</sub></strong></em><em><strong> × x</strong></em><em><strong><sub>i</sub></strong></em><em><strong>/ ∑w</strong></em><em><strong><sub>i</sub></strong></em></p><p><em>or</em></p><p><em><strong>W = Sum of (Product of weights with their respective quantities)/ Sum of all the weights</strong></em></p><p><div class="codebox"><pre>arr=np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">9</span>])<br />weight=np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">6</span>])<br />np.average(arr,weights=weight)</pre></div></p><p></p><p><strong>numpy.median(arr, axis = None) : </strong><h3>Compute the median of the given data (array elements) along the specified axis.</h3></p><p></p><p><strong>Mode</strong></p><p></p><p><div class="codebox"><pre>arr=np.array([<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">9</span>])<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">collections</span> <span style="color:#333333;font-weight:400">import</span> Counter<br />count=Counter(arr)<br /><span style="color:#ff9d00;font-weight:700">print</span>(count.most_common(<span style="color:#ff0044;font-weight:400">1</span>) <span style="color:#0088ff;font-weight:400">#1 here means the first max one</span></pre></div></p><p></p><p><small>Standard Deviation and Variance</small></p><p><strong>Standard Deviation</strong></p><p><strong>What is Standard Deviation?</strong></p><p>Standard deviation is a metric that represents the amount to which various values of a statistical series tend to fluctuate or disperse from its mean or median. It describes how the values are distributed over the data sample and is a measure of the data points’ deviation from the mean. The square root of the variance of a sample, statistical population, random variable, data collection, or probability distribution is its standard deviation.</p><p><strong>Standard Deviation Formula</strong></p><p>The formula for sample standard deviation(s) is as follows:</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-3f5db381bd025a17650ff76db5431a35_l3.svg"><img src="images/50-1.png" alt="images/50-1.png" /></a></p><p><em>where,</em></p><p><em>x</em><em><sub>i</sub></em><em> = data values in the set</em></p><p><em> x̄ = mean of the data</em></p><p><em>N = number of data values</em></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">standard_deviation</span>(arr):<br />    mean=arr.mean()<br />    final_val=<span style="color:#ff0044;font-weight:400">0</span><br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />        val=(i-mean)**<span style="color:#ff0044;font-weight:400">2</span><br />        final_val+=val<br />    <span style="color:#ff9d00;font-weight:700">return</span> (final_val/<span style="color:#ff9d00;font-weight:700">len</span>(arr))**<span style="color:#ff0044;font-weight:400">0.5</span><br />  <br />values=np.array([<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">14</span>])<br />sd=standard_deviation(values)<br /><span style="color:#ff9d00;font-weight:700">print</span>(sd)<br /></pre></div></p><p></p><p></p><p><strong><h3>Variance</h3></strong></p><p><h3>Variance is defined as a measure of dispersion, a metric used to assess the variability of data around an average value. It is a statistical measurement used to determine the spread of values in a data collection in relation to the average or mean value. Variance is divided into two main categories: population variance and sample variance. The population variance is used to determine how each data point in a particular population fluctuates or is spread out, while the sample variance is used to find the average of the squared deviations from the mean.</h3></p><p><strong><h3>Formula</h3></strong></p><p><h3>The variance for a data set is denoted by the symbol σ</h3><sup>2</sup><h3>. For population data, its formula is equal to the sum of squared differences of data entries from the mean divided by the number of entries. While for sample data, we divide the numerator value by the difference between the number of entries and unity.</h3></p><p><em>If the data set is a sample the formula of variance is given by,</em></p><p><em><strong>σ</strong></em><em><strong><sup>2</sup></strong></em><em><strong> = ∑ (x</strong></em><em><strong><sub>i</sub></strong></em><em><strong> – x̄)</strong></em><em><strong><sup>2</sup></strong></em><em><strong>/(n – 1)</strong></em></p><p><em>where,</em></p><p><em>x̄ is the mean of data set.</em></p><p><em>∑ (x</em><em><sub>i</sub></em><em> – x̄)</em><em><sup>2</sup></em><em> is the sum of squares of difference of each observation from mean,</em></p><p><em>n is the total number of observations.</em></p><p><em>If we have a population data set, the formula is written as,</em></p><p><em><strong>σ</strong></em><em><strong><sup>2</sup></strong></em><em><strong> = ∑ (x</strong></em><em><strong><sub>i</sub></strong></em><em><strong> – x̄)</strong></em><em><strong><sup>2</sup></strong></em><em><strong>/n</strong></em></p><p></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">standard_deviation</span>(arr):<br />    mean=arr.mean()<br />    final_val=<span style="color:#ff0044;font-weight:400">0</span><br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> arr:<br />        val=(i-mean)**<span style="color:#ff0044;font-weight:400">2</span><br />        final_val+=val<br />    <span style="color:#ff9d00;font-weight:700">return</span> (final_val/<span style="color:#ff9d00;font-weight:700">len</span>(arr))**<span style="color:#ff0044;font-weight:400">0.5</span><br />  <br />values=np.array([<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">14</span>])<br />sd=standard_deviation(values)<br /><span style="color:#ff9d00;font-weight:700">print</span>(sd**<span style="color:#ff0044;font-weight:400">2</span>)<br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Normal Distribution</h1><br/><p><small>Normal Distribution</small></p><p><strong>Introduction –</strong></p><p>Whenever a random experiment is replicated, the Random Variable that equals the <strong>average</strong> (or total) result over the replicates tends to have a normal distribution as the number of replicates becomes <strong>large</strong>. It is one of the cornerstones of probability theory and statistics, because of the role it plays in the Central Limit Theorem, and because many real-world phenomena involve random quantities that are approximately normal (e.g., errors in scientific measurement). It is also known by other names such as- <strong>Gaussian Distribution</strong>, <strong>Bell shaped Distribution</strong>.</p><p></p><p><h3></h3></p><p><h3></h3><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/1-27.png"><img src="images/52-1.png" alt="images/52-1.png" /></a>It can be observed from the above graph that the distribution is symmetric about its center, which is also the mean (0 in this case). This makes the probability of events at equal deviations from the mean, equally probable. The density is highly centered around the mean, which translates to lower probabilities for values away from the mean.</p><p><strong><h3>Probability Density Function –</h3></strong></p><p><h3>The probability density function of the general normal distribution is given as-</h3></p><p></p><p><img src="images/52-2.png" alt="images/52-2.png" /></p><p><h3>In the above formula, all the symbols have their usual meanings,</h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a368fc9772d324df6b4289745364b44_l3.svg"><img src="images/52-3.png" alt="images/52-3.png" /></a>is the Standard Deviation and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-4.png" alt="images/52-4.png" /></a>is the Mean. It is easy to get overwhelmed by the above formula while trying to understand everything in one glance, but we can try to break it down into smaller pieces so as to get an intuition as to what is going on. The <strong>z-score</strong><h3> is a measure of how many standard deviations away a data point is from the mean. Mathematically,</h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-bd33d7dddd85347e1f4747ccbbc2458c_l3.svg"><img src="images/52-5.png" alt="images/52-5.png" /></a>The exponent of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-58b00876cf89fb43ba28577c5648b301_l3.svg"><img src="images/52-6.png" alt="images/52-6.png" /></a>in the above formula is the square of the z-score times<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e13467a89eb7eb5b41502dcc4c418306_l3.svg"><img src="images/52-7.png" alt="images/52-7.png" /></a></p><p></p><p><h3></h3></p><p><h3></h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-bd33d7dddd85347e1f4747ccbbc2458c_l3.svg"><img src="images/52-8.png" alt="images/52-8.png" /></a>The exponent of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-58b00876cf89fb43ba28577c5648b301_l3.svg"><img src="images/52-9.png" alt="images/52-9.png" /></a>in the above formula is the square of the z-score times<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e13467a89eb7eb5b41502dcc4c418306_l3.svg"><img src="images/52-10.png" alt="images/52-10.png" /></a>. This is actually in accordance to the observations that we made above. Values away from the mean have a lower probability compared to the values near the mean. Values away from the mean will have a higher z-score and consequently a lower probability since the exponent is negative. The opposite is true for values closer to the mean. This gives way for the <strong>68-95-99.7 rule</strong>, which states that the percentage of values that lie within a band around the mean in a normal distribution with a width of two, four and six standard deviations, comprise 68%, 95% and 99.7% of all the values. The figure given below shows this rule-<a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/2-13.png"><img src="images/52-11.png" alt="images/52-11.png" /></a>The effects of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-12.png" alt="images/52-12.png" /></a>and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a368fc9772d324df6b4289745364b44_l3.svg"><img src="images/52-13.png" alt="images/52-13.png" /></a>on the distribution are shown below. Here<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-14.png" alt="images/52-14.png" /></a>is used to reposition the center of the distribution and consequently move the graph left or right, and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a368fc9772d324df6b4289745364b44_l3.svg"><img src="images/52-15.png" alt="images/52-15.png" /></a>is used to flatten or inflate the curve-<a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/3-11.png"><img src="images/52-16.png" alt="images/52-16.png" /></a><strong>Expectation</strong> expectation <a href="https://www.geeksforgeeks.org/linearity-of-expectation/">click here</a> or expected value E[x] can be found by simply multiply the probability distribution function with x and integrate over all possible values Let ‘X’ be a normal distributed random variable with parameters<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-17.png" alt="images/52-17.png" /></a>ans<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9e21d3c6a03704e4162e470dd957dca6_l3.svg"><img src="images/52-18.png" alt="images/52-18.png" /></a>. we know that area or the region inside normal distribution curve is 1 (because probability is 1) therefore= 1<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-551de9fbf79caaacf44d1da0547eac05_l3.svg"><img src="images/52-19.png" alt="images/52-19.png" /></a>writing x as (x-<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-20.png" alt="images/52-20.png" /></a>) +<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-21.png" alt="images/52-21.png" /></a>yields<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-24962457d473164eecf2bb7221962361_l3.svg"><img src="images/52-22.png" alt="images/52-22.png" /></a>letting y = x-<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-be5d4c2c19a6cdf008a0e995c1d7a684_l3.svg"><img src="images/52-23.png" alt="images/52-23.png" /></a>�[�]=1�2�$∫−∞+∞�∗�−12(��)2��$+$�∗∫−∞+∞��(�)��$first one is symmetric about y-axis, hence value of that integral is 0.<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d22809aa7c9fdbe4cf78adfb9b30b2bb_l3.svg"><img src="images/52-24.png" alt="images/52-24.png" /></a>�[�]=0+�∗1therefore , <strong>expectation</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-b7695c34a692b7d6dff256a839c8d625_l3.svg"><img src="images/52-25.png" alt="images/52-25.png" /></a>variance =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9e21d3c6a03704e4162e470dd957dca6_l3.svg"><img src="images/52-26.png" alt="images/52-26.png" /></a><strong>standard deviation</strong> =</p><p><strong><h3>Standard Normal Distribution –</h3></strong></p><p><h3>In the General Normal Distribution, if the Mean is set to 0 and the Standard Deviation is set to 1, then the corresponding distribution obtained is called the Standard Normal Distribution. The Probability Density function now becomes-</h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f837ff69d82b3f67f53111e08450df7e_l3.svg"><img src="images/52-27.png" alt="images/52-27.png" /></a>The cumulative density function of normal distribution does not give a closed formula. Hence precomputed values formulated in tables are used wherever required. But these tables only contain data for the standard distribution. In order to find the cumulative probability for a general normal distribution, it is first standardized and then computed using the value tables. This is beneficial in two ways- 1. First, there needs to be only one table to compute probabilities for all normal distributions. 2. Second, the table size is limited to 40 to 50 rows and 10 columns. This is due 68-95-99.7 rule explained above, which says that values within 3 standard deviations of the mean account for 99.7% probability. So beyond X=3 (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fa7a067c21b2ad239209e1b90ed4836a_l3.svg"><img src="images/52-28.png" alt="images/52-28.png" /></a>) the probabilities are approximately 0.<a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/5-2.jpg"><img src="images/52-29.png" alt="images/52-29.png" /></a>       </p><p></p><p></p><p>                <a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/4-5.jpg"><img src="images/52-30.png" alt="images/52-30.png" /></a></p><p>                </p><p>If X is a normal random variable with E(X)= and V(X)=, </p><p>the random variable  is a normal random variable with E(Z)=0 and V(Z)=1. </p><p>That is, Z is a standard normal random variable.• <strong>Example –</strong><ul><li>uppose that the current measurements in a strip of wire are assumed to follow a normal distribution with a mean of 10 milliamperes and a variance of four (milliamperes). What is the probability that a measurement exceeds 13 milliamperes?</p><p>• <strong>Solution –</strong> Let X denote the current in milliamperes. The requested probability can be represented as P (X &gt; 13). Let Z = (X ? 10) 2. With the Normal Distribution now standardized, the probability P(X &gt; 13) = P(Z &gt; 1.5) can now be easily computed. Looking at the above table, first we find 1.5 in the X column, and then since there are no more digits of significance we look for 0.00 in the Y column. The corresponding cell gives us the value of</li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-48d202ed7f26cc1b48bcc854f490d7d6_l3.svg"><img src="images/52-31.png" alt="images/52-31.png" /></a>So,<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-20fcd68fda6f3a45beef5feb478f2fe1_l3.svg"><img src="images/52-32.png" alt="images/52-32.png" /></a></p><p></p><p><h3></h3></p><p><h3> </h3></p><p><h3> </h3></p><p><strong><h3>Expected value , variance , standard deviation</h3></strong><h3> The expected value of a standard normal random variable X is expected valuevariance</h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5835fae5f528bbab10aeaa2c3fd9215d_l3.svg"><img src="images/52-33.png" alt="images/52-33.png" /></a>standard deviation</p><p></p></div><div class='page'><h1 class='title level-2'>Data Preprocessing</h1><br/><p><small>Data Preprocessing - Removing Null Value Rows</small></p><p>While making a Data Frame from a csv file, many blank columns are imported as null value into the Data Frame which later creates problems while operating that data frame. Pandas isnull() and notnull() methods are used to check and manage NULL values in a data frame.</p><p> </p><p></p><p><h2>Dataframe.isnull()</h2></p><p><em><strong>Syntax: </strong></em><em>Pandas.isnull(“DataFrame Name”) or DataFrame.isnull()</em></p><p><em><strong>Parameters: </strong></em><em>Object to check null values for</em></p><p><em><strong>Return Type: </strong></em><em>Dataframe of Boolean values which are True for NaN values </em></p><p><em> </em></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />data = pd.read_csv(<span style="color:#3ad900;font-weight:400">&quot;googleplaystore.csv&quot;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(data.isnull().sum())<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />Output:<br /><br />App                  0<br />Category             0<br />Rating            1474<br />Reviews              0<br />Size                 0<br />Installs             0</span><br /><span style="color:#3ad900;font-weight:400">Type                 1<br />Price                0<br />Content Rating       1<br />Genres               0<br />Last Updated         0<br />Current Ver          8<br />Android Ver          3<br />dtype: int64</span></pre></div></p><p></p><p><h3>we can delete all the rows which are present in our dataframe with the help of </h3><strong>dropna()</strong><h3> function. Let us see the implementation of that now.</h3></p><p></p><p><div class="codebox"><pre>df = data.dropna()<br /><span style="color:#ff9d00;font-weight:700">print</span>(df.isnull().sum())<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />App               0<br />Category          0<br />Rating            0<br />Reviews           0<br />Size              0<br />Installs          0<br />Type              0<br />Price             0<br />Content Rating    0</span><br /><span style="color:#3ad900;font-weight:400">Genres            0<br />Last Updated      0<br />Current Ver       0<br />Android Ver       0<br />dtype: int64</span></pre></div></p><p></p><p><strong>df=pd.read_csv(&#39;&#39;)</strong></p><p><strong>df.head()</strong></p><p></p><p>print(df[&#39;Rating&#39;])</p><p></p><p><strong>Finding out the Average Rating</strong></p><p></p><p><div class="codebox"><pre>s=<span style="color:#ff0044;font-weight:400">0</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>]<br />	s+=i<br />s=<span style="color:#ff9d00;font-weight:700">int</span>(s)<br />a=s/<span style="color:#ff9d00;font-weight:700">len</span>(df[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>])<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;The average rating is&quot;</span> ,<span style="color:#ff9d00;font-weight:700">round</span>(a,<span style="color:#ff0044;font-weight:400">3</span>))</pre></div></p><p></p><p><strong><h3>Total Number of Unique Categories</h3></strong></p><p><h3> </h3></p><p><h3>We can use the </h3><strong><h3>unique()</h3></strong><h3> function to get all the unique values of </h3><strong><h3>Category</h3></strong><h3> column</h3></p><p></p><p><div class="codebox"><pre>df[<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>].unique()<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />array([&#39;ART_AND_DESIGN&#39;, &#39;AUTO_AND_VEHICLES&#39;, &#39;BEAUTY&#39;,<br />       &#39;BOOKS_AND_REFERENCE&#39;, &#39;BUSINESS&#39;, &#39;COMICS&#39;, &#39;COMMUNICATION&#39;,<br />       &#39;DATING&#39;, &#39;EDUCATION&#39;, &#39;ENTERTAINMENT&#39;, &#39;EVENTS&#39;, &#39;FINANCE&#39;,<br />       &#39;FOOD_AND_DRINK&#39;, &#39;HEALTH_AND_FITNESS&#39;, &#39;HOUSE_AND_HOME&#39;,<br />       &#39;LIBRARIES_AND_DEMO&#39;, &#39;LIFESTYLE&#39;, &#39;GAME&#39;, &#39;FAMILY&#39;, &#39;MEDICAL&#39;,<br />       &#39;SOCIAL&#39;, &#39;SHOPPING&#39;, &#39;PHOTOGRAPHY&#39;, &#39;SPORTS&#39;, &#39;TRAVEL_AND_LOCAL&#39;,<br />       &#39;TOOLS&#39;, &#39;PERSONALIZATION&#39;, &#39;PRODUCTIVITY&#39;, &#39;PARENTING&#39;, &#39;WEATHER&#39;,<br />       &#39;VIDEO_PLAYERS&#39;, &#39;NEWS_AND_MAGAZINES&#39;, &#39;MAPS_AND_NAVIGATION&#39;],<br />      dtype=object)</span></pre></div></p><p></p><p></p><p><h3>To get the total number of Unique values we can use the </h3><strong>nunique() </strong><h3>function.</h3></p><p></p><p><strong>Percentage of Free and Paid Apps</strong></p><p></p><p><div class="codebox"><pre>ff=f/<span style="color:#ff9d00;font-weight:700">len</span>(df[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>])*<span style="color:#ff0044;font-weight:400">100</span><br />ff=<span style="color:#ff9d00;font-weight:700">round</span>(ff,<span style="color:#ff0044;font-weight:400">2</span>)<br />pp=<span style="color:#ff0044;font-weight:400">100</span>-ff<br />pp=<span style="color:#ff9d00;font-weight:700">round</span>(pp,<span style="color:#ff0044;font-weight:400">2</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(f<span style="color:#3ad900;font-weight:400">&quot;A total of {ff}% of the apps are Free and {pp}% of the apps are paid&quot;</span>)</pre></div></p></div><div class='page'><h1 class='title level-3'>Data Analysis Automatic Categorical</h1><br/><p><strong>Total number of apps in each category</strong></p><p></p><p><div class="codebox"><pre>categories = {}<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> name <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Category].unique():</span><br />	ct = <span style="color:#ff0044;font-weight:400">0</span><br />	<span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>]:<br />		<span style="color:#ff9d00;font-weight:700">if</span>(i==name):<br />			ct+=<span style="color:#ff0044;font-weight:400">1</span><br />	categories[name] = ct<br />	<br /><span style="color:#ff9d00;font-weight:700">print</span>(categories)<br /><span style="color:#3ad900;font-weight:400">&#39;&#39;&#39;<br />{&#39;ART_AND_DESIGN&#39;: 65, &#39;AUTO_AND_VEHICLES&#39;: 85,</span><br /><span style="color:#3ad900;font-weight:400"> &#39;BEAUTY&#39;: 53, &#39;BOOKS_AND_REFERENCE&#39;: 231, &#39;BUSINESS&#39;: 460, <br /> &#39;COMICS&#39;: 60, &#39;COMMUNICATION&#39;: 387, &#39;DATING&#39;: 234, &#39;EDUCATION&#39;: 156, <br /> &#39;ENTERTAINMENT&#39;: 149, &#39;EVENTS&#39;: 64, &#39;FINANCE&#39;: 366, &#39;FOOD_AND_DRINK&#39;: 127, <br /> &#39;HEALTH_AND_FITNESS&#39;: 341, &#39;HOUSE_AND_HOME&#39;: 88, &#39;LIBRARIES_AND_DEMO&#39;: 85, &#39;LIFESTYLE&#39;: 382, &#39;GAME&#39;: 1144,<br />  &#39;FAMILY&#39;: 1972, &#39;MEDICAL&#39;: 463, &#39;SOCIAL&#39;: 295, &#39;SHOPPING&#39;: 260, &#39;PHOTOGRAPHY&#39;: 335, &#39;SPORTS&#39;: 384, &#39;TRAVEL_AND_LOCAL&#39;: 258, <br />  &#39;TOOLS&#39;: 843, &#39;PERSONALIZATION&#39;: 392, &#39;PRODUCTIVITY&#39;: 424, &#39;PARENTING&#39;: 60, &#39;WEATHER&#39;: 82, &#39;VIDEO_PLAYERS&#39;: 175, &#39;NEWS_AND_MAGAZINES&#39;: 283, <br />  &#39;MAPS_AND_NAVIGATION&#39;: 137, &#39;1.9&#39;: 1}</span></pre></div></p><p></p><p></p><p><strong><h2>Total number of apps in each Type</h2></strong></p><p></p><p><div class="codebox"><pre>types = {}<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> name <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>].unique():<br />    ct = <span style="color:#ff0044;font-weight:400">0</span><br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>]:<br />        <span style="color:#ff9d00;font-weight:700">if</span>(i == name):<br />            ct += <span style="color:#ff0044;font-weight:400">1</span><br />    types[name] = ct<br />    <br /><span style="color:#ff9d00;font-weight:700">print</span>(types)</pre></div></p><p></p><p></p><p><h2>Total number of apps in each Content Rating</h2></p><p></p><p><div class="codebox"><pre>content_rating = {}<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> name <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Content Rating&#39;</span>].unique():<br />    ct = <span style="color:#ff0044;font-weight:400">0</span><br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;Content Rating&#39;</span>]:<br />        <span style="color:#ff9d00;font-weight:700">if</span>(i == name):<br />            ct += <span style="color:#ff0044;font-weight:400">1</span><br />    content_rating[name] = ct<br />    <br /><span style="color:#ff9d00;font-weight:700">print</span>(content_rating)</pre></div></p></div><div class='page'><h1 class='title level-3'>Null Values Handling</h1><br/><p><h2>Null Values Handling - Numeric</h2></p><p></p><p></p><p><h3>we can handle the null values instead of dropping them.</h3></p><p></p><p><h3>So we can see we don&#39;t have a big dataset and there are NaN or null values present in almost every column. So now how would we handle them?</h3></p><p><strong><h3>SimpleImputer</h3></strong><h3> is a scikit-learn class which is helpful in handling the missing data in the predictive model dataset. It replaces the NaN values with a specified placeholder. </h3></p><p><h3>It is implemented by the use of the </h3><strong><h3>SimpleImputer()</h3></strong><h3> method which takes the following arguments :</h3></p><p><h3> It is implemented by the use of the </h3><strong><h3>SimpleImputer()</h3></strong><h3> method which takes the following arguments :</h3></p><p><h3> </h3></p><p><em><strong>missing_values </strong></em><em>: The missing_values placeholder which has to be imputed. By default is NaN </em></p><p><em><strong>strategy </strong></em><em>: The data which will replace the NaN values from the dataset. The strategy argument can take the values – ‘mean&#39;(default), ‘median’, ‘most_frequent’ and ‘constant’. </em></p><p><em><strong>fill_value </strong></em><em>: The constant value to be given to the NaN data using the constant strategy.  </em></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.impute</span> <span style="color:#333333;font-weight:400">import</span> SimpleImputer<br />imputer = SimpleImputer(missing_values = np.nan, strategy = <span style="color:#3ad900;font-weight:400">&#39;most_frequent&#39;</span>)<br />df.iloc[:,<span style="color:#ff0044;font-weight:400">1</span>:<span style="color:#ff0044;font-weight:400">3</span>]=imputer.fit_transform(df.iloc[:,<span style="color:#ff0044;font-weight:400">1</span>:<span style="color:#ff0044;font-weight:400">3</span>].values)</pre></div></p><p></p><p><h2>Null Values Handling - Categorical</h2></p><p></p><p><div class="codebox"><pre>imputer = SimpleImputer(missing_values = np.nan, strategy = <span style="color:#3ad900;font-weight:400">&#39;most_frequent&#39;</span>)<br />df.iloc[:,:]=imputer.fit_transform(df.iloc[:,:].values)</pre></div></p><p></p><p></p><p>																															<h2>Googleplaystore dataset</h2></p><p></p><p><h3>So we have a huge number of data which is null in the </h3><strong><h3>Rating </h3></strong><h3>column. We can drop the rows which are null but that would not be optimal because the number of data. is very much. So we are going to use the </h3><strong><h3>SimpleImputer </h3></strong><h3> and replace the null values with the mean of the Rating column.</h3></p><p><h3>Let&#39;s get started with the coding implementation now.</h3></p><p></p><p></p><p><div class="codebox"><pre>impute = SimpleImputer(missing_values = np.nan , strategy = <span style="color:#3ad900;font-weight:400">&#39;mean&#39;</span>)<br />df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ] =impute.fit_transform(df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ].values)<br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Data Analysis</h1><br/><p><h2>Data Analysis with Multiple Columns</h2></p><p></p><p><div class="codebox"><pre>impute = SimpleImputer(missing_values = np.nan , strategy = <span style="color:#3ad900;font-weight:400">&#39;mean&#39;</span>)<br />impute.fit(df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ].values)<br />df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ] = impute.transform(df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ].values)<br /><br />df = df.dropna()<br /><br />df=df.values</pre></div></p><p></p><p></p><p><strong><h2>Q1. How many free apps are there in ART_AND_DESIGN?</h2></strong></p><p></p><p><div class="codebox"><pre>c = <span style="color:#ff0044;font-weight:400">0</span><br /><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df:<br />    <span style="color:#ff9d00;font-weight:700">if</span>(i[<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#3ad900;font-weight:400">&#39;ART_AND_DESIGN&#39;</span> <span style="color:#ff9d00;font-weight:700">and</span> i[<span style="color:#ff0044;font-weight:400">6</span>] == <span style="color:#3ad900;font-weight:400">&#39;Free&#39;</span>):<br />        c += <span style="color:#ff0044;font-weight:400">1</span><br />        <br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;There are&quot;</span>,c,<span style="color:#3ad900;font-weight:400">&#39;free apps from ART_AND_DESIGN&#39;</span>)</pre></div></p><p></p><p></p><p><h2>Q4. List all the free apps with rating more then 4.5 and category is FAMILY?</h2></p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;*&quot;</span>*<span style="color:#ff0044;font-weight:400">100</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;        These are the free apps where Category is FAMILY with rating more than 4.5.&quot;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;*&quot;</span>*<span style="color:#ff0044;font-weight:400">100</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> df:<br />    <span style="color:#ff9d00;font-weight:700">if</span>(i[<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#3ad900;font-weight:400">&#39;FAMILY&#39;</span> <span style="color:#ff9d00;font-weight:700">and</span> i[<span style="color:#ff0044;font-weight:400">2</span>] &gt; <span style="color:#ff0044;font-weight:400">4.5</span> <span style="color:#ff9d00;font-weight:700">and</span> i[<span style="color:#ff0044;font-weight:400">6</span>] == <span style="color:#3ad900;font-weight:400">&#39;Free&#39;</span>):<br />        <span style="color:#ff9d00;font-weight:700">print</span>(i[<span style="color:#ff0044;font-weight:400">0</span>])<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;-&quot;</span>*<span style="color:#ff0044;font-weight:400">100</span>)<br /></pre></div></p><p></p><p><h2>Data Analysis using Conditions</h2></p><p></p><p>Q1-</p><p><div class="codebox"><pre>df_pr = df[df[<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>] == <span style="color:#3ad900;font-weight:400">&#39;ART_AND_DESIGN&#39;</span>]<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#ff9d00;font-weight:700">len</span>(df_pr[df_pr[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>] &gt; <span style="color:#ff0044;font-weight:400">4.5</span>]))</pre></div></p><p></p><p>List all free apps with rating more than 4.5 and family</p><p><div class="codebox"><pre>df_pr = df[df[<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>] == <span style="color:#3ad900;font-weight:400">&#39;FAMILY&#39;</span>]<br />df_pr = df_pr[df_pr[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>] &gt; <span style="color:#ff0044;font-weight:400">4.5</span>]<br /><br />df_pr[df_pr[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>] == <span style="color:#3ad900;font-weight:400">&#39;Free&#39;</span>]</pre></div></p><p><div class="codebox"><pre><br />df_pr = df[df[<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>] == ‘Family’]<br />df_pr = df[df[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>] &gt; <span style="color:#ff0044;font-weight:400">4.5</span>]<br /><span style="color:#ff9d00;font-weight:700">len</span>(df_pr[df_pr[Type]== ‘free’])</pre></div></p><p></p></div><div class='page'><h1 class='title level-3'>GroupBy</h1><br/><p><small>GroupBy in Pandas</small><ul><li>oupby is a pretty simple concept. We can create a grouping of categories and apply a function to the categories. It’s a simple concept but it’s an extremely valuable technique that’s widely used in data science. In real data science projects, you’ll be dealing with large amounts of data and trying things over and over, so for efficiency, we use Groupby concept. Groupby concept is really important because it’s ability to aggregate data efficiently, both in performance and the amount code is magnificent. Groupby mainly refers to a process involving one or more of the following steps they are: </p><p> </p><p>• <strong>Splitting :</strong></li><li>t is a process in which we split data into group by applying some conditions on datasets.</p><p>• <strong>Applying :</strong></li><li>t is a process in which we apply a function to each group independently</p><p>• <strong>Combining :</strong></li></ul> It is a process in which we combine different datasets after applying groupby and results into a data structure</p><p><ol><li> following image will help in understanding a process involve in Groupby concept. </p><p>1. Group the unique values from the Team column </li></ol></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/groupby1.png"><img src="images/57-1.png" alt="images/57-1.png" /></a><ol><li>. Now there’s a bucket for each group </li></ol></p><p> <a href="https://media.geeksforgeeks.org/wp-content/uploads/groupby3.png"><img src="images/57-2.png" alt="images/57-2.png" /></a><ol><li>Toss the other data into the buckets </li></ol></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/groupby2.png"><img src="images/57-3.png" alt="images/57-3.png" /></a><ol><li>Apply a function on the weight column of each bucket. </li></ol></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/groupby4.png"><img src="images/57-4.png" alt="images/57-4.png" /></a></p><p> </p><p> </p><p>Now let us see the implementation of this in our <strong><span style="text-decoration:underline;">googleplaystore </span></strong>dataset.</p><p>So let us see our dataset again before getting started.</p><p>Python3<div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.impute</span> <span style="color:#333333;font-weight:400">import</span> SimpleImputer<br /><br />df=pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;googleplaystore.csv&#39;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(df.head())</pre></div><strong>Output:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221119225104/Screenshot20221119at104648PM1.jpg"><img src="images/57-5.png" alt="images/57-5.png" /></a> </p><p></p><p></p><p>Let us handle the null values again before getting started.</p><p>Python3</p><p><div class="codebox"><pre>impute = SimpleImputer(missing_values = np.nan , strategy = <span style="color:#3ad900;font-weight:400">&#39;mean&#39;</span>)<br />impute.fit(df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ].values)<br />df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ] = impute.transform(df.iloc[ : , <span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#ff0044;font-weight:400">3</span> ].values)<br /><br />df = df.dropna()<br /> </pre></div></p><p></p><p></p><p><h3>Q1. Which category is having maximum average rating Descending order?</h3></p><p><div class="codebox"><pre>df.groupby(<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>).mean()[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>].sort_values(ascending=<span style="color:#ff0044;font-weight:400">False</span>)</pre></div></p><p></p><p><h3>Q2. How many paid apps are there in each category in Descending Order?</h3></p><p><div class="codebox"><pre>df_pr = df[df[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>] == <span style="color:#3ad900;font-weight:400">&#39;Paid&#39;</span>]<br />df_pr.groupby(<span style="color:#3ad900;font-weight:400">&#39;Category&#39;</span>).count()[<span style="color:#3ad900;font-weight:400">&#39;Type&#39;</span>].sort_values(ascending = <span style="color:#ff0044;font-weight:400">False</span>) </pre></div></p><p></p><p></p></div><div class='page'><h1 class='title level-1'>Tableau</h1><br/><p><ul><li><strong>Tableau: </strong></li><li>bleau is a very powerful data visualization tool that can be used by data analysts, scientists, statisticians, etc. to visualize the data and get a clear opinion based on the data analysis. Tableau is very famous as it can take in data and produce the required data visualization output in a very short time.</p><p>• <strong>Dashboard: </strong></li></ul>A dashboard could also a set of several views, letting you compare a selection of data simultaneously. For example, if you’ve got a group of views that you simply review a day, you’ll create a dashboard that displays all the views directly, instead of navigating to separate worksheets. Like worksheets, you access dashboards from tabs at the lowest of a workbook. Data in sheets and dashboards are connected; once you modify a sheet, any dashboards containing it change, and therefore the other way around. Both sheets and dashboards update with the newest available data from the info source.</p><p></p><p><h3>Dataset used in the given examples is </h3><strong><h3>Dataset</h3></strong><h3>.</h3></p><p><h3>For this we have to follow some steps:</h3></p><p><h3>Open the Tableau tool and connect a dataset into it. Drag and drop the one sheet of the connected dataset. Click on sheet1 to open the tableau worksheet. On clicking Sheet1 you will get whole dataset attributes on the left side and a worksheet for work.</h3></p><p><h3> </h3></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201010184446/t8.PNG"><img src="images/58-1.png" alt="images/58-1.png" /></a></p><p></p><p></p><p><small>CONTINUOUS DATA VS DISCRETE DATA</small></p><p>Tableau represents data differently in the view depending on whether the field is discrete (blue), or continuous (green). <em>Continuous</em> and <em>discrete</em> are mathematical terms. Continuous means &quot;forming an unbroken whole, without interruption&quot;; discrete means &quot;individually separate and distinct.&quot;</p><p>Green measuresand dimensionsare continuous. Continuous field values are treated as an infinite range. Generally, continuous fields add axes to the view.</p><p>Blue measuresand dimensionsare discrete. Discrete values are treated as finite. Generally, discrete fields add headers to the view.</p><p></p><p><h2> </h2></p><p></p><p><h2>Examples of continuous and discrete fields used in a view</h2></p><p>In the example on the left (below), because the Quantity field is set to Continuous, it creates a horizontal axis along the bottom of the view. The green background and the axis help you to see that it&#39;s a continuous field.</p><p>In the example on the right, the Quantity field has been set to Discrete. It creates horizontal headers instead of an axis. The blue background and the horizontal headers help you to see that it&#39;s discrete.</p><p></p><p></p><p></p><p><h3>A parameter is a workbook variable such as a number, date, or string that can replace a constant value in a calculation, filter, or reference line.</h3></p><p><h3> </h3></p><p><h3>You can even create a </h3><em><h3>dynamic</h3></em><h3> parameter that’s set to automatically refresh its current value (to the result of a single-value, view-independent calculation), list of values (based on a data source column), or range of values. This will happen each time the workbook is opened and Tableau connects to the data source referenced by the parameter, or whenever you select Refresh from the data source’s context menu.</h3></p><p><h3> </h3></p><p><h3>Parameters are useful when you want to add interactivity and flexibility to a report, or to experiment with what-if scenarios. Suppose you are unsure which fields to include in your view or which layout would work best for your viewers. You can incorporate parameters into your view to let viewers choose how they want to look at the data.</h3></p><p><h3> </h3></p><p><h3>When you use parameters, you need to tie them to the view in some way:</h3></p><p><h3>You can use parameters in calculations and calculated fields that are used in the view.</h3></p><p><h3>You can display the parameter control in the view for users to select parameters.</h3></p><p></p><p><small>MEASURE VS DIMENSION</small></p><p>When you connect to a new data source, Tableau assigns each field in the data source as dimension or measure in the Data pane, depending on the type of data the field contains. You use these fields to build views of your data.</p><p> </p><p><em>Dimensions</em> contain qualitative values (such as names, dates, or geographical data). You can use dimensions to categorize, segment, and reveal the details in your data. Dimensions affect the level of detail in the view.</p><p><em>Measures</em> contain numeric, quantitative values that you can measure. Measures can be aggregated. When you drag a measure into the view, Tableau applies an aggregation to that measure (by default).</p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Tableau data</h1><br/><p></p><p><small>CONTINUOUS DATA VS DISCRETE DATA</small></p><p>Tableau represents data differently in the view depending on whether the field is discrete (blue), or continuous (green). <em>Continuous</em> and <em>discrete</em> are mathematical terms. Continuous means &quot;forming an unbroken whole, without interruption&quot;; discrete means &quot;individually separate and distinct.&quot;</p><p>Green measuresand dimensionsare continuous. Continuous field values are treated as an infinite range. Generally, continuous fields add axes to the view.</p><p>Blue measuresand dimensionsare discrete. Discrete values are treated as finite. Generally, discrete fields add headers to the view.</p><p></p><p><h2> </h2></p><p></p><p><h2>Examples of continuous and discrete fields used in a view</h2></p><p>In the example on the left (below), because the Quantity field is set to Continuous, it creates a horizontal axis along the bottom of the view. The green background and the axis help you to see that it&#39;s a continuous field.</p><p>In the example on the right, the Quantity field has been set to Discrete. It creates horizontal headers instead of an axis. The blue background and the horizontal headers help you to see that it&#39;s discrete.</p><p></p><p></p><p></p><p><h3>A parameter is a workbook variable such as a number, date, or string that can replace a constant value in a calculation, filter, or reference line.</h3></p><p><h3> </h3></p><p><h3>You can even create a </h3><em><h3>dynamic</h3></em><h3> parameter that’s set to automatically refresh its current value (to the result of a single-value, view-independent calculation), list of values (based on a data source column), or range of values. This will happen each time the workbook is opened and Tableau connects to the data source referenced by the parameter, or whenever you select Refresh from the data source’s context menu.</h3></p><p><h3> </h3></p><p><h3>Parameters are useful when you want to add interactivity and flexibility to a report, or to experiment with what-if scenarios. Suppose you are unsure which fields to include in your view or which layout would work best for your viewers. You can incorporate parameters into your view to let viewers choose how they want to look at the data.</h3></p><p><h3> </h3></p><p><h3>When you use parameters, you need to tie them to the view in some way:</h3></p><p><h3>You can use parameters in calculations and calculated fields that are used in the view.</h3></p><p><h3>You can display the parameter control in the view for users to select parameters.</h3></p><p></p><p><small>MEASURE VS DIMENSION</small></p><p>When you connect to a new data source, Tableau assigns each field in the data source as dimension or measure in the Data pane, depending on the type of data the field contains. You use these fields to build views of your data.</p><p> </p><p><em>Dimensions</em> contain qualitative values (such as names, dates, or geographical data). You can use dimensions to categorize, segment, and reveal the details in your data. Dimensions affect the level of detail in the view.</p><p><em>Measures</em> contain numeric, quantitative values that you can measure. Measures can be aggregated. When you drag a measure into the view, Tableau applies an aggregation to that measure (by default).</p><p></p><p></p><p></p><p></p><p></p><p><strong><h3>A line chart, also referred to as a line graph or a line plot, connects a series of data points using a line. This chart type presents sequential values to help you identify trends. Most of the time, the x-axis (horizontal axis) represents a sequential progression of values. The y-axis (vertical axis) then tells you the values for a selected metric across that progression. This is a common chart and is great to use when you want to show data over time.</h3></strong></p><p><h3></h3></p><p><h3></h3><strong><h3>A line chart supports monitoring behavior in a set of data. These charts are useful for more than tracking change over time. They also help highlight differences and correlations within your data. Furthermore, a line chart can help a viewer make predictions about what might happen next.</h3></strong></p><p><h3></h3></p><p><h3></h3><strong><h3>Data that is measured in a continuous progression works well in a line chart format.</h3></strong></p><p></p><p><strong><h3>Use scatter plots to visualize relationships between numerical variables.</h3></strong></p><p><h3> </h3></p><p><strong><h3>In Tableau, you create a scatter plot by placing at least one measure on the Columns shelf and at least one measure on the Rows shelf. If these shelves contain both dimensions and measures, Tableau places the measures as the innermost fields, which means that measures are always to the right of any dimensions that you have also placed on these shelves.</h3></strong></p><p><h3> </h3></p><p><strong><h3>A scatter plot can use several mark types. By default, Tableau uses the shape mark type. Depending on your data, you might want to use another mark type, such as a circle or a square. </h3></strong></p><p><h3></h3></p><p><h3></h3></p></div><div class='page'><h1 class='title level-2'>Fundamentals of Tableau</h1><br/><p><small>ADD CALCULATED FIELDS</small></p><p><strong><h3>                                 ADD CALCULATED FIELDS</h3></strong></p><p><h3></h3></p><p><h3> </h3></p><p><h3>Sometimes your data source does not contain a field (or column) that you need for your analysis. For example, your data source might contain fields with values for Sales and Profit, but not for Profit Ratio. If this is the case, you can create a calculated field for Profit Ratio using data from the Sales and Profit fields.</h3></p><p><strong><h3>Step 1: Create the calculated field</h3></strong></p><p><h3>In a worksheet in Tableau, select </h3><strong><h3>Analysis &gt; Create Calculated Field.</h3></strong></p><p><h3>In the Calculation Editor that opens, give the calculated field a name.</h3></p><p><h3>In this example, the calculated field is called Profit Ratio.</h3></p><p></p><p><h2>Step 2: Enter a formula</h2></p><p><strong><h3>I</h3></strong><h3>n the Calculation Editor, enter a formula.</h3></p><p><h3>This example uses the following formula:</h3></p><p><h3>SUM([Profit])/SUM([Sales])</h3></p><p><h3>Formulas use a combination of functions, fields, and operators. </h3></p><p><h3>When finished, click OK.</h3></p><p><h3></h3></p><p><h3>The new calculated field is added to the Data pane. If the new field computes quantitative data, it is added to Measures. If it computes qualitative data, it is added to Dimensions.</h3></p><p><h3>You are now ready to use the calculated field in the view.</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Applying filter and Conditional Formatting</h1><br/><p><small>APPLYING FILTER TO PLOT</small></p><p><h3> </h3></p><p><strong><h3>EXTRACT FILTER</h3></strong></p><p><h3>Extracts are saved subsets of data that you can use to improve performance or to take advantage of Tableau functionality not available or supported in your original data</h3></p><p><h3></h3></p><p><h3>When you create an extract of your data, you can reduce the total amount of data by using filters and configuring other limits. After you create an extract, you can refresh it with data from the original data. When refreshing the data, you have the option to either do a full refresh, which replaces all of the contents in the extract, or you can do an incremental refresh, which only adds rows that are new since the previous refresh.</h3></p><p></p><p></p><p><h3>Extracts are advantageous for several reasons:</h3></p><p><strong><h3>Supports large data sets</h3></strong><h3>: You can create extracts that contain billions of rows of data.</h3></p><p><strong><h3>Help improve performance</h3></strong><h3>: When you interact with views that use extract data sources, you generally experience better performance than when interacting with views based on connections to the original data.</h3></p><p><strong><h3>Support additional functionality</h3></strong><h3>: Extracts allow you to take advantage of Tableau functionality that&#39;s not available or supported by the original data, such as the ability to compute Count Distinct.</h3></p><p><h3></h3></p><p><h3> </h3></p><p><strong><h3>QUICK FILTER</h3></strong></p><p><h3></h3></p><p><h3> </h3></p><p><h3>In Tableau, many filter types are quickly available using the right-click option on the measure and dimension. These filters have enough functionality to solve most of the everyday filtering needs. These filters are known as Quick filters.</h3></p><p></p><p></p><p><small>CONDITIONAL FORMATTING</small></p><p><h3>Tableau </h3><strong><h3>Conditional Formatting</h3></strong><h3> is one of the most widely used methods for quickly classifying data. As the name implies, color-coding is the most important aspect of Tableau </h3></p><p><h3>Conditional Formatting data analysis tool, and it essentially means formatting data values based on certain conditions.</h3></p><p></p><p></p><p><h3>Tableau </h3><strong><h3>Conditional Formatting</h3></strong><h3> has features that enable the concept to be applied even to graphs, making visualizations more interactive and communicative.</h3></p><p><h3>Tableau Conditional Formatting is a good way to draw attention to textual information. Color and Symbols are two common examples of Tableau Conditional Formatting. When you use conditional formatting in Tableau visualizations, you can quickly highlight important data.</h3></p><p></p><p><h3>Modifying</h3><strong><h3> Rows &amp; Columns</h3></strong><h3> helps you get a better understanding of data and helps you get the information you need. Rows &amp; Columns can be modified easily using Tableau Conditional Formatting feature.</h3></p><p></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Data Hierarchy</h1><br/><p><h2>DATA HIERARCHY</h2></p><p>When you connect to a data source, Tableau automatically separates date fields into hierarchies so you can easily break down the visualization. You can also create your own custom hierarchies. For example, if you have a set of fields named Region, State, and County, you can create a hierarchy from these fields so that you can quickly drill down between levels in the visualization.</p><p> </p><p>To create a hierarchy:</p><p>     1.  In the Data pane, drag a field and drop it directly on top of another field.</p><p>     2.  When prompted, enter a name for the hierarchy and click <strong>OK</strong>.</p><p>     3.  Drag additional fields into the hierarchy as needed. You can also reorder fields in the hierarchy by dragging them to a               new position.</p><p></p><p> </p><p>When you add a field from a hierarchy to the visualization, you can quickly drill up or down in the hierarchy to add or subtract more levels of detail.</p><p></p><p></p></div><div class='page'><h1 class='title level-3'>MARKS</h1><br/><p><h2>ENCODING TO MARKS</h2></p><p></p><p></p><p></p><p><h3>he Marks Cards in Tableau provide some of the most powerful functionality in the program because they allow you to modify a view’s design, visualization type, user experience, and granularity of analysis all in one place.</h3></p><p></p><p><h3>You use the Marks card to set the mark type , and to encode your data with color, size, shape, text, and detail. </h3></p><p></p><p></p><p><h3>The Color, Size, and Shape Marks Cards all allow you to “encode” the marks on a view.</h3></p><p></p><p><h3>Encoding marks adds depth to an analysis by mapping marks to colors, sizes, and / or shapes to add context to a view.</h3></p><p><h3> </h3></p><p></p><p><h3>There are now three different legends corresponding with the encoding that was just added.</h3></p><p></p><p><h3>For consistency, this encoding will conveniently carry through on other views as they are created. For example, if we color a new view by the Segment dimension, Consumer will still be identified as blue, Corporate will still be identified as orange, and Home Office will still be identified as green.</h3></p><p></p><p><h3>These colors can be changed by clicking on the color legend and mapping new colors.</h3></p><p></p><p><h3>These three Marks Cards can also be used to change all the marks on the view instead of mapping to a specific dimension.</h3></p><p></p><p><h3>Instead of placing a dimension on the Marks Cards, click each card to experiment with changing the color, size, or shapes for all of the marks at the same time.</h3></p><p></p><p></p><p>Groups can be created to put useful data into groups for meaning. It can be done in data pane</p></div><div class='page'><h1 class='title level-3'>Highlighting</h1><br/><p><small>HIGHLIGHTING IN TABLEAU</small></p><p>Highlight actions allow you to call attention to marks of interest by coloring specific marks and dimming all others. You can highlight marks in the view using a variety of tools. For example, you can manually select the marks you want to highlight, use the legend to select related marks, use the highlighter to search for marks in context or create an advanced highlight action.</p><p>The following table describes the different methods you can use to highlight marks in a view, dashboard, or story.</p><p><table class="table"><tr><th>Highlight method</th><th>Benefits</th><th>When you might use this</th></tr><tr><td>Select marks</td><td>Manually select a group of marks to highlight in a view.</p><p>Your selection is saved with the workbook.</td><td>When you want to manually highlight a selection of marks and dim all others.</p><p>Works well with small domains or views with a small amount of data.</td></tr><tr><td>Legends</td><td>Supports one-way and two-way highlighting.</p><p>Highlight on color, size, or shape.</p><p>You can disable or enable the highlighting action for the workbook or sheets from the toolbar.</p><p>Your selection is saved with the workbook and can be included in dashboards and stories and when publishing.</td><td>When you want to focus on select members in a view and dim all others.</p><p>When you want to highlight using only the legend or the legend and the view.</p><p>Works well with small domains or views with a small amount of data.</td></tr><tr><td>Highlighter</td><td>Search for data points in a view using keywords or select from a drop-down list.</p><p>Highlight marks while maintaining the context of the other data points.</p><p>Values automatically update when the underlying data is updated.</p><p>Highlighters added to worksheets also appear on dashboards and stories.</td><td>When you want to highlight a mark or group of marks for a discrete field that is included in the view.</p><p>When you want to do ad hoc comparisons with instant highlighting.</p><p>Works well with large domains and large amounts of data.</td></tr><tr><td> </td><td> </td><td> </td></tr></table></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Need of Calculated Fields</h1><br/><p><h2>NEED OF CALCULATED FIELDS</h2><h2></h2></p><p><h2> </h2><ul><li>lculated fields allow you to create new data from data that already exists in your data source. When you create a calculated field, you are essentially creating a new field (or column) in your data source, the values or members of which are determined by a calculation that you control. </p><p>This new calculated field is saved to your data source in Tableau, and can be used to create more robust visualizations. But don&#39;t worry: your original data remains untouched.</p><p></p><p>You can use calculated fields for many, many reasons. Some examples might include:</p><p></p><p>• To segment data</li><li>To convert the data type of a field, such as converting a string to a date.</li><li>To aggregate data</li><li>To filter results</li><li>To calculate ratios</li></ul></p><p> <ul><li>ere are three main types of calculations you can use to create calculated fields in Tableau:</p><p>◇ <strong>Basic calculations </strong></li></ul>- Basic calculations allow you to transform values or members at the data source level of detail (a row-level calculation) or at the visualization level of detail (an aggregate calculation).</p><p><ul><li><strong>Level of Detail (LOD) expressions </strong>- Just like basic calculations,<span style="color:#8ff0a4;"> LOD calculations allow you to compute values at the data source level and the visualization level. However, LOD calculations give you even more control on the level of granularity you want to compute. </span></li></ul>They can be performed at a more granular level (INCLUDE), a less granular level (EXCLUDE), or an entirely independent level (FIXED) with respect to the granularity of the visualization.</p><p>.<ul><li><strong>Table calculations</strong></li></ul> - Table calculations allow you to transform values at the level of detail of the visualization only. </p><p></p><p></p><p><small>TABLE CALCULATION</small><ul><li>table calculation is a transformation you apply to the values in a visualization. </p><p></p><p>Table calculations are a special type of calculated field that computes the local data in Tableau. </p><p>They are calculated based on what is currently in the visualization and do not consider any measures or dimensions that are filtered out of the visualization.</p><p>You can use table calculations for a variety of purposes, including:</p><p>• Transforming values to rankings</li><li>Transforming values to show running totals</li><li>Transforming values to show percent of total</li></ul></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Labelling and Tooltip</h1><br/><p><small>LABELING AND TOOLTIP ADDITION</small></p><p><h3>The Label and Tooltip Marks Cards can both be used to add written information to a view. </h3></p><p><h3></h3></p><p><h3>The difference is that whatever information is added as a Label will show up on the view </h3></p><p><h3> any information added to the tooltips will only show up when an end user hovers over marks on the view.</h3></p><p><h3> </h3></p><p><h3>This is an important distinction that should be considered when you are authoring in Tableau.</h3></p><p><h3> </h3></p><p><h3>For example, if your visualization will be printed or copied and pasted as a screenshot, you would want to add the information to Label to ensure the information is shown on the view. On the other hand, if you know your end users will be interacting with Tableau, you may opt to save some on-screen real estate by providing the information through tooltips.</h3></p><p><h3> </h3></p><p><h3>As with the other Marks Cards, labels and tooltips can be customized with specific information by dragging and dropping fields onto the Label and Tooltip Marks Cards, respectively. You can click into each of these two Marks Cards to toggle them on and off, change the formatting, and even type in additional information.</h3></p><p></p><p><h3>The six Marks Cards introduced in this post can dramatically improve the depth, design, and user experience of your visualizations.</h3></p><p><h3> </h3></p><p><h3>Utilizing this functionality will not only help your analyses, it will make your final product more effective with end users.</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Sets</h1><br/><p><small>SETS IN TABLEAU</small></p><p></p><p><span style="color:#8ff0a4;">Sets in Tableau are used to create subsets of data based on certain conditions defined by the user. For example, a set can be created for having a subset of data of top 10 customers with the highest sales. </span></p><p><span style="color:#8ff0a4;"> </span></p><p><span style="color:#8ff0a4;">There are two types of sets: “dynamic set” and “fixed set”. In Tableau, sets can only be created based on dimension fields.</span></p><p></p><p><small>WAYS TO IMPLEMENT SETS</small></p><p></p><p><h2>Create a dynamic set</h2></p><p><h3>The members of a dynamic set change when the underlying data changes. Dynamic sets can only be based on a single dimension.</h3></p><p><h3>To create a dynamic set:</h3><ol><li>In the Data pane, right-click a dimension and select Create &gt; Set.</li><li>In the Create Set dialog box, configure your set. You can configure your set using the following tabs:</li></ol></p><p><h3>General: Use the General tab to select one or more values that will be considered when computing the set</h3></p><p><h3>                         Condition: Use the Condition tab to define rules that determine which members to include in the set.</h3></p><p><h3>                         Top: Use the Top tab to define limits on what members to include in the set.</h3></p><p></p><p><h2>Create a fixed set</h2></p><p><h3>The members of a fixed set do not change, even if the underlying data changes. A fixed set can be based on a single dimension or multiple dimensions.</h3></p><p><h3>To create a fixed set:</h3><ol><li>In the visualization, select one or more marks (or headers) in the view.</li><li>Right-click the mark(s) and select Create Set.</li><li>n the Create Set dialog box, type a name for the set.</li><li>Optionally complete any of the following:</li><li>By default, the set includes the members listed in the dialog box. You can select the option to Exclude these members instead. When you exclude, the set will include all of the members you didn&#39;t select.</li><li>Remove any dimensions that you don&#39;t want to be considered by clicking the red &quot;x&quot; icon that appears when you hover over a column heading.</li><li>Remove any specific rows that you don&#39;t want to include in the set by clicking the red &quot;x&quot; icon that appears when you hover over the row.</li><li>If the marks you selected represent multiple dimensions, each member of the set will be a combination of those dimensions. You can specify the character that separates the dimension values. To do so, for Separate members by, enter a character of your choice.</li><li>Select Add to Filters shelf to automatically move the set to the Filters shelf once it is created.</li></ol></p><p></p><p></p><p><h3>        5.  When finished, click</h3><strong><h3> OK</h3></strong><h3>.</h3></p><p><h3>             The new set is added to the bottom of the Data pane, under the Sets section. </h3></p><p><h3></h3></p><p><h3> </h3></p><p></p><p><h2>Add or remove data points from sets</h2></p><p><h3>If you created a set using specific data points, you can add more data to or subtract data from the set.</h3></p><p><h3>To add or remove data points from a set:</h3><ol><li>In the visualization, select the data points you want to add or remove.</li><li>In the tooltip that appears, click the Sets drop-down menu icon, and then select Add to [set name] or Remove from [set name] to add or remove data from a particular set.</li></ol></p><p></p><p><h3></h3></p><p><h3> </h3></p><p><h3>After you create a set, it displays at the bottom of the Data pane in the Sets section. You can drag it into the viz like any other field.</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Sparklines</h1><br/><p><small>SPARKLINES</small></p><p>A sparkline is a very small line chart, typically drawn without axes or coordinates. It presents the general shape of the variation (typically over time) in some measurement in a simple and highly condensed way.</p><p></p><p>Stock markets, size of economy, business performance and KPI dashboards are perfect places to make the best use of Sparklines.</p><p> </p><p></p><p><h2>to make sparklines in Tableau</h2></p><p>Step 1 – Place ‘Measure Names’, then ‘Measure Values’ on your ‘Rows’ shelf.</p><p>Step 2 – Place a date field on the ‘Columns’ shelf.</p><p>Step 3 – Reduce the width of the sparklines view to make the trends pop.</p><p>Step 4 – Remove irrelevant measures from your view.</p><p>Step 5 – Exclude zero from your axes or remove measures that have little to no fluctuation.</p><p>Step 6 – Hide axes and format your view</p><p></p></div><div class='page'><h1 class='title level-2'>Plotting graphs</h1><br/></div><div class='page'><h1 class='title level-3'>Bump Chart</h1><br/><p><h2>BUMP CHART</h2></p><p>A Bump Chart is used to compare two dimensions against each other using one of the Measure values. They are very useful for exploring the changes in Rank of a value over a time dimension or place dimension or some other dimension relevant to the analysis.</p><p></p><p>The Bump Chart takes two dimensions with zero or more measures.</p><p></p><p>Step 1 − Drag and drop YEAR to columns shelf. Add the Region to the colors mark.</p><p>Step 2 − Next, create a calculated field quick calculation rank. Go to Analysis → Create Calculated Field. </p><p>Step 3 − Drag Rank to the Rows shelf. The following chart appears which shows the dimension Sub-Category with each region arranged in an increasing order of their  ranks</p><p>Step 4 − Apply some more calculation to the rank field. Right click and choose edit in shelf to do so</p><p>Step 5 − Right click for discrete/continous and line mark for continuous</p><p></p></div><div class='page'><h1 class='title level-3'>Box and Whisker plots</h1><br/><p><small>BOX AND WHISKER PLOTS</small></p><p>Box and whisker plots, sometimes known as box plots, are a great chart to use when showing the distribution of data points across a selected measure. They display ranges within variables measured. </p><p>This includes the outliers, the median, the mode, and where the majority of the data points lie in the “box”. These visuals are helpful to compare the distribution of many variables against each other.</p><p> </p><p>Box and whisker plots portray the distribution of your data, outliers, and the median. The box within the chart displays around 50 percent of the data points. It summarizes a data set in five marks.</p><p></p><p> The mark with the greatest value is called the maximum. It will likely fall far outside the box. The mark with the lowest value is called the minimum. It will likely fall outside the box on the opposite side as the maximum.</p><p> </p><p>Use a box and whisker plot to show the distribution of data within a population. They allow for users to determine where the majority of the points land at a glance. They are even more useful when comparing distributions between members of a category in your data.</p><p> </p><p>Use a box and whisker plot when the desired outcome from your analysis is to understand the distribution of data points within a range of values. They also help you determine the existence of outliers within the dataset.</p><p></p></div><div class='page'><h1 class='title level-3'>Bubble chart</h1><br/><p><h3>bble charts display data as a cluster of circles. Each of the values in the dimension field represents a circle whereas the values of measure represent the size of those circles. As the values are not going to be presented in any row or column, you can drag the required fields to different shelves under the marks card.</h3></p><p></p><p><h2>Simple Bubble Chart</h2></p><p></p><p><h3>Using the Sample-superstore, let&#39;s plan to find the size of profits for different ship modes. To achieve this objective, following are the steps.</h3></p><p></p><p><h3>Step 1 − Drag and drop the Unit price into the Size shelf under Marks card.</h3></p><p><h3>Step 2 − Drag and drop the dimension Rep mode into the Labels shelf under Marks card.</h3></p><p><h3>Step 3 − Pull the dimension Rep to the Colors shelf under Marks card.</h3></p><p></p><p><img src="images/72-1.png" alt="images/72-1.png" /></p></div><div class='page'><h1 class='title level-3'>Bullet Graph</h1><br/><p><small>BULLET GRAPH</small></p><p><h3>A bullet graph is a bar marked with extra encodings to show progress towards a goal against a reference line.</h3></p><p><h3> Each bar focuses the user on one measure, bringing in more visual elements to provide additional detail.</h3></p><p><h3> </h3></p><p><h3>The bullet graph, designed by Stephen Few, replaces meters and gauges that dominated early dashboards and reports. It provides more information in a smaller space; making it ideal for a compact dashboard.</h3></p><p><h3></h3></p><p><h3>The bullet graph depicts a single primary measure. It includes measures from other fields to enhance the graphical display for analysis. One might display the current year’s revenue, measured against a goal, while contrasting it with performance from a previous year. </h3></p><p><h3></h3></p><p><h3>The axis measuring the data uses tick marks and labels to support analysis at a glance. Bullet graphs, being a form of bar chart, start at zero to support visual interpretation of the data.</h3></p><p><h3></h3></p><p><h3>If you have a target goal that you need to meet at a regular interval of time, a bullet graph will help display your goal, the current data set, and previous data sets all in one visualization. These bullet graphs can stand next to each other and display multiple data sets to provide a sweeping overview of how one system works. The bullet graph is not good for analyzing change-over-time, part-to-whole, flow, or distribution. </h3></p><p></p><p></p><p><img src="images/73-1.png" alt="images/73-1.png" /></p></div><div class='page'><h1 class='title level-3'>ChoroPleth Map</h1><br/><p><h2>CHOROPLETH MAP</h2></p><p></p><p>A Choropleth Map is a great option to represent <span style="color:#8ff0a4;">spatial variations of a quantity or amount in a given area.</span><ul><li> create a Choropleth Map, Tableau requires:</p><p>• A dimension with a Geographic role (e.g. Country)</li><li>Or a geometry contained in a Spatial file (e.g. Shapefile)</li></ul></p><p></p><p>A geographic field alone is not enough to create a meaningful choropleth map.</p><p>But it represents the first step.</p><p></p><p>After adding measures and dimensions, you can deduce helpful information from it.</p><p></p><p> </p><p></p></div><div class='page'><h1 class='title level-3'>Clustering in Tableau</h1><br/><p><h2>CLUSTERING IN TABLEAU</h2></p><p></p><p><h3>Cluster analysis partitions marks in the view into clusters, where the marks within each cluster are more similar to one another than they are to marks in other clusters.</h3></p><p><h3> </h3></p><p><strong><h3>Create clusters</h3></strong><ol><li>Create a view.</li><li>Drag Cluster from the Analytics pane into the view, and drop it on in the target area in the view.</li><li>Customize the cluster results by doing either of the following in the Clusters  dialog box.</li><li>When you finish customizing the cluster results, click the X in the upper-right corner of the Clusters dialog box to close it</li></ol></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Control Chart</h1><br/><p><h2>CONTROL CHART</h2></p><p></p><p><span style="color:#000000;"> </span><strong><span style="color:#000000;">Tableau control chart </span></strong><ol><li><span style="color:#000000;">a graph used to study how a process changes over time.  All processes have some variability.  That’s normal.  But large shifts or swings are cause for study and indicate something has changed about the way your process is behaving.  They are used to pinpoint sources of variation.</span></p><p><span style="color:#000000;"></span></p><p><span style="color:#000000;">Data are plotted in time order. A control chart always has a central line for the average, an upper line for the upper control limit, and a lower line for the lower control limit. These lines are determined from historical data and typically are based on standard deviations from the average or median line in the center. </span></p><p><span style="color:#000000;"> </span></p><p><span style="color:#000000;">TO CREATE</span></p><p><span style="color:#000000;">1. Create a line chart. </span></li><li><span style="color:#000000;">Add a </span><a href="https://datacrunchcorp.com/tableau-reference-lines/">reference line</a></li><li><span style="color:#000000;">y right clicking on the axis or on the Analytics pane at the left, and set it to be a Line, Per Pane, and set the value to Average (or Median if desired). </span></p><p><span style="color:#000000;">3. Right click on the axis again and add another reference line.  </span></li><li><span style="color:#000000;">Make this one a Distribution.  Set it to Standard Deviation.  Type in -3,3.  If that seems too wide, you can also choose either -1,1 or -2,2. </span></li><li><span style="color:#000000;">Click ok and look for any outliers in your data.</span></li></ol><span style="color:#000000;"></span></p><p><span style="color:#000000;"></span><span style="color:#000000;"></span></p><p><span style="color:#000000;"> </span></p><p></p><p></p><p></p><p> </p><p></p><p><img src="images/76-1.png" alt="images/76-1.png" /></p></div><div class='page'><h1 class='title level-3'>Donut Chart</h1><br/><p><small>DONUT CHART</small><span style="color:#000000;"></span></p><p><span style="color:#000000;"> </span></p><p><span style="color:#000000;">A donut chart is a hollow circular chart that is divided into multiple segments in proportion with the related values. In the center of it is an empty space where we can add labels showing a total value or a parameter as a whole so that you can instantly compare it with the segment values.</span></p><p><span style="color:#000000;"> </span></p><p><span style="color:#000000;"></span></p><p><span style="color:#000000;"></span><h2>How to Create a Donut Chart in Tableau?</h2><span style="color:#000000;"></span></p><p><span style="color:#000000;"></span></p><p><span style="color:#000000;">Step 1: Create Two Aggregate Measure Fields</span></p><p><span style="color:#000000;">Step 2: Select Mark Type for Measures</span></p><p><span style="color:#000000;">Step 3: Add Set of Fields to Get Pie Chart</span></p><p><span style="color:#000000;">Step 4: Select Circle from Drop-Down List</span></p><p><span style="color:#000000;">Step 5: Select Color Card to Change Circle Color</span></p><p><span style="color:#000000;">Step 6: Add Measure Field into Label Card</span></p><p><span style="color:#000000;">Step 7: Select Dual Axis to Combine Charts</span></p><p><span style="color:#000000;">Step 8: Click on Size Card to Reduce Size</span></p><p><span style="color:#000000;">Step 9: Finalize Tableau Donut Chart</span></p><p><span style="color:#000000;">Step 10: Change the Color Scheme of the Chart</span></p><p><span style="color:#000000;"></span></p><p><span style="color:#000000;"></span><a href="https://images.squarespace-cdn.com/content/v1/56fd706140261df95349d4bd/1483505449956-MEURM7Z5JPPH0K3LEAGD/Donut+Chart.png?format=1500w"><img src="images/77-1.png" alt="images/77-1.png" /></a></p></div><div class='page'><h1 class='title level-3'>Dual Axis Combo Chart</h1><br/><p><h2>DUAL - AXIS COMBO CHART</h2></p><p><h3>Combination charts are views that use multiple mark types in the same visualization. For example, you may show the sum of profit as bars with a line across the bars showing the sum of sales.</h3></p><p><h3></h3></p><p><h3> You can also use combination charts to show multiple levels of detail in the same view. For example, you can have a line chart with individual lines showing average sales over time for each customer segment, then you can have another line that shows the combined average across all customer segments.</h3></p><p><h3> </h3></p><p><h3>To create a combination chart, follow the steps below:</h3><ol><li>Open Tableau Desktop and connect to the Sample - Superstore data source.</li><li>Navigate to a new worksheet.</li><li>From the Data pane, drag <strong>Order Date</strong> to the <strong>Columns </strong></li><li>lf.</p><p>4. On the Columns shelf, right-click YEAR(Order Date) and select Month.</li><li>From the Data pane, drag Sales to the Rows shelf.</li><li>From the Data pane, drag Profit to the Rows shelf and place it to the right of SUM(Sales).</li><li>On the Rows shelf, right-click SUM(Profit) and select <strong>Dual-Axis</strong></li><li>. On the SUM(Profit) Marks card, click the Mark Type drop-down and select <strong>Bar</strong></li><li>. In the visualization, right-click the Profit axis and select <strong>Synchronize </strong></li></ol>Axis.</p><p></p><p><img src="images/78-1.png" alt="images/78-1.png" /></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p><h2>DUAL AXIS MAP</h2></p><p></p><p></p><p><h3> A dual-axis map is a map with two sets of geographic data overlaid on top of one another.For example, a filled map of U.S. states with data points for each city layered on top.</h3></p><p><h3>There are three ways to create a dual-axis map in Tableau:</h3><ul><li><a href="https://help.tableau.com/current/pro/desktop/en-us/maps_dualaxis.htm#generated">By using Tableau Latitude(generated) and Longitude(generated) fields</a></li><li><a href="https://help.tableau.com/current/pro/desktop/en-us/maps_dualaxis.htm#customonly">By using custom latitude and longitude fields</a></li><li><a href="https://help.tableau.com/current/pro/desktop/en-us/maps_dualaxis.htm#custom">By using a combination of Tableau Latitude(generated) and Longitude (generated) fields, and custom latitude and longitude fields</a></li></ul></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Dumbbell Chart</h1><br/><p><small>DUMBBELL CHART</small></p><p><h3>Tableau dumbbell charts, also known as DNA charts, are an alternative visualization choice for illustrating the change between two data points. </h3></p><p><h3>Tableau dumbbell charts are actually dual-axis combination charts, where one of the axes has a mark type of circle and the other has a mark type of line. </h3></p><p><h3> </h3></p><p><h3>TO CREATE </h3></p><p><h3>create a dot plot with the measure and dimension you want to visualize. </h3></p><p></p><p><h3> to create a second axis with the Sales measure and change its mark type to line. </h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Funnel Chart</h1><br/><p><h2>FUNNEL CHART</h2></p><p><h3>A tableau funnel chart is a type of visualization that represents linear workflows in decreasing order. It visually represents the progression of a business process and helps the user get a systematic view of various data values.</h3></p><p><h3> </h3></p><p><h3>How to create ?</h3><ol><li>Duplicate the measure you want to use to visualize with the funnel (customers, revenue, visits).</li><li>Put the two measures on the column shelf.</li><li>Reverse one of the two measure axis. You will find the option by double clicking on the X axis:</li><li>Add to the Rows shelf the dimension you want to use to split your funnel.</li><li>Don’t forget to customize your formatting to get rid of any lines—especially the column dividers and the Zero Line that would otherwise divide your funnel in two.</li></ol></p><p><h3>A funnel—also called a pipeline, a sales process or a cycle—can be used to bring significant clarity to your sales data. Whether you’re interested in identifying customers who are dropping out of the sales process, understanding your buyers’ purchase journey, or visualizing whether you have enough prospects to achieve a sales target, you can do it with a funnel.</h3></p><p></p><p></p><p><img src="images/87-1.png" alt="images/87-1.png" /></p></div><div class='page'><h1 class='title level-3'>Gantt Chart</h1><br/><p><small>GANTT CHART</small><ol><li>se Gantt charts to show the duration of events or activities.</p><p></p><p>In a Gantt chart, each separate mark (usually a bar) shows a duration. For example, you might use a Gantt chart to display average delivery time for a range of products.</p><p></p><p>To create a Gantt chart that shows how many days elapse on average between order date and ship date, follow these steps:</p><p></p><p>1. Connect to the Sample - Superstore data source.</li><li>Drag the Order Date dimension to Columns.</li></ol></p><p>Tableau aggregates the dates by year and creates column headers with labels for the years.<ol><li>On the Columns shelf, click the Year (Order Date) drop-down arrow, and then select Week Number.</li><li>Drag the Sub-Category and Ship Mode dimensions to the Rows shelf. Drop Ship Mode to the right of Sub-Category.</li><li></li><li>In the toolbar menu, click Analysis &gt; Create Calculated Field. You can also right-click (Control-click on Mac) any field in the Data pane and select Create &gt; Calculated Field.</li><li>In the calculation dialog box, name your calculated field OrderUntilShip.</li><li>Clear any content that&#39;s in the Formula box by default.</li><li>In the Formula box, enter the following formula and then click OK:</li></ol></p><p>DATEDIFF(&#39;day&#39;,[Order Date],[Ship Date])<ol><li> formula creates a custom measure that captures the difference between the Order Date and Ship Date values, in days.</p><p>9. Drag the OrderUntilShip measure to Size on the Marks card.</li></ol></p><p>The default aggregation for OrderUntilShip is Sum, but in this case it makes more sense to average the values.<ol><li>Right-click (Control-click on Mac) the SUM(OrderUntilShip) field on the Marks card, and then select Measure (Sum) &gt; Average.</li><li>Hold down the Ctrl key (Option key on the Mac) and drag the Week(Order Date) field from the Columns shelf to the Filter shelf.</li><li>In the Filter Field dialog box, select Range of Dates and then click Next.</li><li>Set the range to a three-month time interval, such as 1/1/2013 to 3/31/2013, and then click OK.</li><li>Drag the Ship Mode dimension to Color on the Marks card.</li></ol></p><p></p><p><img src="images/79-1.png" alt="images/79-1.png" /></p></div><div class='page'><h1 class='title level-3'>Heatmaps</h1><br/><p><h2>HEATMAPS</h2></p><p></p><p><h3>Tableau heatmap is a visualization where marks on the view are represented using color. And as the density of records increases per mark, a more intense color is displayed (heating up). When displayed as a crosstab – it forms a</h3><h3> </h3><h3>highlight table.</h3></p><p><h3> </h3></p><p><h3>the process of creating a heatmap requires,</h3><ul><li>One or more dimensions against One or two measures.</li><li>In this case using SAMPLE SUPERSTORE data, I will build my layout as follows,</li></ul></p><p><ul><li>Drag Order Date to the columns shelf.</li><li>Drag product Sub-Category to the rows shelf.</li><li>Drag Sales to the text shelf.</li><li>Under Show Me Tab, select ‘Heat Maps’</li></ul></p><p></p><p><img src="images/80-1.png" alt="images/80-1.png" /></p></div><div class='page'><h1 class='title level-3'>Histogram</h1><br/><p><small>HISTOGRAM</small></p><p>   </p><p>A histogram represents the frequencies of values of a variable bucketed into ranges. Histogram is similar to bar chart but it groups the values into continuous ranges. Each bar in histogram represents the height of the number of values present in that range.</p><p>Tableau creates a histogram by taking one measure. It creates an additional bin field for the measure used in creating a histogram.</p><p></p><p><h2>Creating a Histogram</h2></p><p>Using the Sample-superstore, plan to find the quantities of sales for different regions. To achieve this, drag the Measure named Quantity to the Rows shelf. Then open Show Me and select the Histogram chart. </p><p></p><p><h3>Creating a Histogram with Dimension</h3></p><p>You can also add Dimensions to Measures to create histograms. This will create a stacked histogram. Each bar will have stacks representing the values of the dimension. </p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Jitter Points</h1><br/><p><h2>JITTER POINTS</h2></p><p><h3>Jitter is a random value (or for our purposes pseudo-random) that is assigned to the dots to separate them so that they aren&#39;t plotted directly on top of each other. Tableau doesn&#39;t offer a check box, a built-in function, or a parameter to apply jitter, and there is no Tableau function to generate a random number.</h3></p><p><h3></h3></p><p><h3>You may want to spread the dots in your distribution when they are packed together to allow for easy reading of the dots that overlap. Using the jitter plot technique in this way allows you to separate marks or dots into different columns.</h3></p><p><h3> </h3></p><p><h3>When you’re working with geographic data, it is not advisable to use the jitter plot technique when the exact location of a mark is important to the analysis. If, for example, your data set is measuring when and where gas emissions were detected by a sensor, a jitter plot technique would move overlapping marks to a new point (i.e. the latitude and longitude).</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Pareto Chart</h1><br/><p><h2>PARETO CHART</h2></p><p><h3>A Pareto chart is a type of chart that contains both bars and a line graph, where individual values are represented in descending order by bars, and the ascending cumulative total is represented by the line. </h3></p><p><h3> </h3></p><p><h3>TO CREATE</h3><ol><li>Connect to the Sample - Superstore data source.</li><li>From the Data pane, drag Sub-Category to Columns, and then drag Sales to Rows.</li><li>Click Sub-Category on Columns and choose Sort.</li></ol></p><p></p><p></p><p><img src="images/83-1.png" alt="images/83-1.png" /></p></div><div class='page'><h1 class='title level-3'>Pie Chart</h1><br/><p><h2>PIE CHART</h2><ol><li>pie chart helps organize and show data as a percentage of a whole. </p><p></p><p>To create a pie chart view that shows how different product categories contribute to total sales, follow these steps:</p><p></p><p>1. Connect to the Sample - Superstore data source.</li><li>Drag the Sales measure to Columns and drag the Sub-Category dimension to Rows.</li><li>Click Show Me on the toolbar, then select the pie chart type.</li><li>Add labels by dragging the Sub-Category dimension from the Data pane to Label on the Marks card.</li></ol></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Stacked Area Chart</h1><br/><p><h2>STACKED  AREA CHART</h2><ol><li>area chart is a line chart where the area between the line and the axis are shaded with a color. These charts are typically used to represent accumulated totals over time and are the conventional way to display stacked lines.</p><p></p><p>To create an area chart, follow the steps below:</p><p>1. Open Tableau Desktop and connect to the Sample - Superstore data source.</li><li>Navigate to a new worksheet.</li><li>From the Data pane, drag Order Date to the Columns shelf.</li><li>On the Columns shelf, right-click YEAR(Order Date) and select Month.</li><li>From the Data pane, drag Quantity to the Rows shelf.</li><li>From the Date pane, drag Ship Mode to Color on the Marks card.</li><li>On the Marks card, click the Mark Type drop-down and select Area.</li></ol></p><p></p></div><div class='page'><h1 class='title level-3'>Symbol Map</h1><br/><p><h2>SYMBOL MAP</h2></p><p><h3>A symbol map leverages our ability to interpret information by overlaying quantitative values onto geographical locations using symbols. The symbol or symbols on a symbol map are often represented by a circle, however they can be any shape of icon.</h3></p><p><h3></h3></p><p><h3>The map contains symbols that represent values in a data set. These symbols can be of consistent size, shape and color or they can differ (in size, shape, or color) to represent variation of the data.</h3></p><p><h3></h3></p><p><h3>A symbol map can be used to show location or another form of data that can be applied to geographical locations. For example a symbol map to point out the cities that have been hit by hurricanes throughout a period of time with each symbol sized (scaled) to indicate the total number of hurricanes. </h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Treemap chart</h1><br/><p><h2>TREEMAP CHART</h2></p><p><h3>The treemap functions as a visualization composed of nested rectangles. These rectangles represent certain categories within a selected dimension and are ordered in a hierarchy, or “tree.” Quantities and patterns can be compared and displayed in a limited chart space. Treemaps represent part of a whole relationship.</h3></p><p><h3> </h3></p><p>T<h3>he largest box shows the largest part of the whole, while the smallest box shows the smallest part. For a deeper analysis, These boxes can be nested to show many categories. </h3></p><p><h3> </h3></p><p><h3>Treemaps best depict data that needs to show a part-to-whole relationship. Percentages of a measure for each dimension are displayed as squares that, when added together, comprise the whole. Using our Superstore dataset, we can divide the total number of sales into categories.</h3></p><p><h3></h3></p><p><h3> Adding the Product Sub-Category dimension would create “seating,” “tables,” and “lamps”. In this example, three specific items of furniture that fall under their respective categories become smaller nested squares.</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Waterfall chart</h1><br/><p><h2>WATERFALL CHART</h2></p><p>Waterfall charts effectively display the cumulative effect of sequential positive and negative values.</p><p> It shows where a value starts, ends and how it gets there incrementally. So, we are able to see both the size of changes and difference in values between consecutive data points.</p><p></p><p><h2>Creating a Waterfall Chart</h2></p><p></p><p>Using the Sample-superstore, plan to find the variation of Sales for each Sub-Category of Products.</p><p></p><p><strong>Step 1 </strong>− Drag the Dimension Sub-Category to the Columns shelf and the Measure Sales to the Rows shelf. Sort the data in an ascending order of sales value.</p><p><strong>Step 2 </strong>− Next, right-click on the SUM (Sales) value and select the running total from the table calculation option. Change the chart type to Gantt Bar. </p><p><strong>Step 3</strong> − Create a calculated field named -sales and mention the following formula for its value.</p><p><strong>Step 4</strong> − Drag the newly created calculated field (-sales) to the size shelf under Marks Card.</p><p></p></div><div class='page'><h1 class='title level-3'>Word Cloud</h1><br/><p>Word • <strong>World Cloud:</strong> A Word cloud, also referred to as a Tag cloud, may be a visual representation of text data, typically want to depict keyword metadata (tags) on websites or to see free morpheme text[Wikipedia]. Word clouds are a popular type of info-graphic with the assistance of which we will show the frequency of words in our data. This can be depicted either by the size or the color of the chosen fields in the data. They are a reasonably powerful feature to draw attention to your presentation or story.</p><p></p><p><h3>Dataset used in the given examples is </h3><strong><h3>Dataset</h3></strong></p><p><strong><h3>Steps to illustrate a Word Cloud in Tableau:</h3></strong><ul><li>Open Tableau tool and connect a dataset into it.</li><li>Drag and drop the one sheet of connected dataset.</li><li>Click on <em>Sheet1</em></li><li>o open the tableau worksheet.</p><p>◇ On clicking <em>Sheet1</em></li></ul> you will get whole dataset attributes on left side and a worksheet for work.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201009195419/t187.gif"><img src="images/91-1.png" alt="images/91-1.png" /></a></p></div><div class='page'><h1 class='title level-1'>Web Scraping</h1><br/><p><h2>What is Web Scraping and How to Use It</h2></p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20200622222131/What-is-Web-Scraping-and-How-to-Use-It.png"><img src="images/92-1.png" alt="images/92-1.png" /></a></p><p>Unlike the long and mind-numbing process of manually getting data, Web scraping uses intelligence automation methods to get thousands or even millions of data sets in a smaller amount of time. So let’s understand what Web scraping is in detail and how to use it to obtain data from other websites.</p><p></p><p><h3>What is Web Scraping?</h3></p><p>Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.</p><p></p><p></p><p>Web scraping requires two parts, namely the <strong>crawler</strong> and the <strong>scraper</strong>. The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. The scraper, on the other hand, is a specific tool created to extract data from the website. The design of the scraper can vary greatly according to the complexity and scope of the project so that it can quickly and accurately extract the data.</p><p></p><p></p></div><div class='page'><h1 class='title level-2'>To Scrape</h1><br/><p><h3>Why is Python a popular programming language for Web Scraping?</h3></p><p></p><p><a href="https://www.geeksforgeeks.org/python-programming-language/">Python</a><span style="color:#8ff0a4;"> seems to be in fashion these days! It is the most popular language for web scraping as it can handle most of the processes easily. It also has a variety of libraries that were created specifically for Web Scraping. </span><strong><a href="https://scrapy.org/">Scrapy</a></strong><span style="color:#8ff0a4;"> is a very popular open-source web crawling framework that is written in Python. It is ideal for web scraping as well as extracting data using APIs. </span><strong><a href="https://pypi.org/project/beautifulsoup4/">Beautiful soup</a></strong><span style="color:#8ff0a4;"> is another Python library that is highly suitable for Web Scraping. It creates a parse tree that can be used to extract data from HTML on a website. Beautiful soup also has multiple features for navigation, searching, and modifying these parse trees.</span></p><p></p><p><h3>What is Web Scraping used for?</h3><ol><li> Scraping has multiple applications across various industries. Let’s check out some of these now!</p><p></p><p><h4>1. Price Monitoring</h4></li></ol></p><p>Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.<ol><li>2. <h4>2. Market Research</h4></li></ol></p><p>Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. <ol><li>3. <h4>3. News Monitoring</h4></li></ol></p><p>Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!<ol><li>4. <h4>4. Sentiment Analysis</h4></li></ol></p><p>If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.<ol><li>5. <h4>5. Email Marketing</h4></li></ol></p><p>Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s</p></div><div class='page'><h1 class='title level-3'>Beautiful Soup</h1><br/><p><h1>Beautiful Soup</h1><ul><li>ere are mainly two ways to extract data from a website:</p><p></p><p>• Use the API of the website (if it exists). For example, Facebook has the Facebook Graph API which allows retrieval of data posted on Facebook.</li><li>Access the HTML of the webpage and extract useful information/data from it. This technique is called web scraping or web harvesting or web data extraction.</li></ul></p><p></p><p>This article discusses the steps involved in web scraping using the implementation of a Web Scraping framework of Python called Beautiful Soup.</p><p></p><p> <strong>Steps involved in web scraping:</strong><ol><li>Send an HTTP request to the URL of the webpage you want to access. The server responds to the request by returning the HTML content of the webpage. For this task, we will use a third-party HTTP library for python-requests.</li><li>Once we have accessed the HTML content, we are left with the task of parsing the data. Since most of the HTML data is nested, we cannot extract data simply through string processing. One needs a parser which can create a nested/tree structure of the HTML data. There are many HTML parser libraries available but the most advanced one is html5lib.</li><li>Now, all we need to do is navigating and searching the parse tree that we created, i.e. tree traversal. For this task, we will be using another third-party python library, <a href="http://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a></li></ol>. It is a Python library for pulling data out of HTML and XML files.</p><p><strong>Step 1: Installing the required third-party libraries</strong></p><p></p><p>pip install requests</p><p>pip install html5lib</p><p>pip install bs4</p><p></p><p><strong>Step 2: Accessing the HTML content from webpage</strong> </p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> requests<br />URL = <span style="color:#3ad900;font-weight:400">&quot;https://www.geeksforgeeks.org/data-structures/&quot;</span><br />r = requests.get(URL)<br /><span style="color:#ff9d00;font-weight:700">print</span>(r.content)</pre></div></p><p></p><p>This code works as : -</p><p></p><p>importing requests and requesting the HTTP for the given URL</p><p>r.content prints raw HTML content</p><p></p><p>“Not Accepted Error” : Adding a browser agent</p><p><h3>https://deviceatlas.com/blog/list-of-user-agent-strings</h3></p><p></p><p><div class="codebox"><pre>headers = {<span style="color:#3ad900;font-weight:400">&#39;User-Agent&#39;</span>: <span style="color:#3ad900;font-weight:400">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246&quot;</span>}<br /><span style="color:#0088ff;font-weight:400"># Here the user agent is for Edge browser on windows 10. You can find your browser user agent from the above given link.</span><br />r = requests.get(url=URL, headers=headers)<br /><span style="color:#ff9d00;font-weight:700">print</span>(r.content)</pre></div></p><p></p><p><strong>Step 3: Parsing the HTML content</strong><h3> </h3></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#This will not run on online IDE</span><br /><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br />  <br />URL = <span style="color:#3ad900;font-weight:400">&quot;http://www.values.com/inspirational-quotes&quot;</span><br />r = requests.get(URL)<br />  <br />soup = BeautifulSoup(r.content, <span style="color:#3ad900;font-weight:400">&#39;html5lib&#39;</span>) <span style="color:#0088ff;font-weight:400"># If this line causes an error, run &#39;pip install html5lib&#39; or install html5lib</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(soup.prettify())<br /></pre></div></p><p></p><p><strong>Step 4: Searching and navigating through the parse tree</strong></p><p><h3> Now, we would like to extract some useful data from the HTML content. The soup object contains all the data in the nested structure which could be programmatically extracted. In our example, we are scraping a webpage consisting of some quotes. So, we would like to create a program to save those quotes (and all relevant information about them). </h3></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Python program to scrape website </span><br /><span style="color:#0088ff;font-weight:400">#and save quotes from website</span><br /><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><span style="color:#333333;font-weight:400">import</span> csv<br />   <br />URL = <span style="color:#3ad900;font-weight:400">&quot;http://www.values.com/inspirational-quotes&quot;</span><br />r = requests.get(URL)<br />   <br />soup = BeautifulSoup(r.content, <span style="color:#3ad900;font-weight:400">&#39;html5lib&#39;</span>)<br />   <br />quotes=[]  <span style="color:#0088ff;font-weight:400"># a list to store quotes</span><br />   <br />table = soup.find(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, attrs = {<span style="color:#3ad900;font-weight:400">&#39;id&#39;</span>:<span style="color:#3ad900;font-weight:400">&#39;all_quotes&#39;</span>}) <br />    <br /><span style="color:#ff9d00;font-weight:700">for</span> row <span style="color:#ff9d00;font-weight:700">in</span> table.findAll(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>,<br />                         attrs = {<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>:<span style="color:#3ad900;font-weight:400">&#39;col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top&#39;</span>}):<br />    quote = {}<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;theme&#39;</span>] = row.h5.text<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;url&#39;</span>] = row.a[<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;lines&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;alt&#39;</span>].split(<span style="color:#3ad900;font-weight:400">&quot; #&quot;</span>)[<span style="color:#ff0044;font-weight:400">0</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;alt&#39;</span>].split(<span style="color:#3ad900;font-weight:400">&quot; #&quot;</span>)[<span style="color:#ff0044;font-weight:400">1</span>]<br />    quotes.append(quote)<br />   <br />filename = <span style="color:#3ad900;font-weight:400">&#39;inspirational_quotes.csv&#39;</span><br /><span style="color:#ff9d00;font-weight:700">with</span> <span style="color:#ff9d00;font-weight:700">open</span>(filename, <span style="color:#3ad900;font-weight:400">&#39;w&#39;</span>, newline=<span style="color:#3ad900;font-weight:400">&#39;&#39;</span>) <span style="color:#333333;font-weight:400">as</span> f:<br />    w = csv.DictWriter(f,[<span style="color:#3ad900;font-weight:400">&#39;theme&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;url&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;lines&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>])<br />    w.writeheader()<br />    <span style="color:#ff9d00;font-weight:700">for</span> quote <span style="color:#ff9d00;font-weight:700">in</span> quotes:<br />        w.writerow(quote)</pre></div><ul><li>It is noticed that all the quotes are inside a div container whose id is ‘all_quotes’. So, we find that div element (termed as table in above code) using <strong>find()</strong></li></ul> method :</p><p><ul><li>ble = soup.find(&#39;div&#39;, attrs = {&#39;id&#39;:&#39;all_quotes&#39;}) </p><p></p><p>◇ The first argument is the HTML tag you want to search and second argument is a dictionary type element to specify the additional attributes associated with that tag. <strong>find()</strong> method returns the first matching element. You can try to print <strong>table.prettify()</strong></li><li>o get a sense of what this piece of code does.</p><p>◇ </li><li>Now, in the table element, one can notice that each quote is inside a div container whose class is quote. So, we iterate through each div container whose class is quote. Here, we use findAll() method which is similar to find method in terms of arguments but it returns a list of all matching elements. Each quote is now iterated using a variable called <strong>row. </strong>Here is one sample row HTML content for better understanding:</li></ul><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200324205346/code-snippet.png"><img src="images/94-1.png" alt="images/94-1.png" /></a><ul><li></li><li>Now consider this piece of code:</li></ul></p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> row <span style="color:#ff9d00;font-weight:700">in</span> table.find_all_next(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, attrs = {<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>: <span style="color:#3ad900;font-weight:400">&#39;col-6 col-lg-3 text-center margin-30px-bottom sm-margin-30px-top&#39;</span>}):<br />    quote = {}<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;theme&#39;</span>] = row.h5.text<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;url&#39;</span>] = row.a[<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;lines&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;alt&#39;</span>].split(<span style="color:#3ad900;font-weight:400">&quot; #&quot;</span>)[<span style="color:#ff0044;font-weight:400">0</span>]<br />    quote[<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>] = row.img[<span style="color:#3ad900;font-weight:400">&#39;alt&#39;</span>].split(<span style="color:#3ad900;font-weight:400">&quot; #&quot;</span>)[<span style="color:#ff0044;font-weight:400">1</span>]<br />    quotes.append(quote)</pre></div><ul><li>We create a dictionary to save <strong><span style="color:#ff9d00;">all</span></strong>nformation about a quote. The nested structure can be accessed using dot notation. To access the text inside an HTML </p><p>    element, we use <strong>.text : </strong></li></ul></p><p><ul><li>ote[&#39;theme&#39;] = row.h5.text</p><p>◇ We can add, remove, modify and access a tag’s attributes. This is done by treating the tag as a dictionary:</li></ul></p><p></p><p>quote[&#39;url&#39;] = row.a[&#39;href&#39;</p><p>]◇ Lastly, all the quotes are appended to the list called <strong>quotes.</strong><ul><li>Finally, we would like to save all our data in some CSV file.</li></ul></p><p></p><p><div class="codebox"><pre>filename = <span style="color:#3ad900;font-weight:400">&#39;inspirational_quotes.csv&#39;</span><br /><span style="color:#ff9d00;font-weight:700">with</span> <span style="color:#ff9d00;font-weight:700">open</span>(filename, <span style="color:#3ad900;font-weight:400">&#39;w&#39;</span>, newline=<span style="color:#3ad900;font-weight:400">&#39;&#39;</span>) <span style="color:#333333;font-weight:400">as</span> f:<br />    w = csv.DictWriter(f,[<span style="color:#3ad900;font-weight:400">&#39;theme&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;url&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;lines&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>])<br />    w.writeheader()<br />    <span style="color:#ff9d00;font-weight:700">for</span> quote <span style="color:#ff9d00;font-weight:700">in</span> quotes:<br />		w.writerow(quote)</pre></div><ul><li>      \</p><p></p><p>◇ Here we create a CSV file called inspirational_quotes.csv and save all the quotes in it for any further use.</li></ul></p><p></p></div><div class='page'><h1 class='title level-3'>Scraping Multiple Pages</h1><br/><p><h1>Scraping Multiple Pages</h1></p><p></p><p><h2>Scraping multiple Pages of a website Using Python</h2><ul><li>w, there may arise various instances where you may want to get data from multiple pages from the same website or multiple different URLs as well, and manually writing code for each webpage is a time-consuming and tedious task. Plus, it defines all basic principles of automation. Duh!  </p><p>To solve this exact problem, we will see two main techniques that will help us extract data from multiple webpages:</p><p>• The same website</li><li>Different website URLs</li></ul></p><p></p><p><strong>Approach:</strong><ul><li>e approach of the program will be fairly simple, and it will be easier to understand it in a POINT format:</p><p>◇ We’ll import all the <strong>necessary libraries</strong></li><li>◇ Set up our URL strings for making a connection using the <strong>requests </strong></li><li>brary.</p><p>◇ Parsing the available data from the target page using the <strong>BeautifulSoup </strong></li><li>brary’s parser.</p><p>◇ From the target page, <strong>Identify </strong>and <strong>Extract </strong></li><li>e classes and tags which contain the information that is valuable to us.</p><p>◇ <strong>Prototype </strong></li></ul>it for one page using a loop and then apply it to all the pages.</p><p></p><p><strong>Example 1: Looping through the page numbers </strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210224143314/image20210224143314-660x68.png"><img src="images/95-1.png" alt="images/95-1.png" /></a><em>page numbers at the bottom of the GeeksforGeeks website</em></p><p></p><p>Most websites have pages labeled from 1 to N. This makes it really simple for us to loop through these pages and extract data from them as these pages have similar structures. For example:</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210224142442/image20210224142442-660x32.png"><img src="images/95-2.png" alt="images/95-2.png" /></a><em>notice the last section of the URL – page/4/</em></p><p></p><p>Here, we can see the page details at the end of the URL. Using this information we can easily create a <em><strong>for loop</strong></em> iterating over as many pages as we want (by putting <em><strong>page/(i)/</strong></em> in the URL string and iterating “<em>i</em>” <em>till N</em>) and scrape all the useful data from them. The following code will give you more clarity over how to scrape data by using a <strong>For Loop</strong> in Python.</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup <span style="color:#333333;font-weight:400">as</span> bs<br />  <br />URL = <span style="color:#3ad900;font-weight:400">&#39;https://www.geeksforgeeks.org/page/1/&#39;</span><br />  <br />req = requests.get(URL)<br />soup = bs(req.text, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br />  <br />titles = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>,attrs = {<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;head&#39;</span>})<br />  <br /><span style="color:#ff9d00;font-weight:700">print</span>(titles[<span style="color:#ff0044;font-weight:400">4</span>].text)</pre></div></p><p></p><p><strong><h3>Output:</h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210224230221/13-660x179.PNG"><img src="images/95-3.png" alt="images/95-3.png" /></a> </p><p></p><p><h3>Now, using the above code, we can get the titles of all the articles by just sandwiching those lines with a loop.</h3><ul><li>Python</li></ul></p><p></p><p> <div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup <span style="color:#333333;font-weight:400">as</span> bs  <br />URL = <span style="color:#3ad900;font-weight:400">&#39;https://www.geeksforgeeks.org/page/&#39;</span>  <br /><span style="color:#ff9d00;font-weight:700">for</span> page <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">10</span>):      <span style="color:#0088ff;font-weight:400"># pls note that the total number of    </span><br />	req = requests.get(URL + <span style="color:#ff9d00;font-weight:700">str</span>(page) + <span style="color:#3ad900;font-weight:400">&#39;/&#39;</span>)    <br />	soup = bs(req.text, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)      <br />	titles = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>,attrs={<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;head&#39;</span>})      <br />	<span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">19</span>):        <br />		<span style="color:#ff9d00;font-weight:700">if</span> page&gt;<span style="color:#ff0044;font-weight:400">1</span>:            <br />			<span style="color:#ff9d00;font-weight:700">print</span>(f<span style="color:#3ad900;font-weight:400">&quot;{(i-3)+page*15}&quot;</span> + titles[i].text)        <br />		<span style="color:#ff9d00;font-weight:700">else</span>:            <br />			<span style="color:#ff9d00;font-weight:700">print</span>(f<span style="color:#3ad900;font-weight:400">&quot;{i-3}&quot;</span> + titles[i].text)</pre></div></p><p><strong><h3>Output:</h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210227182552/image20210227182552-660x303.png"><img src="images/95-4.png" alt="images/95-4.png" /></a></p><p></p><p><strong><h3>Note:</h3></strong><h3> The above code will fetch the first 10 pages from the website and scrape all the 150 titles of the articles that fall under those pages. </h3></p><p><strong><h3>Example 2: Looping through a list of different URLs.</h3></strong></p><p></p><p><h3>to scrape different pages, and you don’t know their page numbers? You’ll need to scrape those different URLs one by one and manually code a script for every such webpage.</h3></p><p></p><p><h3>Instead, you could just make a list of these URLs and loop through them. By simply iterating the items in the list i.e. the URLs, we will be able to extract the titles of those pages without having to write code for each page. Here’s an example code of how you can do it.</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup <span style="color:#333333;font-weight:400">as</span> bs<br />URL = [<span style="color:#3ad900;font-weight:400">&#39;https://www.geeksforgeeks.org&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;https://www.geeksforgeeks.org/page/10/&#39;</span>]<br />  <br /><span style="color:#ff9d00;font-weight:700">for</span> url <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">2</span>):<br />    req = requests.get(URL[url])<br />    soup = bs(req.text, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br />  <br />    titles = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>,attrs={<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;head&#39;</span>})<br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">19</span>):<br />        <span style="color:#ff9d00;font-weight:700">if</span> url+<span style="color:#ff0044;font-weight:400">1</span>  &gt; <span style="color:#ff0044;font-weight:400">1</span>:<br />            <span style="color:#ff9d00;font-weight:700">print</span>(f<span style="color:#3ad900;font-weight:400">&quot;{(i - 3) + url * 15}&quot;</span> + titles[i].text)<br />        <span style="color:#ff9d00;font-weight:700">else</span>:<br />            <span style="color:#ff9d00;font-weight:700">print</span>(f<span style="color:#3ad900;font-weight:400">&quot;{i - 3}&quot;</span> + titles[i].text)</pre></div></p><p></p><p><strong><h3>Output:</h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210227183111/image20210227183110-660x359.png"><img src="images/95-5.png" alt="images/95-5.png" /></a></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Create Pandas DataFrame from Lists and saving it as CSV</h1><br/><p><h2>Create a Pandas DataFrame from Lists and Saving it as CSV</h2></p><p><strong>Creating a Pandas DataFrame</strong></p><p>Python is a great language for doing data analysis, primarily because of the fantastic ecosystem of data-centric python packages. Pandas is one of those packages and makes importing and analyzing data much easier.</p><p>Creating Pandas Dataframe can be achieved in multiple ways. Let’s see how can we create a Pandas DataFrame from Lists.</p><p></p><p><strong>Code #1:</strong> Basic example</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># import pandas as pd</span><br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />  <br /><span style="color:#0088ff;font-weight:400"># list of strings</span><br />lst = [<span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;For&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;is&#39;</span>, <br />            <span style="color:#3ad900;font-weight:400">&#39;portal&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;for&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>]<br />  <br /><span style="color:#0088ff;font-weight:400"># Calling DataFrame constructor on list</span><br />df = pd.DataFrame(lst)<br />df<br /></pre></div></p><p></p><p></p><p><strong>Output:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/df_from_list1.png"><img src="images/96-1.png" alt="images/96-1.png" /></a></p><p> </p><p><strong>Code #2:</strong> Dataframe using list with index and column names</p><p> </p><p> </p><p> <div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># import pandas as pd</span><br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />  <br /><span style="color:#0088ff;font-weight:400"># list of strings</span><br />lst = [<span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;For&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;is&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;portal&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;for&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;Geeks&#39;</span>]<br />  <br /><span style="color:#0088ff;font-weight:400"># Calling DataFrame constructor on list</span><br /><span style="color:#0088ff;font-weight:400"># with indices and columns specified</span><br />df = pd.DataFrame(lst, index =[<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;b&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;c&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;d&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;e&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;f&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;g&#39;</span>],<br />                                              columns =[<span style="color:#3ad900;font-weight:400">&#39;Names&#39;</span>])<br />df</pre></div></p><p></p><p><strong>Output:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/df_from_list2.png"><img src="images/96-2.png" alt="images/96-2.png" /></a></p><p></p><p><strong>Saving a DataFrame as CSV</strong></p><p></p><p><h3>Export CSV to a working directory</h3></p><p>Here, we simply export a Dataframe to a CSV file using df.to_csv().</p><p></p><p><div class="codebox"><pre>df.to_csv(<span style="color:#3ad900;font-weight:400">&#39;file1.csv&#39;</span>)</pre></div></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Scraping Quotes</h1><br/><p><h2>Scraping Quotes</h2></p><p> </p><p>Code</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br /><span style="color:#0088ff;font-weight:400"># Importing Important Libraries</span><br /><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><br />link = <span style="color:#3ad900;font-weight:400">&#39;https://books.toscrape.com/catalogue/page-1.html&#39;</span><br /><br /><span style="color:#0088ff;font-weight:400"># Sending a request to the website(link)</span><br />res = requests.get(link)<br /><br /><span style="color:#0088ff;font-weight:400"># Creating a soup using BeautifulSoup</span><br />soup = BeautifulSoup(res.text, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br /></pre></div></p><p><strong><span style="text-decoration:underline;">Scraping only Quotes and Authors Name</span></strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br />quotes = []<br /><span style="color:#ff9d00;font-weight:700">for</span> quote <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;text&#39;</span>):<br />    quotes.append(quote.text[<span style="color:#ff0044;font-weight:400">1</span>:-<span style="color:#ff0044;font-weight:400">1</span>])<br />    <span style="color:#ff9d00;font-weight:700">print</span>(quote.text[<span style="color:#ff0044;font-weight:400">1</span>:-<span style="color:#ff0044;font-weight:400">1</span>] + <span style="color:#3ad900;font-weight:400">&quot;\n&quot;</span>)<br /><br /><span style="color:#0088ff;font-weight:400"># Authors Name</span><br />authors = []<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;small&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>):<br />    authors.append(i.text)<br /></pre></div> </p><p><strong><span style="text-decoration:underline;">Code where we have extracted quotes, author name, details and tags</span></strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br /><span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;quote&#39;</span>):<br />    quote = sp.find(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;text&#39;</span>).text[<span style="color:#ff0044;font-weight:400">1</span>:-<span style="color:#ff0044;font-weight:400">1</span>]<br />    authors = sp.find(<span style="color:#3ad900;font-weight:400">&#39;small&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>).text<br />    details = sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br />    tags = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;tag&#39;</span>):<br />        tags.append(tag.text)<br />    tags = <span style="color:#3ad900;font-weight:400">&#39;,&#39;</span>.join(tags)<br />    <span style="color:#ff9d00;font-weight:700">print</span>(quote)<br />    <span style="color:#ff9d00;font-weight:700">print</span>(authors)<br />    <span style="color:#ff9d00;font-weight:700">print</span>(details)<br />    <span style="color:#ff9d00;font-weight:700">print</span>(tags)<br />    <span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;*&quot;</span>*<span style="color:#ff0044;font-weight:400">127</span>)<br /></pre></div> </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128204040/Screenshot202211282037271-1024x542.jpg"><img src="images/97-1.png" alt="images/97-1.png" /></a> </p><p><strong><span style="text-decoration:underline;">Creating a List </span></strong></p><p><div class="codebox"><pre>data = []<br /><span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;quote&#39;</span>):<br />    quote = sp.find(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;text&#39;</span>).text[<span style="color:#ff0044;font-weight:400">1</span>:-<span style="color:#ff0044;font-weight:400">1</span>]<br />    authors = sp.find(<span style="color:#3ad900;font-weight:400">&#39;small&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>).text<br />    details = sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br />    tags = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;tag&#39;</span>):<br />        tags.append(tag.text)<br />    tags = <span style="color:#3ad900;font-weight:400">&#39;,&#39;</span>.join(tags)<br />    data.append([quote, authors, details, tags])<br /></pre></div></p><p><strong><span style="text-decoration:underline;">Accessing Various HREFs</span></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128204425/Acc-768x479.jpg"><img src="images/97-2.png" alt="images/97-2.png" /></a>  </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128204552/Ext-768x398.jpg"><img src="images/97-3.png" alt="images/97-3.png" /></a>  </p><p>We&#39;ll copy this dataframe into a new dataframe df_2 and then delete the uneccessary columns</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128204808/1.jpg"><img src="images/97-4.png" alt="images/97-4.png" /></a>  </p><p><em><strong><span style="text-decoration:underline;"> Scraping Multiple Pages</span></strong></em></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">tqdm</span> <span style="color:#333333;font-weight:400">import</span> tqdm<br />Multiple_Pages = []<br /><span style="color:#0088ff;font-weight:400"># tqdm used for better representation.</span><br /><span style="color:#ff9d00;font-weight:700">for</span> page <span style="color:#ff9d00;font-weight:700">in</span> tqdm(<span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">11</span>)):<br /><br />    link = (<span style="color:#3ad900;font-weight:400">&#39;http://quotes.toscrape.com/page/&#39;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(page))<br />    res = requests.get(link)<br />    soup = BeautifulSoup(res.text, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br /><br />    <span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;quote&#39;</span>):<br /><br />        quote = sp.find(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;text&#39;</span>).text[<span style="color:#ff0044;font-weight:400">1</span>:-<span style="color:#ff0044;font-weight:400">1</span>]<br />        authors = sp.find(<span style="color:#3ad900;font-weight:400">&#39;small&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;author&#39;</span>).text<br />        details = sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br /><br />        tags = []<br /><br />        <span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>, class_=<span style="color:#3ad900;font-weight:400">&#39;tag&#39;</span>):<br />            tags.append(tag.text)<br /><br />        tags = <span style="color:#3ad900;font-weight:400">&#39;,&#39;</span>.join(tags)<br />        Multiple_Pages.append([quote, authors, details, tags])<br /></pre></div> </p><p><strong><span style="text-decoration:underline;">Creating Dataframe and saving it</span></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128205251/2-1024x402.jpg"><img src="images/97-5.png" alt="images/97-5.png" /></a> </p></div><div class='page'><h1 class='title level-3'>Book Scraper</h1><br/><p><h2>Book Scraper</h2></p><p>we will scrape a website <strong><span style="text-decoration:underline;">books.toscrape</span></strong>. The URL for the website is <em><strong><span style="text-decoration:underline;">&#39;https://books.toscrape.com/catalogue/page-1.html&#39;.</span></strong></em></p><p>#Code</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Importing Important Libraries</span><br /><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><br />link = <span style="color:#3ad900;font-weight:400">&#39;https://books.toscrape.com/catalogue/page-1.html&#39;</span><br /><br /><span style="color:#0088ff;font-weight:400">#Sending a request to the website(link)</span><br />res = requests.get(link)<br /><br /><span style="color:#0088ff;font-weight:400">#Creating a soup using BeautifulSoup</span><br />soup = BeautifulSoup(res.text,<span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br /></pre></div> </p><p>The above code is just the basics on how we start any project related to web scraping. </p><p>Lets start scraping 1st page from<em><strong><span style="text-decoration:underline;"> </span></strong></em><em><strong><a href="https://books.toscrape.com/">https://books.toscrape.com/</a></strong></em></p><p>Whenever we want to scrape any website. The first step is inspecting the website and finding out the class/div/tag etc that we want to scrap. For the above URL we want to scrap information about the books present in the website.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128211443/Screenshot221-660x319.jpg"><img src="images/98-1.png" alt="images/98-1.png" /></a> </p><p></p><p>We want to scrap books data so we have to select the list li having class = <em><span style="text-decoration:underline;">&#39;col-xs-6 col-sm-4 col-md-3 col-lg-3&#39;</span></em></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br />book = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;li&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;col-xs-6 col-sm-4 col-md-3 col-lg-3&#39;</span>)<br /><br />data=[]<br /><span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;li&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;col-xs-6 col-sm-4 col-md-3 col-lg-3&#39;</span>):<br />    <span style="color:#0088ff;font-weight:400">#print(sp)</span><br />	<span style="color:#0088ff;font-weight:400">#Finding different aspects to be scraped from the first page </span><br />    book_link   = <span style="color:#3ad900;font-weight:400">&quot;https://books.toscrape.com/catalogue/&quot;</span> + sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>].get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br />    <br />    title       = sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>].get(<span style="color:#3ad900;font-weight:400">&#39;title&#39;</span>)<br />    <br />    img_link    = <span style="color:#3ad900;font-weight:400">&quot;https://books.toscrape.com/&quot;</span> + sp.find(<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>)[<span style="color:#ff0044;font-weight:400">3</span>:]<br />    <br />    book_rating = (sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>])<br />    <br />    price       = sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>,class_=<span style="color:#3ad900;font-weight:400">&#39;price_color&#39;</span>).text[<span style="color:#ff0044;font-weight:400">1</span>:]<br />    <br />    stock       =  sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;instock availability&#39;</span>).text.strip()<br />	<span style="color:#0088ff;font-weight:400">#Appending all the data into a list(data)</span><br />    data.append([title,book_rating,price,stock,book_link,img_link]) <br /></pre></div> </p><p>Output from Data</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128191634/Screenshot20221128191542.jpg"><img src="images/98-2.png" alt="images/98-2.png" /></a> </p><p><strong><span style="text-decoration:underline;">Scraping Multiple Pages</span></strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">tqdm</span> <span style="color:#333333;font-weight:400">import</span> tqdm<br />Multiple_Pages = []<br /><span style="color:#0088ff;font-weight:400">#tqdm used for better representation.</span><br /><span style="color:#ff9d00;font-weight:700">for</span> page <span style="color:#ff9d00;font-weight:700">in</span> tqdm(<span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1</span>,<span style="color:#ff0044;font-weight:400">51</span>)):<br />  	<span style="color:#0088ff;font-weight:400">#using a for loop as there are 50 pages then creating a link using page-1,page-2...page-50</span><br />    link = <span style="color:#3ad900;font-weight:400">&#39;https://books.toscrape.com/catalogue/page-&#39;</span>+<span style="color:#ff9d00;font-weight:700">str</span>(page)+<span style="color:#3ad900;font-weight:400">&#39;.html&#39;</span><br />    res = requests.get(link)<br />    soap = BeautifulSoup(res.text,<span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br />    <span style="color:#0088ff;font-weight:400">#same code as in scraping for 1 page</span><br />    <span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soap.find_all(<span style="color:#3ad900;font-weight:400">&#39;li&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;col-xs-6 col-sm-4 col-md-3 col-lg-3&#39;</span>):<br />       <br />        book_link   = <span style="color:#3ad900;font-weight:400">&quot;https://books.toscrape.com/catalogue/&quot;</span> + sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>].get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br /><br />        title       = sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>].get(<span style="color:#3ad900;font-weight:400">&#39;title&#39;</span>)<br /><br />        img_link    = <span style="color:#3ad900;font-weight:400">&quot;https://books.toscrape.com/&quot;</span> + sp.find(<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>)[<span style="color:#ff0044;font-weight:400">3</span>:]<br /><br />        book_rating = (sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;class&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>])<br /><br />        price       = sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>,class_=<span style="color:#3ad900;font-weight:400">&#39;price_color&#39;</span>).text[<span style="color:#ff0044;font-weight:400">1</span>:]<br /><br />        stock       =  sp.find(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;instock availability&#39;</span>).text.strip()<br /><br />        Multiple_Pages.append([title,book_rating,price,stock,book_link,img_link])<br /><br /> <br /><br /><span style="color:#0088ff;font-weight:400">#Creating a Dataframe</span><br />Multiple_Pages_df = pd.DataFrame(data=Multiple_Pages)<br />Multiple_Pages_df = Multiple_Pages_df.rename(columns={<span style="color:#ff0044;font-weight:400">0</span>: <span style="color:#3ad900;font-weight:400">&#39;Title&#39;</span>, <span style="color:#ff0044;font-weight:400">1</span>: <span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>,<span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#3ad900;font-weight:400">&#39;Price&#39;</span>,<span style="color:#ff0044;font-weight:400">3</span>:<span style="color:#3ad900;font-weight:400">&#39;Stock Available&#39;</span>,<span style="color:#ff0044;font-weight:400">4</span>:<span style="color:#3ad900;font-weight:400">&#39;Book Link&#39;</span>,<span style="color:#ff0044;font-weight:400">5</span>:<span style="color:#3ad900;font-weight:400">&#39;Image Link&#39;</span>})<br />df_1 = Multiple_Pages_df<br /><br /><br /><span style="color:#0088ff;font-weight:400">#Saving the Dataframe in a csv file</span><br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />Multiple_Pages_df.to_csv(<span style="color:#3ad900;font-weight:400">&#39;All Books.csv&#39;</span>,index=<span style="color:#ff0044;font-weight:400">False</span>)<br /></pre></div> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221128192301/Screenshot20221128192114.jpg"><img src="images/98-3.png" alt="images/98-3.png" /></a> </p><p><strong><span style="text-decoration:underline;">Books Page Scraping</span></strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># code</span><br />data_2 = []<br /><span style="color:#ff9d00;font-weight:700">for</span> links <span style="color:#ff9d00;font-weight:700">in</span> tqdm(Multiple_Pages_df[<span style="color:#3ad900;font-weight:400">&#39;Book Link&#39;</span>]):<br />    res        = requests.get(links)<br />    soup       = BeautifulSoup(res.text,<span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br />    <br />    Book_Genre       = soup.find(<span style="color:#3ad900;font-weight:400">&#39;ul&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;breadcrumb&#39;</span>).find_all(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>)[<span style="color:#ff0044;font-weight:400">2</span>].text<br />    <br />    temp       = soup.find(<span style="color:#3ad900;font-weight:400">&#39;table&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;table table-striped&#39;</span>).find_all(<span style="color:#3ad900;font-weight:400">&#39;td&#39;</span>)    <br />    <br />    UPC              = temp[<span style="color:#ff0044;font-weight:400">0</span>].text<br />    price_exc_tax    = temp[<span style="color:#ff0044;font-weight:400">2</span>].text[<span style="color:#ff0044;font-weight:400">1</span>:]<br />    price_inc_tax    = temp[<span style="color:#ff0044;font-weight:400">3</span>].text[<span style="color:#ff0044;font-weight:400">2</span>:]<br />    tax              = temp[<span style="color:#ff0044;font-weight:400">4</span>].text[<span style="color:#ff0044;font-weight:400">2</span>:]<br />    availability     = temp[<span style="color:#ff0044;font-weight:400">5</span>].text<br />    reviews          = temp[<span style="color:#ff0044;font-weight:400">6</span>].text   <br />    data_2.append([Book_Genre,price_exc_tax,price_inc_tax,tax,UPC,availability,reviews])<br />    <br />    <br /><span style="color:#0088ff;font-weight:400">#Creating a dataframe</span><br />df_2 = pd.DataFrame(data_2)<br />df_2 = df_2.rename(columns={<span style="color:#ff0044;font-weight:400">0</span>:<span style="color:#3ad900;font-weight:400">&#39;Genre&#39;</span>,<span style="color:#ff0044;font-weight:400">1</span>:<span style="color:#3ad900;font-weight:400">&#39;Price&#39;</span>,<span style="color:#ff0044;font-weight:400">2</span>:<span style="color:#3ad900;font-weight:400">&quot;Price(Excluding Tax)&quot;</span>,<span style="color:#ff0044;font-weight:400">3</span>:<span style="color:#3ad900;font-weight:400">&quot;Price(Including Tax)&quot;</span> ,<span style="color:#ff0044;font-weight:400">4</span>:<span style="color:#3ad900;font-weight:400">&quot;UPC&quot;</span>,<span style="color:#ff0044;font-weight:400">5</span>:<span style="color:#3ad900;font-weight:400">&quot;Stock&quot;</span>,<span style="color:#ff0044;font-weight:400">6</span>:<span style="color:#3ad900;font-weight:400">&quot;Reviews&quot;</span>})<br /><br /><span style="color:#0088ff;font-weight:400">#Saving Dataframe</span><br />df_2.to_csv(<span style="color:#3ad900;font-weight:400">&#39;All Page.csv&#39;</span>,index=<span style="color:#ff0044;font-weight:400">False</span>)<br /> <br />Python3<span style="color:#0088ff;font-weight:400"># code</span><br />df = pd.DataFrame()<br />df[<span style="color:#3ad900;font-weight:400">&#39;UPC&#39;</span>]   = df_2[<span style="color:#3ad900;font-weight:400">&#39;UPC&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Title&#39;</span>] = df_1[<span style="color:#3ad900;font-weight:400">&#39;Title&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Genre&#39;</span>]  = df_2[<span style="color:#3ad900;font-weight:400">&#39;Genre&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>] = df_1[<span style="color:#3ad900;font-weight:400">&#39;Rating&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Price&#39;</span>]   = df_2[<span style="color:#3ad900;font-weight:400">&#39;Price&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Total Tax&#39;</span>] = df_2[<span style="color:#3ad900;font-weight:400">&#39;Total Tax&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Stock&#39;</span>] = df_2[<span style="color:#3ad900;font-weight:400">&#39;Stock&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Review&#39;</span>] = df_2[<span style="color:#3ad900;font-weight:400">&#39;Reviews&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Book Link&#39;</span>] = df_1[<span style="color:#3ad900;font-weight:400">&#39;Book Link&#39;</span>]<br />df[<span style="color:#3ad900;font-weight:400">&#39;Cover Image&#39;</span>] = df_1[<span style="color:#3ad900;font-weight:400">&#39;Image Link&#39;</span>]<br /><span style="color:#0088ff;font-weight:400">#Saving final scrap</span><br />df.to_csv(<span style="color:#3ad900;font-weight:400">&quot;Final Scrap.csv&quot;</span>)<br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Wikipedia Scraper</h1><br/><p><h2>Wikipedia Scraper</h2></p><p><h3>In this project we will take a person’s name as input from the user and then scrape his/her Wikipedia page. All the scraped information will be written in a text file and then saved in the current working directory of the user. </h3></p><p><h3>To start with the project, you should be familiar with the libraries like requests and BeautifulSoup. </h3></p><p><strong><h3>#First importing the libraries</h3></strong></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> requests<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd</pre></div></p><p><strong><h3>#Creating Link </h3></strong></p><p><div class="codebox"><pre>inp   = <span style="color:#ff9d00;font-weight:700">input</span>(<span style="color:#3ad900;font-weight:400">&quot;Enter Persons name: &quot;</span>)<br /><br />link  = <span style="color:#3ad900;font-weight:400">&#39;https://www.google.com/search?q=&#39;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(inp) +<span style="color:#3ad900;font-weight:400">&quot; &quot;</span>+ <span style="color:#3ad900;font-weight:400">&quot;Wikipedia&quot;</span><br /><br />link  = link.replace(<span style="color:#3ad900;font-weight:400">&#39; &#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;+&#39;</span>) </pre></div></p><p></p><p><h3>The link that is generated and stored in the variable link is basically the first Wikipedia link returned by Google when we type the person&#39;s name and add Wikipedia after it. Every whitespace is replaced by a “+” sign. We are using Google to generate the link because it’ll generate the link for Wikipedia even if we misspell the person’s name.</h3></p><p><a href="https://lh6.googleusercontent.com/kW4FLR3_eD-K8RfX5bVz-36-IQ218IdTvnspBnhHqNjUOppgEHjb232lCMR-5bz1APJwYO6-2cnQw4_gQAJtGBpsWE_UgGkfbLgZoK-9UHkfRf1SM9mx9wSC3h6EDAkG4tZatBRd-sma1TDUKgvVxdhpl7u2J26OOkU-DSzE7wSAYJdzY3AKDsvTiQdUbr8TTbekl4SslA"><img src="images/99-1.png" alt="images/99-1.png" /></a></p><p><h3>Look at the example. Even if we misspell Mahatma Gandhi, it’ll return the same. Now you must be wondering how the Google link can be used to scrape the Wikipedia page. </h3></p><p></p><p><h3>To get the first link, i.e., the link to the Wikipedia page of the desired person. First, we will send a request to the Google link. In this case, i.e.,      </h3></p><p><h3>https://www.google.com/search?q=Mahatma+Gandhi+Wikipedia</h3></p><p></p><p><h3>After sending the request we will create a soup using BeautifulSoup</h3></p><p></p><p><em><strong><h3>soup  = BeautifulSoup(res.text,’html.parser’)</h3></strong></em></p><p><h3>If we print this soup, we will scrape html data from the google search.</h3></p><p><h3>In order to get the link of the Wikipedia page we will use:</h3></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>):<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        link = sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)  <br />        <span style="color:#ff9d00;font-weight:700">if</span>(<span style="color:#3ad900;font-weight:400">&#39;en.wikipedia.org&#39;</span> <span style="color:#ff9d00;font-weight:700">in</span> link):<br />            <span style="color:#ff9d00;font-weight:700">break</span><br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        <span style="color:#ff9d00;font-weight:700">pass</span><br />link = (link[<span style="color:#ff0044;font-weight:400">7</span>:]).split(<span style="color:#3ad900;font-weight:400">&#39;&amp;&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>]<br /></pre></div></p><p></p><p><h3>First by using soup.find_all(‘div’) we found all the div tags present in the google page. Then for the div tags we found those tags that contain anchor tags and extracted href from them(Links to page). As it is still on google it isn’t necessary that the first div tag which contains an anchor tag corresponds to the Wikipedia page. To solve this problem, we used an if condition which checks that the link must contain ‘en.wikipedia.org’. After finding a link that contains en.wikipedia.org we used a break in order to stop iterating forward and update the link with the first link found. This first link will be the link to the Wikipedia page and will look something like this: </h3></p><p><a href="https://lh4.googleusercontent.com/SWJqXYjbYIwQ6VNRP3jlYSSEiptsntFjonJO0f9fFt78hXziMtxoFjXDPr1dPY9Eo4lkUDUUwz54wEaOOUSNg64dCz0eBlFzdlD6zjcGF5hpcoZ2DKs1R46jjsT0J6vn462vl-azGePVWHhT40pQS2RpDyDPrZD4c5NBrZOP9QrEwebpX-2zixEuIqQl0B5KhYyVGH_N6Q"><img src="images/99-2.png" alt="images/99-2.png" /></a></p><p><h3>The useful part of the link starts from https and ends at ‘Mahatma_Gandhi’ so we will remove the first 7 characters and split the link at ‘&amp;’ . Then we will update the link as: </h3></p><p></p><p><div class="codebox"><pre>link = (link[<span style="color:#ff0044;font-weight:400">7</span>:]).split(<span style="color:#3ad900;font-weight:400">&#39;&amp;&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>] </pre></div><h3></h3></p><p><h3> </h3></p><p><h3>If we print this link, it and click on it. It’ll redirect us to the Wikipedia page of Mahatma Gandhi. </h3></p><p><h3>Here we again have to update our res variable and send a new request to the Wikipedia page and make a soup out of it.</h3></p><p><h3>After doing it we can Scrape data.</h3></p><p><h3>Below is an example of how to scrape the paragraph: </h3></p><p><div class="codebox"><pre>paragraphs = <span style="color:#3ad900;font-weight:400">&#39; &#39;</span><br /><br /><span style="color:#ff9d00;font-weight:700">for</span> p <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;p&#39;</span>):<br /><br />    paragraphs += p.text<br /><br />    paragraphs += <span style="color:#3ad900;font-weight:400">&#39;\n&#39;</span>   <br /><br />paragraphs = paragraphs.strip()<br /></pre></div></p><p></p><p><h3> After storing all the necessary information in paragraphs, we can write it in a text file and save it in the current working directory </h3></p><p></p><p><div class="codebox"><pre>fd = <span style="color:#ff9d00;font-weight:700">open</span>(heading + <span style="color:#3ad900;font-weight:400">&quot;.txt&quot;</span> , <span style="color:#3ad900;font-weight:400">&#39;w&#39;</span>,encoding=<span style="color:#3ad900;font-weight:400">&#39;utf-8&#39;</span>)<br />fd.write(paragraphs)<br />fd.close()</pre></div></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Selenium</h1><br/><p><h2>Need for Web Drivers and Introduction to Selenium</h2></p><p><h3>The first question that comes to our mind before using web drivers to scrape data is &quot;What is the need for web drivers&quot; when we can simply scrape data using requests?</h3></p><p><h3>To answer this question, let&#39;s first recall how we used to scrap data using requests.</h3></p><p><h3>We used to import requests and send a request to the website using</h3></p><p><a href="https://lh6.googleusercontent.com/k55l0m8Q7nEhvqjZS_9fyJaXCRc4kNj-p_dWXezbAMVHDC3Z8-E6NA_fCRGLtYlZbCr5kKOScCve9mNSFKjZTOJPqJdKRkgQO3Z7y-nMtc0ONBMIZoPd9ML9cF16SQzi1g4VXnwTviXOknxkZjmzY_QHkT75QoPBlm44uItilpAVVHgqKFXfHNZUPhKUSoqRG0-YGQbw_w"><img src="images/100-1.png" alt="images/100-1.png" /></a></p><p><h3>Now we usually create a soup out of this request using another important library called </h3><em><h3>‘BeautifulSoup’. </h3></em><h3>When we print this soup, we get data from the website.</h3></p><p><h3>                                   </h3><a href="https://lh4.googleusercontent.com/gVw6E_fw22nRicJSy6MclkDuXog3yaUKGmJB8yVRTgBAUHSfM5-pTZtMaCU-pq-2Wh37cX03fIouVCnLybqS2IPTSUQWIDmuRAQL1DDE_I0A_RSH9TCmbfHK0IY-D4_TYXaN7yZ58PaS9rH_gZt9O9M2zSPJaiKE2fmk0Lw5oGxjkVMse_xPRjLdT8J4QlupNGXfH4oGZg"><img src="images/100-2.png" alt="images/100-2.png" /></a>                        </p><p><h3>Now coming to the question of what the need for Web Drivers? Suppose we want to scrape data from a big e-commerce website. The first step is to send a request to the website and then print the text, i.e., basically the HTML code of the website. When we try to print the text/code, it would print some code that isn’t the html code we’re looking for or it would return a message saying</h3></p><p><h3>&quot;Web scraping is not permitted.&quot;</h3></p><p><h3>                  OR</h3></p><p><a href="https://lh5.googleusercontent.com/UeKcKCOi6Hv1ziBpkND9dSLVR2WXrC8K87xcDq2N2T8Hcpbl9j--4xP7HFVkzV1dlx5TDvw_rZwJ5tsNhp4T1_Nw4Sn0ujEuwmQOarI7ozywZWSoYBCNmzxj_MrpU3h_zQLXIxHFTRYdP2PE3T3VvfDq0iHKOcoca57RMTNWRwPgapjhdYvpy_x2cqFlL6Zc"><img src="images/100-3.png" alt="images/100-3.png" /></a></p><p><h3>All websites are scrapable, some are hard to scrape and some are easy.</h3></p><p><h3>Another use of web drivers is that they help us scrape data from websites that are dynamic in nature. Dynamic websites are those websites that produce information when we click on some element. For example, when using Amazon, if we search for mobiles, it will show us a page containing different types of mobiles. When we click on any of the mobiles, it directs us to the page of that particular mobile phone. In order to scrape data from the full page of mobiles and the data of each mobile’s page, web servers are used, as the website is dynamic in nature.</h3></p><p><h3></h3></p><p><h3> </h3></p><p><h3>Now coming to the second part, &quot;</h3><strong><h3>What is Selenium and how do web drivers work</h3></strong><h3>&quot;?</h3></p><p><h3>Selenium is an open-source framework designed for testing. The Selenium Web Driver is just one part of the overall Selenium library. Selenium allows us to run our scripts in an automated process on the web driver, which helps us to decrease the time to scrape data. As it uses automation, we don’t have to manually do anything. Selenium supports a lot of web drivers, e.g., Chrome, Mozilla, Safari, etc.</h3></p><p><h3> </h3></p><p><h3>Selenium Web Drivers basically work in 3 steps:</h3></p><p><h3>First, the JSON wire protocol converts the test commands into an HTTP request.</h3></p><p><h3>The Browser Driver, which is already present in each browser, is initialised before any script is executed.</h3></p><p><h3>Once everything is ready, the driver starts to send requests to the browser.</h3></p><p><h3>Each Web Driver can directly call its browser. Whenever a script is executed, an HTTP request is generated by the JSON wire protocol. The browser driver uses an HTTP server for getting HTTP requests. After receiving and executing the request, the status is sent back to the HTTP server, which forwards it back to the script.</h3></p><p><h3> </h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Setting up Selenium and Web Drivers</h1><br/><p><small>Setting up Selenium and Web Drivers</small></p><p><h3>Selenium is used for automation of scripts. For example, scraping data from a website and storing the result in a file, let’s say a csv, can be very time-consuming if done manually, but using Selenium and automating the scraping scripts can speed up the process. Selenium supports scripts in various languages like Ruby, Java, Python etc.</h3></p><p><h3>Now let’s jump towards the setting up of Selenium and Web Drivers. Note here we will be setting up selenium in Python so Python should already be installed on your computers.</h3></p><p><h3> </h3></p><p><h3> To impot a web driver, we have to use:</h3></p><p><h3>                                           </h3><strong><h3> from selenium import webdriver</h3></strong></p><p><h3>In order to run the web driver, we’ve to use</h3></p><p><h3>                                          </h3><strong><h3>  webdriver.Chrome()</h3></strong></p><p><h3>We can use any supported browser to see a list of supported browsers press tab after writing webdriver. </h3></p><p><h3>If we leave the parenthesis, it will return an error. In the parenthesis, we have to specify the path of the web driver. To download the web driver first, we run the command</h3></p><p><h3>                                           </h3><strong><h3>webdriver.Chrome()</h3></strong></p><p><h3>The error would give us a link which contains downloadable files of web drivers for all the different architectures of OS.</h3></p><p><h3> </h3></p><p><h3>After downloading the driver compatible with your PC, we can use another library, </h3><strong><h3>chromedriver.binary,</h3></strong><h3> which can help us get the path of the driver.</h3></p><p><h3>First, we&#39;ve got to use the command:</h3></p><p><h3>                          </h3><strong><h3>    !pip install chromedriver.binary</h3></strong></p><p><h3>Then,</h3></p><p><h3>                             </h3><strong><h3> import chromedriver.binary</h3></strong></p><p><h3>To use chromedriver.binary, we&#39;ve got to use </h3><strong><h3>chromedriver_filename.</h3></strong><h3> To do this, we’ll use this command:</h3></p><p><strong><h3>import chromedriver_filename from chromedriver.binary</h3></strong></p><p><h3>This command would return you the path of the driver. To ease the process, we can store this path in a variable named path and then use that path variable in order to open a browser.</h3></p><p><h3>                             </h3><strong><h3> path   =  chromedriver.binary import chromedriver_filename</h3></strong></p><p><strong><h3>                              driver = webdriver.Chrome(path)</h3></strong></p><p><h3>If we run this driver, it’ll open a browser. Now to open a webpage on this browser we have to use .get() function.</h3></p><p><h3>                             </h3><strong><h3> link = ‘https://www.youtube.com/c/GeeksforGeeksVideos/videos</h3></strong></p><p><strong><h3>                              driver.get(link)</h3></strong></p><p><h3>To print content, we can use Beautiful Soup:</h3></p><p><strong><h3>Soup = BeautifulSoup(driver.page_source,’html.parser’)</h3></strong></p><p><strong><h3>print(Soup.prettify)</h3></strong></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Youtube Scraper</h1><br/><p><h2>YouTube Scraper 1</h2></p><p><strong><span style="text-decoration:underline;">Pre-Requisites: Selenium(Web drivers), BeautifulSoup, Pandas(for Data frame), NumPy(for Nan value)</span></strong></p><p></p><p>. In this project we’re going to scrape GFG’s YouTube channel and scrape data (title, thumbnail, likes, views, upload etc) for all the data/ videos available on the channel. We’re not going to use Infinite scroll in this project and will manually scroll down the videos page till we reach the pages bottom.</p><p></p><p>The link for the channel is:<em><span style="text-decoration:underline;"> &#39;https://www.youtube.com/c/GeeksforGeeksVideos/videos’</span></em></p><p><div class="codebox"><pre>browser = webdriver.Chrome(chromedriver_binary.chromedriver_filename)<br />browser.get(<span style="color:#3ad900;font-weight:400">&#39;https://www.youtube.com/c/GeeksforGeeksVideos/videos&#39;</span>)<br />soup = BeautifulSoup(browser.page_source, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)</pre></div></p><p></p><p>Let’s get started with the basics first i.e., understanding the tags. These tags will help us to scrape the data from the channel. These tags basically help us in locating various pieces of information about the video that we want to scrape.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221201121528/1-660x64.jpg"><img src="images/102-1.png" alt="images/102-1.png" /></a></p><p> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221201121547/2-660x449.jpg"><img src="images/102-2.png" alt="images/102-2.png" /></a> </p><p></p><p>Here we selected <em><strong><span style="text-decoration:underline;">ytd-rich-grid-renderer</span></strong></em><em><span style="text-decoration:underline;"> </span></em>and using this tag scraped the title of the videos. Using</p><p><em><strong><span style="text-decoration:underline;">sp[-1].find(…).get(‘title’)</span></strong></em> will give us the title of the last video.</p><p>Using the same soup we can scrape Links, Views, Upload Date etc</p><p><div class="codebox"><pre><br />	links = sp.fin(‘a’ , class_= <span style="color:#3ad900;font-weight:400">&#39;yt-simple-endpoint style-scope ytd-grid-video-renderer&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br />	<span style="color:#0088ff;font-weight:400">#Similarly, Views can be scraped using:</span><br />	views = sp[i].find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-grid-video-renderer&#39;</span>)[<span style="color:#ff0044;font-weight:400">1</span>].text<br />	<span style="color:#0088ff;font-weight:400">#Thumbnail can be scraped using:</span><br />	thumbnail_link = sp.find(<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>).split(<span style="color:#3ad900;font-weight:400">&#39;?&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>]</pre></div> </p><p></p><p><div class="codebox"><pre>data = []<br /><br /><span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;ytd-grid-video-renderer&#39;</span>):<br /><br />    title          = sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;yt-simple-endpoint style-scope ytd-grid-video-renderer&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;title&#39;</span>)<br /><br />    links          =  <span style="color:#3ad900;font-weight:400">&quot;https://www.youtube.com&quot;</span> +   sp.find(<span style="color:#3ad900;font-weight:400">&#39;a&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;yt-simple-endpoint style-scope ytd-grid-video-renderer&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;href&#39;</span>)<br /><br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br /><br />        views      = sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-grid-video-renderer&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>].text<br /><br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br /><br />        views      =  <span style="color:#ff0044;font-weight:700">None</span><br /><br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br /><br />        date_time  = sp.find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>,class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-grid-video-renderer&#39;</span>)[<span style="color:#ff0044;font-weight:400">1</span>].text<br /><br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br /><br />        date_time  =  <span style="color:#ff0044;font-weight:700">None</span> <br /><br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br /><br />        thumbnail_link = sp.find(<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>).split(<span style="color:#3ad900;font-weight:400">&#39;?&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>]<br /><br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br /><br />        thumbnail_link = <span style="color:#ff0044;font-weight:700">None</span><br /><br />    data.append([title,links,views,date_time,thumbnail_link])<br /></pre></div><code></code></p><p><code> </code><strong>#Output Sample</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221201121834/3-660x219.jpg"><img src="images/102-3.png" alt="images/102-3.png" /></a> </p><p>We can save this data as csv, but before that we’ve to create a data frame out of it.</p><p></p><p><div class="codebox"><pre>df = pd.DataFrame(data, columns = [<span style="color:#3ad900;font-weight:400">&#39;title&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;views&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;date_time&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;video_link&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;thumbnail_link&#39;</span>])<br />df.to_csv(‘data.csv’,index=<span style="color:#ff0044;font-weight:400">False</span>)</pre></div></p><p><h2>YouTube Scraper 2</h2></p><p>In the previous article we scraped data from the main page. In this article we will scrape data from the videos page example:</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221201122117/4-660x554.jpg"><img src="images/102-4.png" alt="images/102-4.png" /></a> </p><p>We will scrape data like description, number of likes, date_time, views and title.</p><p>The method is same but here we will use links of the videos to visit each videos page. We’ve already scraped the links for each video in the previous article. Let’s start the scraping:</p><p></p><p><strong><span style="text-decoration:underline;">#Code</span></strong></p><p><div class="codebox"><pre>df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;data.csv&#39;</span>)<br />df.head()<br /><br />browser = webdriver.Chrome(chromedriver_binary.chromedriver_filename)<br />browser.get(<span style="color:#3ad900;font-weight:400">&#39;https://www.youtube.com&#39;</span>)<br />time.sleep(<span style="color:#ff0044;font-weight:400">2</span>)<br /><br />data = []<br /> <br /><span style="color:#ff9d00;font-weight:700">for</span> link <span style="color:#ff9d00;font-weight:700">in</span> tqdm(df[<span style="color:#3ad900;font-weight:400">&#39;video_link&#39;</span>]):<br />    link = <span style="color:#3ad900;font-weight:400">&#39;https://www.youtube.com&#39;</span> + link<br />    browser.get(link)<br />    time.sleep(<span style="color:#ff0044;font-weight:400">5</span>)<br />    soup = BeautifulSoup(browser.page_source, <span style="color:#3ad900;font-weight:400">&#39;html.parser&#39;</span>)<br /><br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        title = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;yt-formatted-string&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-video-primary-info-renderer&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>].text<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        title = np.nan<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        view = soup.find(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span> , class_ = <span style="color:#3ad900;font-weight:400">&#39;view-count style-scope ytd-video-view-count-renderer&#39;</span>).text<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        view = np.nan<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        date_time = soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;yt-formatted-string&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-video-primary-info-renderer&#39;</span>)[<span style="color:#ff0044;font-weight:400">1</span>].text<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        date_time = np.nan<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        like = soup.find(<span style="color:#3ad900;font-weight:400">&#39;yt-formatted-string&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;style-scope ytd-toggle-button-renderer style-text&#39;</span>).text<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        like = np.nan<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        description = soup.find(<span style="color:#3ad900;font-weight:400">&#39;yt-formatted-string&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;content style-scope ytd-video-secondary-info-renderer&#39;</span>).text<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        description = np.nan<br />    data.append([title , date_time, like, view, link, description])<br /><br /><span style="color:#0088ff;font-weight:400">#Creating and Saving the dataframe</span><br />df = pd.DataFrame(data, columns = [<span style="color:#3ad900;font-weight:400">&#39;title&#39;</span> , <span style="color:#3ad900;font-weight:400">&#39;date_time&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;likes&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;views&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;link&#39;</span> , <span style="color:#3ad900;font-weight:400">&#39;description&#39;</span>])<br />df.to_csv(<span style="color:#3ad900;font-weight:400">&#39;GFG.csv&#39;</span>, index = <span style="color:#ff0044;font-weight:400">False</span>)<br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Stock Infinite Scroll</h1><br/><p><h2>Infinite Scrolling</h2></p><p><h3> </h3><span style="color:#000000;"></span></p><p><span style="color:#000000;"></span><h3>Before jumping to infinite scrolling, we should understand its use case first. Infinite scrolling is used when websites load more data after we reach the bottom. </h3></p><p><a href="https://lh6.googleusercontent.com/z5_WuPU9oszNEKQtwVDSmkIFjKnZpvH4F7FLAwgrVvTyGB4RS-3A3VnZqJWeYjrv9xJSibHlTJU9GQmm_MGf7hH1jGeeAAqoUDn_i17slXLcyZwvEgOsofOt2Ny6buGQjM7qbpTbl67QgEuwB0LAmbbHEdZ2xmeoPDrIpXg8wjlO8uMyRLNe33Kfz40bBB5HnXCXy8XwNw"><img src="images/103-1.png" alt="images/103-1.png" /></a></p><p></p><p><h3>Let us jump to the second part i.e., how to implement infinite scrolling. All of the codes are implemented on </h3><em><strong><h3>https://stock-pictures.netlify.app</h3></strong></em><h3>. This is a website, i.e., specifically made to scrap data using infinite scrolling. But the same method can be applied to any website that requires infinite scrolling to scrape data.</h3></p></div><div class='page'><h1 class='title level-3'>Infinite Scroll</h1><br/><p></p><p><h3>This website will only scrape data if used through a webdriver. </h3></p><p><h3>Code for implementing infinite scrolling on </h3><em><strong><h3>stock-pictures.netlify.app</h3></strong></em><h3>:</h3></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Importing Libraries</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">selenium</span> <span style="color:#333333;font-weight:400">import</span> webdriver         <br /><span style="color:#333333;font-weight:400">import</span> time<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">tqdm</span> <span style="color:#333333;font-weight:400">import</span> tqdm<br /><br /> <span style="color:#0088ff;font-weight:400">#Using a web driver and opening a link with it</span><br /><br />link  = <span style="color:#3ad900;font-weight:400">&#39;https://stock-pictures.netlify.app&#39;</span><br />browser = webdriver.Chrome()<br />browser.get(link)<br /><br /><span style="color:#0088ff;font-weight:400">#Code for Infinite Scroll</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> tqdm(<span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">540000</span>,<span style="color:#ff0044;font-weight:400">1000</span>)):<br />	browser.execute_script(<span style="color:#3ad900;font-weight:400">&quot;window.scrollTo(0,&quot;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(i) + <span style="color:#3ad900;font-weight:400">&quot;)&quot;</span>)<br />	time.sleep(<span style="color:#ff0044;font-weight:400">.3</span>) <br /></pre></div></p><p><h3>After this, we can use normal scraping techniques using BeautifulSoup.</h3></p><p><h3>Let’s understand the code of infinite scrolling</h3></p><p><h3>                        </h3></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> tqdm(<span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">540000</span>,<span style="color:#ff0044;font-weight:400">1000</span>)):<br />	browser.execute_script(<span style="color:#3ad900;font-weight:400">&quot;window.scrollTo(0,&quot;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(i) + <span style="color:#3ad900;font-weight:400">&quot;)&quot;</span>)<br />	time.sleep(<span style="color:#ff0044;font-weight:400">.3</span>)<br /></pre></div>	</p><p></p><p>	<h3>First, we need to understand how we can automate scrolling. We can use</h3><em><strong><h3> browser.execute_script(&quot;window.scrollTo(0,&quot; + str(i) + &quot;)&quot;)</h3></strong></em></p><p><h3>Let’s break down the code:</h3></p><p><strong><h3>execute_script</h3></strong><h3> comes with </h3><strong><h3>webdrivers</h3></strong><h3>. When we use </h3><em><strong><h3>window.scroll(x,y)</h3></strong></em><h3>. The parameter x points to the first pixel and y to the pixel to which we want to scroll. </h3></p><p></p><p><h3>Now let’s understand how we implemented this in our case. As we don’t know the bottom of the website,  we are using a for loop (Syntax </h3><strong><h3>for(start,stop,step))</h3></strong><h3>.</h3></p><p><h3>In </h3><em><strong><h3>browser.execute_script </h3></strong></em><h3>we pass </h3><em><strong><h3>window.scrollTo</h3></strong></em><h3> and pass the start and end pixel as parameters to it. As we don’t know the end pixel or where the site ends,  we are using a for loop to automatically scroll down to the new end after the first loading point is found and new data is loaded. We use sleep to allow the website to load new data after we’ve reached the bottom.</h3></p><p></p><p><h3>Now the main point of concern is what should be the stop and for the for loop. The start should be 0.</h3></p><p><h3>Finding the stop is a manual process. We should use a random number for stops and see how much scrolling takes place. If it doesn’t scroll to the bottom, we have to increase the value of the stop. </h3></p><p><h3>If the end of the website is reached before the loop ends, then we have to check manually the value tqdm is showing and update the same as the value for stop.</h3></p><p><h3>Example:</h3></p><p><a href="https://lh6.googleusercontent.com/-wUdYT2GLtIjj60QoOW3aHpbwUlVxCE13GP6ZOkbzonSCkemp0pGNVQKLh9_4llGYLqKmiltTTs6IsPbatiouPJQpAWixR1-iqDRq4SQp0rD71LmZqTmS8qLkiJlcpmXW1cGCts7rvIzttG_ikwOiMlIuIvNO3iWrOenkn8uaJXLvdomp9z9L4WG7sVDot2UGbsaLSq-8g"><img src="images/105-1.png" alt="images/105-1.png" /></a></p><p><h3></h3></p><p><h3> </h3></p><p><h3>For the same stock images website, I found the bottom at pixel 5,40,000</h3></p><p><h3>(540*1000(step-size)) </h3></p><p><h3>So, we can drastically reduce the time by reducing the stop parameter value.</h3></p><p></p></div><div class='page'><h1 class='title level-3'>Stock Images Scraper</h1><br/><p><h2>Stock Image Scraper</h2></p><p>In this project we will be scraping all the data including images from        </p><p>                     <strong><span style="text-decoration:underline;">&#39;https://stock-pictures.netlify.app&#39; </span></strong></p><p></p><p>The concepts covered in this project can be applied to scrape image data from any website and in storing those images in a dynamic manner. </p><p> This project covers various important aspects of data collection. Apart from data collection (scraping Images, likes ,tags) you will also learn how to dynamically name these images and also how to create folder based on names of these tags and store images in them.</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Importing Libraries.</span><br /><span style="color:#333333;font-weight:400">import</span> time,requests,chromedriver_binary<br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">tqdm</span> <span style="color:#333333;font-weight:400">import</span> tqdm <br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">bs4</span> <span style="color:#333333;font-weight:400">import</span> BeautifulSoup<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">selenium</span> <span style="color:#333333;font-weight:400">import</span> webdriver<br /><br /><span style="color:#0088ff;font-weight:400"># Selenium</span><br />browser = webdriver.Chrome(path)<br />browser.get(<span style="color:#3ad900;font-weight:400">&#39;https://stockmages.netlify.app&#39;</span>)<br /><br /><br /><span style="color:#0088ff;font-weight:400">#Infinite Scroll to reach the bottom </span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> tqdm(<span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">5000000</span>,<span style="color:#ff0044;font-weight:400">1000</span>)):<br />    browser.execute_script(<span style="color:#3ad900;font-weight:400">&quot;window.scrollTo(0,&quot;</span>  + <span style="color:#ff9d00;font-weight:700">str</span>(i) + <span style="color:#3ad900;font-weight:400">&quot;)&quot;</span>)<br />    time.sleep(<span style="color:#ff0044;font-weight:400">.1</span>)<br /><span style="color:#0088ff;font-weight:400">#Using this much range will lead ypu to the bottom of the path</span><br /></pre></div> </p><p>Now we will scrape the page using different tags.</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Scraping the Page</span><br />soup = BeautifulSoup(browser.page_source,’html.parser’)<br /><br /><span style="color:#0088ff;font-weight:400">#Scraping the Image Details</span><br />data = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> sp <span style="color:#ff9d00;font-weight:700">in</span> tqdm(soup.find_all(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;container&#39;</span>)):<br />    	img_link = sp.find(<span style="color:#3ad900;font-weight:400">&#39;img&#39;</span>).get(<span style="color:#3ad900;font-weight:400">&#39;src&#39;</span>)<br />    	tags     = sp.find(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;tag-color&#39;</span>).text[<span style="color:#ff0044;font-weight:400">7</span>:].strip()<br />    	likes    = <span style="color:#ff9d00;font-weight:700">int</span>(sp.find(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;likes-comments&#39;</span>).find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>)[<span style="color:#ff0044;font-weight:400">0</span>].text.strip()[:-<span style="color:#ff0044;font-weight:400">6</span>])<br />    	comments = <span style="color:#ff9d00;font-weight:700">int</span>(sp.find(<span style="color:#3ad900;font-weight:400">&#39;div&#39;</span>, class_ = <span style="color:#3ad900;font-weight:400">&#39;likes-comments&#39;</span>).find_all(<span style="color:#3ad900;font-weight:400">&#39;span&#39;</span>)[<span style="color:#ff0044;font-weight:400">1</span>].text.strip()[:-<span style="color:#ff0044;font-weight:400">9</span>]) <br />    	data.append([img_link, tags, likes, comments])<br /><br /><span style="color:#0088ff;font-weight:400">#Creating a dataframe and saving it</span><br />df = pd.DataFrame(data, columns = [<span style="color:#3ad900;font-weight:400">&#39;img_link&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;tags&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;likes&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;comments&#39;</span>])<br />df.to_csv(<span style="color:#3ad900;font-weight:400">&#39;images.csv&#39;</span>, index = <span style="color:#ff0044;font-weight:400">False</span>)<br /></pre></div></p><p></p><p> </p><p>This code will scrape data from the website and give us the link of image, tags of image, number of likes of image and the number of comments on it. A sample of dataframe: - </p><p><a href="https://lh4.googleusercontent.com/CZnwcSsfXlWGGD55q_yyycWGKPiYvloSj8C2TdWUSAPMATXod-vYtmPjBbeTYkBS0UxRRkrK3wrGiULHPuUgx_M1M_luWbSJVxUO1pbR0Cnrd3ew6HzMMNq-vUrWALpiEZBZCR-EzstYjfbhmdhtlBcaNhB3H1jgkLJhQhEaUGZ6ysjC-MQB9hWiwVDqS4NBfUUQb5ZqYA"><img src="images/106-1.png" alt="images/106-1.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Downloading and Dynamic Naming of Images</h1><br/><p><h2>Downloading and Dynamic Naming of Images</h2></p><p></p><p> As  scraping/downloading of images will be an automated process, if it finds 2 images having the same name it will overwrite the previous image and change it with the new one. This would lead to loss of data.</p><p>Let us download 1 sample image first before downloading and naming all of the images.</p><p></p><p>We can download 1 image as</p><p></p><p><div class="codebox"><pre>fd = <span style="color:#ff9d00;font-weight:700">open</span>(‘img.jpg’ , ‘wb’)<br />fd.write(res.content)<br />fd.close()<br /></pre></div></p><p><strong>Defining a function to download images</strong></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">download</span>(link, img_path ):<br />    res = requests.get(link)         <br />    fd = <span style="color:#ff9d00;font-weight:700">open</span>(img_path,<span style="color:#3ad900;font-weight:400">&#39;wb&#39;</span>)         <span style="color:#0088ff;font-weight:400"># wb = (write binary format)</span><br />    fd.write(res.content)            <br />    fd.close()<br /></pre></div><code></code></p><p><code></code> </p><p>Using this function now we&#39;ll download all the images from the site</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Downloading all Images.</span><br />paths   = []<br />img_ids = []<br />ref = <span style="color:#ff0044;font-weight:400">100000</span><br />i   = <span style="color:#ff0044;font-weight:400">1</span><br /><span style="color:#ff9d00;font-weight:700">for</span> link <span style="color:#ff9d00;font-weight:700">in</span> tqdm(df[<span style="color:#3ad900;font-weight:400">&#39;img_link&#39;</span>]):<br />    img_id = <span style="color:#3ad900;font-weight:400">&#39;A&#39;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(i + ref)[<span style="color:#ff0044;font-weight:400">1</span>:]          <span style="color:#0088ff;font-weight:400"># Creating Image ID</span><br />    i += <span style="color:#ff0044;font-weight:400">1</span><br />    img_path = <span style="color:#3ad900;font-weight:400">&#39;Imgs/&#39;</span> + img_id + <span style="color:#3ad900;font-weight:400">&#39;.jpg&#39;</span>    <span style="color:#0088ff;font-weight:400"># Creating Image Path</span><br />   	download(link, img_path)                <span style="color:#0088ff;font-weight:400"># Downloading the Image</span><br />    paths.append(img_path)<br />    img_ids.append(img_id)<br /><span style="color:#0088ff;font-weight:400">#Saving ID’s and paths in df and saving it</span><br />df[<span style="color:#3ad900;font-weight:400">&#39;img_id&#39;</span>]   = img_ids<br />df[<span style="color:#3ad900;font-weight:400">&#39;img_path&#39;</span>] = paths<br />df.to_csv(<span style="color:#3ad900;font-weight:400">&#39;imgs.csv&#39;</span>, index = <span style="color:#ff0044;font-weight:400">False</span>)<br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Image Dataset Creation</h1><br/><p><h2>Image Dataset Creation</h2></p><p>This project is basically in continuation with the image scraper project. In this project we will create folders for all tags an also remove certain images thar are below some threshold value. Let’s work with the project i.e., creating folders based on tags and saving images in it and deleting folders having images less than the threshold value.</p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Importing libraries</span><br /><span style="color:#333333;font-weight:400">import</span> os<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">shutil</span> <span style="color:#333333;font-weight:400">import</span> copyfile <span style="color:#333333;font-weight:400">as</span> copy<br /><br /><span style="color:#0088ff;font-weight:400">#Removing unnecessary libraries</span><br /><span style="color:#ff9d00;font-weight:700">del</span> df[<span style="color:#3ad900;font-weight:400">&#39;img_link&#39;</span>]<br /><span style="color:#ff9d00;font-weight:700">del</span> df[<span style="color:#3ad900;font-weight:400">&#39;img_id&#39;</span>]<br /><span style="color:#ff9d00;font-weight:700">del</span> df[<span style="color:#3ad900;font-weight:400">&#39;likes&#39;</span>]<br /><span style="color:#ff9d00;font-weight:700">del</span> df[<span style="color:#3ad900;font-weight:400">&#39;comments&#39;</span>]<br /></pre></div></p><p></p><p>Now for the new dataset we will find tags. We&#39;ll create a list and append tags in it. Then we&#39;ll create folders based on these tags using <strong><span style="text-decoration:underline;">os.mkdir</span></strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Finding all tags</span><br />t = []<br /><span style="color:#ff9d00;font-weight:700">for</span> tags <span style="color:#ff9d00;font-weight:700">in</span> df[<span style="color:#3ad900;font-weight:400">&#39;tags&#39;</span>]:<br />    	t += [tag.strip() <span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> tags.split(<span style="color:#3ad900;font-weight:400">&#39;,&#39;</span>)]<br />tags = <span style="color:#ff9d00;font-weight:700">list</span>(<span style="color:#ff9d00;font-weight:700">set</span>(t))<br />		<br /><br /><br /><span style="color:#0088ff;font-weight:400">#Creating folders for each tag</span><br /><span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> tqdm(tags):<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />     	 os.mkdir(<span style="color:#3ad900;font-weight:400">&#39;Dataset/&#39;</span> + tag)<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />   	     <span style="color:#ff9d00;font-weight:700">pass</span> <br /></pre></div></p><p></p><p>Now our folders are ready and each folder is named after a specific tag. Let&#39;s  save the images in their particular folders now.</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Saving images in specific folders</span><br />error = <span style="color:#ff0044;font-weight:400">0</span><br /><span style="color:#ff9d00;font-weight:700">for</span> data <span style="color:#ff9d00;font-weight:700">in</span> tqdm(df.values):  <br />    tags = data[<span style="color:#ff0044;font-weight:400">0</span>]<br />    tags = [<span style="color:#3ad900;font-weight:400">&#39;Dataset/&#39;</span> + tag.strip() + <span style="color:#3ad900;font-weight:400">&#39;/&#39;</span> <span style="color:#ff9d00;font-weight:700">for</span> tag <span style="color:#ff9d00;font-weight:700">in</span> tags.split(<span style="color:#3ad900;font-weight:400">&#39;,&#39;</span>)] <br />    src = data[<span style="color:#ff0044;font-weight:400">1</span>]<br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> tags:<br />        dst = i + src.split(<span style="color:#3ad900;font-weight:400">&#39;/&#39;</span>)[-<span style="color:#ff0044;font-weight:400">1</span>]<br />        <span style="color:#ff9d00;font-weight:700">try</span>:<br />            copy(src, dst)<br />        <span style="color:#ff9d00;font-weight:700">except</span>:<br />            error += <span style="color:#ff0044;font-weight:400">1</span><br /></pre></div></p><p></p><p>in the above code, we first loop in tqdm(df.values) for going through df.values</p><p>dataset+tag.strip holds tag</p><p>src is source for it, dst holds destination, copy() copies the  </p></div><div class='page'><h1 class='title level-3'>Thresholding Images</h1><br/><p><h2>Thresholding Images</h2></p><p>Till now we&#39;ve downloaded the images created folders based on tags and stored their respective images in them. Now coming to the last part of the project i.e., only to keep those folders of images that are having a certain number of images in them or that are having images greater than the threshold number. To do it first we&#39;ve to check the number of images present in a particular folder and then compare it with the threshold value if it&#39;s less than the threshold we&#39;ll use shutil to move them to a different folder or simply delete them.</p><p>	</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Checking number of Images in Each Folder</span><br />folder_ = []<br />freq    = []<br /><span style="color:#ff9d00;font-weight:700">for</span> folder <span style="color:#ff9d00;font-weight:700">in</span> tqdm(folders):<br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        freq.append(<span style="color:#ff9d00;font-weight:700">len</span>(os.listdir(<span style="color:#3ad900;font-weight:400">&#39;Dataset/&#39;</span> + folder)))<br />        folder_.append(folder)<br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        <span style="color:#ff9d00;font-weight:700">pass</span><br /><br /><br /><span style="color:#0088ff;font-weight:400">#Removing images with less than 50 images(Threshold)</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> tqdm(df_[df_[<span style="color:#3ad900;font-weight:400">&#39;freq&#39;</span>] &lt; <span style="color:#ff0044;font-weight:400">50</span>][<span style="color:#3ad900;font-weight:400">&#39;folder&#39;</span>]):<br />    src = <span style="color:#3ad900;font-weight:400">&#39;Dataset/&#39;</span> + i<br />    dst = <span style="color:#3ad900;font-weight:400">&#39;Temp/&#39;</span> + i<br />    shutil.move(src, dst)   <br /><br /></pre></div></p></div><div class='page'><h1 class='title level-1'>AI and Data Science</h1><br/><p><h2> AI</h2></p><p>Before leading to the meaning of artificial intelligence let understand what is the meaning of Intelligence- </p><p>Intelligence: The ability to learn and solve problems. This definition is taken from webster’s Dictionary. </p><p>The most common answer that one expects is <strong>“to make computers intelligent so that they can act intelligently!”</strong>, but the question is how much intelligent? How can one judge intelligence? </p><p>…as intelligent as humans. If the computers can, somehow, solve real-world problems, by improving on their own from past experiences, they would be called “intelligent”. </p><p>Thus, the AI systems are more generic(rather than specific), can “think” and are more flexible. </p><p>Intelligence, as we know, is the ability to acquire and apply knowledge. Knowledge is the information acquired through experience. Experience is the knowledge gained through exposure(training). Summing the terms up, we get <strong>artificial intelligence</strong> as the “copy of something natural(i.e., human beings) ‘WHO’ is capable of acquiring and applying the information it has gained through exposure.” </p><p><strong>Intelligence is composed of:</strong><ul><li></p><p>• Reasoning</li><li>Learning</li><li>Problem Solving</li><li>Perception</li><li>Linguistic Intelligence</li></ul></p><p></p><p>Many tools are used in AI, including versions of search and mathematical optimization, logic, and methods based on probability and economics. The AI field draws upon computer science, mathematics, psychology, linguistics, philosophy, neuroscience, artificial psychology, and many others. </p><p><strong>Need for Artificial Intelligence</strong><ol><li>1. To create expert systems that exhibit intelligent behavior with the capability to learn, demonstrate, explain, and advise its users.</li><li>Helping machines find solutions to complex problems like humans do and applying them as algorithms in a computer-friendly manner.</li></ol></p><p><strong>Approaches of AI</strong><ul><li>ere are a total of four approaches of AI and that are as follows:</p><p>◇ <strong>Acting humanly (The Turing Test approach): </strong></li><li>is approach was designed by Alan Turing. The ideology behind this approach is that a computer passes the test if a human interrogator, after asking some written questions, cannot identify whether the written responses come from a human or from a computer.</p><p>◇ <strong>Thinking humanly (The cognitive modeling approach): </strong></li><li>e idea behind this approach is to determine whether the computer thinks like a human. </p><p>◇ <strong>Thinking rationally (The “laws of thought” approach): </strong></li><li>he idea behind this approach is to determine whether the computer thinks rationally i.e. with logical reasoning. </p><p>◇ <strong>Acting rationally (The rational agent approach): </strong></li></ul>The idea behind this approach is to determine whether the computer acts rationally i.e. with logical reasoning. </p><p></p><p><strong>Applications of AI</strong> include <strong>Natural Language Processing, Gaming, Speech Recognition, Vision Systems, Healthcare, Automotive</strong>, etc. </p><p>An AI system is composed of an agent and its environment. An agent(e.g., human or robot) is anything that can perceive its environment through sensors and acts upon that environment through effectors. Intelligent agents must be able to set goals and achieve them. In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that cannot only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment. Natural language processing gives machines the ability to read and understand human language. Some straightforward applications of natural language processing include information retrieval, text mining, question answering, and machine translation. Machine perception is the ability to use input from sensors (such as cameras, microphones, sensors, etc.) to deduce aspects of the world. e.g., Computer Vision. Concepts such as game theory, and decision theory, necessitate that an agent can detect and model human emotions. </p><p>Many times, students get confused between Machine Learning and Artificial Intelligence, but Machine learning, a fundamental concept of AI research since the field’s inception, is the study of computer algorithms that improve automatically through experience. The mathematical analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as a computational learning theory. </p><p>Stuart Shapiro divides AI research into three approaches, which he calls computational psychology, computational philosophy, and computer science. Computational psychology is used to make computer programs that mimic human behavior. Computational philosophy is used to develop an adaptive, free-flowing computer mind. Implementing computer science serves the goal of creating computers that can perform tasks that only people could previously accomplish. </p><p><strong>AI has developed a large number of tools to solve the most difficult problems in computer science, like:</strong><ul><li> </p><p>◇ Search and optimization</li><li>Logic</li><li>Probabilistic methods for uncertain reasoning</li><li>Classifiers and statistical learning methods</li><li>Neural networks</li><li>Control theory</li><li>Languages</li></ul></p><p></p><p>High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), virtual assistants (such as Siri), image recognition in photographs, spam filtering, prediction of judicial decisions[204] and targeted online advertisements. Other applications include Healthcare, Automotive, Finance, Video games, etc </p><p>Are there limits to how intelligent machines – or human-machine hybrids – can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. ‘‘Superintelligence’’ may also refer to the form or degree of intelligence possessed by such an agent.</p><p></p><p><h2> Data Science</h2></p><p>In a world of data space where organizations deal with petabytes and exabytes of data, the era of Big Data emerged, the essence of its storage also grew. It was a great challenge and concern for industries for the storage of data until 2010. Now when frameworks like Hadoop and others solved the problem of storage, the focus shifted to processing of data. Data Science plays a big role here. All those fancy Sci-fi movies you love to watch around can turn into reality by Data Science. Nowadays it’s growth has been increased in multiple ways and thus one should be ready for our future by learning what it is and how can we add value to it. Without any hunches, let’s dive into the world of Data Science.</p><p>After touching to slightest idea, you might have ended up with many questions like What is Data Science? Why we need it? How can I be a Data Scientist?? etc? So let’s clear out ourselves from this baffle.</p><p></p><p></p><p><strong>What is Data Science?</strong></p><p>Data Science is kinda blended with various tools, algorithms, and machine learning principles. Most simply, it involves obtaining meaningful information or insights from structured or unstructured data through a process of analyzing, programming and business skills. It is a field containing many elements like mathematics, statistics, computer science, etc. Those who are good at these respective fields with enough knowledge of the domain in which you are willing to work can call themselves as Data Scientist. It’s not an easy thing to do but not impossible too. You need to start from data, it’s visualization, programming, formulation, development, and deployment of your model. In the future, there will be great hype for data scientist jobs. Taking in that mind, be ready to prepare yourself to fit in this world.</p><p></p><p></p><p><strong>How Data Science Works?</strong></p><p>Data science is not a one-step process such that you will get to learn it in a short time and call ourselves a Data Scientist. It’s passes from many stages and every element is important. One should always follow the proper steps to reach the ladder. Every step has its value and it counts in your model. Buckle up in your seats and get ready to learn about those steps.</p><p></p><p></p><p><strong>Problem Statement:</strong> No work start without motivation, Data science is no exception though. It’s really important to declare or formulate your problem statement very clearly and precisely. Your whole model and it’s working depend on your statement. Many scientist considers this as the main and much important step of Date Science. So make sure what’s your problem statement and how well can it add value to business or any other organization.</p><p></p><p><strong>Data Collection:</strong> After defining the problem statement, the next obvious step is to go in search of data that you might require for your model. You must do good research, find all that you need. Data can be in any form i.e unstructured or structured. It might be in various forms like videos, spreadsheets, coded forms, etc. You must collect all these kinds of sources.</p><p></p><p><strong>Data Cleaning:</strong> As you have formulated your motive and also you did collect your data, the next step to do is cleaning. Yes, it is! Data cleaning is the most favorite thing for data scientists to do. Data cleaning is all about the removal of missing, redundant, unnecessary and duplicate data from your collection. There are various tools to do so with the help of programming in either R or Python. It’s totally on you to choose one of them. Various scientist have their opinion on which to choose. When it comes to the statistical part, R is preferred over Python, as it has the privilege of more than 12,000 packages. While python is used as it is fast, easily accessible and we can perform the same things as we can in R with the help of various packages.</p><p></p><p><strong>Data Analysis and Exploration:</strong> It’s one of the prime things in data science to do and time to get inner Holmes out. It’s about analyzing the structure of data, finding hidden patterns in them, studying behaviors, visualizing the effects of one variable over others and then concluding. We can explore the data with the help of various graphs formed with the help of libraries using any programming language. In R, ggplot is one of the most famous models while matplotlib in Python.</p><p></p><p><strong>Data Modelling:</strong> Once you are done with your study that you have formed from data visualization, you must start building a hypothesis model such that it may yield you a good prediction in future. Here, you must choose a good algorithm that best fit to your model. There different kinds of algorithms from regression to classification, SVM( Support vector machines), Clustering, etc. Your model can be of a Machine Learning algorithm. You train your model with the train data and then test it with test data. There are various methods to do so. One of them is the K-fold method where you split your whole data into two parts, One is Train and the other is test data. On these bases, you train your model.</p><p></p><p><strong>Optimization and Deployment:</strong> You followed each and every step and hence build a model that you feel is the best fit. But how can you decide how well your model is performing? This where optimization comes. You test your data and find how well it is performing by checking its accuracy. In short, you check the efficiency of the data model and thus try to optimize it for better accurate prediction. Deployment deals with the launch of your model and let the people outside there to benefit from that. You can also obtain feedback from organizations and people to know their need and then to work more on your model.</p><p></p></div><div class='page'><h1 class='title level-1'>Machine Learning</h1><br/></div><div class='page'><h1 class='title level-2'>Linear Regression</h1><br/><p><h2>Linear Regression Introduction</h2></p><p><strong>Linear Regression</strong></p><p><strong>Linear Regression</strong> is a machine learning algorithm based on <strong>supervised learning</strong>. It performs a <strong>regression task</strong>. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between dependent and independent variables they are considering and the number of independent variables being used.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20220211023552/lr1.png"><img src="images/111-1.png" alt="images/111-1.png" /></a></p><p></p><p>Linear regression performs the task to predict a dependent variable value (y) based on a given independent variable (x).<span style="color:#8ff0a4;"> </span></p><p><span style="color:#8ff0a4;">So, this regression technique finds out a linear relationship between x (input) and y(output). Hence, the name is Linear Regression.</span></p><p>In the figure above, X (input) is the work experience and Y (output) is the salary of a person. The regression line is the best fit line for our model.</p><p></p><p><strong>Hypothesis function for Linear Regression :</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20220211023622/lr2.png"><img src="images/111-2.png" alt="images/111-2.png" /></a></p><p></p><p></p><p>While training the model we are given :</p><p><strong>x:</strong> input training data (univariate – one input variable(parameter))</p><p><strong>y:</strong> labels to data (supervised learning)</p><p>If the data is not univariate, then we take the dot product of the theta(one dimensional matrix of randomized values which update as the minimisation function proceeds) and the X variable(the entire dataset)</p><p></p><p>When training the model – it fits the best line to predict the value of y for a given value of x. The model gets the best regression fit line by finding the best θ1 and θ2 values.</p><p><strong>θ1:</strong> intercept</p><p><strong>θ2:</strong> coefficient of x</p><p>Once we find the best θ1 and θ2 values, we get the best fit line. So when we are finally using our model for prediction, it will predict the value of y for the input value of x.</p><p></p><p><strong>How to update θ1 and θ2 values to get the best fit line ?</strong></p><p></p><p><strong>Cost Function (J):</strong></p><p></p><p>By achieving the best-fit regression line, the model aims to predict y value such that the error difference between predicted value and true value is minimum. So, it is very important to update the θ1 and θ2 values, to reach the best value that minimizes the error between predicted y value (pred) and true y value (y).</p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20220211023741/lr3.png"><img src="images/111-3.png" alt="images/111-3.png" /></a></p><p>Cost function(J) of Linear Regression is the <strong>Root Mean Squared Error (RMSE)</strong> between predicted y value (pred) and true y value (y).</p><p>Gradient Descent:</p><p>To update θ1 and θ2 values in order to reduce Cost function (minimizing RMSE value) and achieve the best fit line the model uses Gradient Descent. The idea is to start with random θ1 and θ2 values and then iteratively update the values, reaching minimum cost.</p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Linear Regressino w3school</h1><br/><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats<br /><br />x = [<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">17</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">11</span>,<span style="color:#ff0044;font-weight:400">12</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">6</span>]<br />y = [<span style="color:#ff0044;font-weight:400">99</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">88</span>,<span style="color:#ff0044;font-weight:400">111</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">103</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">94</span>,<span style="color:#ff0044;font-weight:400">78</span>,<span style="color:#ff0044;font-weight:400">77</span>,<span style="color:#ff0044;font-weight:400">85</span>,<span style="color:#ff0044;font-weight:400">86</span>]<br /><br />slope, intercept, r, p, std_err = stats.linregress(x, y)<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myfunc</span>(x):<br />  <span style="color:#ff9d00;font-weight:700">return</span> slope * x + intercept<br /><br />mymodel = <span style="color:#ff9d00;font-weight:700">list</span>(<span style="color:#ff9d00;font-weight:700">map</span>(myfunc, x))<br /><br />plt.scatter(x, y)<br />plt.plot(x, mymodel)<br />plt.show()<br /></pre></div></p><p></p><p></p><p><h3>Example Explained</h3></p><p><h3>Import the modules you need.</h3></p><p><h3>You can learn about the Matplotlib module in our </h3><h3>Matplotlib Tutorial</h3><h3>.</h3></p><p><h3>You can learn about the SciPy module in our </h3><h3>SciPy Tutorial</h3><h3>.</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats</pre></div></p><p></p><p><h3>Create the arrays that represent the values of the x and y axis:</h3></p><p><div class="codebox"><pre>x = [<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">17</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">11</span>,<span style="color:#ff0044;font-weight:400">12</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">6</span>]<br />y = [<span style="color:#ff0044;font-weight:400">99</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">88</span>,<span style="color:#ff0044;font-weight:400">111</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">103</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">94</span>,<span style="color:#ff0044;font-weight:400">78</span>,<span style="color:#ff0044;font-weight:400">77</span>,<span style="color:#ff0044;font-weight:400">85</span>,<span style="color:#ff0044;font-weight:400">86</span>]</pre></div></p><p></p><p><h3>Execute a method that returns some important key values of Linear Regression:</h3></p><p><div class="codebox"><pre>slope, intercept, r, p, std_err = stats.linregress(x, y)<br /></pre></div></p><p><h3>Create a function that uses the </h3><code><h3>slope</h3></code><h3> and </h3><code><h3>intercept</h3></code><h3> values to return a new value. This new value represents where on the y-axis the corresponding x value will be placed:</h3></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myfunc</span>(x):<br />  <span style="color:#ff9d00;font-weight:700">return</span> slope * x + intercept</pre></div></p><p></p><p><h3>Run each value of the x array through the function. This will result in a new array with new values for the y-axis:</h3></p><p><div class="codebox"><pre>mymodel = <span style="color:#ff9d00;font-weight:700">list</span>(<span style="color:#ff9d00;font-weight:700">map</span>(myfunc, x))</pre></div></p><p></p><p><h3>Draw the original scatter plot:</h3></p><p><div class="codebox"><pre>plt.scatter(x, y)</pre></div></p><p></p><p><h3>Draw the line of linear regression:</h3></p><p><div class="codebox"><pre>plt.plot(x, mymodel)</pre></div></p><p></p><p><h3>Display the diagram:</h3></p><p><div class="codebox"><pre>plt.show()<br /></pre></div></p><p></p><p></p><p><h2>R for Relationship</h2></p><p><h3>It is important to know how the relationship between the values of the x-axis and the values of the y-axis is, if there are no relationship the linear regression can not be used to predict anything.</h3></p><p><h3>This relationship - the coefficient of correlation - is called </h3><code><h3>r</h3></code><h3>.</h3></p><p><h3>The </h3><code><h3>r</h3></code><h3> value ranges from -1 to 1, where 0 means no relationship, and 1 (and -1) means 100% related.</h3></p><p><h3>Python and the Scipy module will compute this value for you, all you have to do is feed it with the x and y values.</h3></p><p></p><p><h3>Example</h3></p><p><h3>How well does my data fit in a linear regression?</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats<br /><br />x = [<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">17</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">11</span>,<span style="color:#ff0044;font-weight:400">12</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">6</span>]<br />y = [<span style="color:#ff0044;font-weight:400">99</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">88</span>,<span style="color:#ff0044;font-weight:400">111</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">103</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">94</span>,<span style="color:#ff0044;font-weight:400">78</span>,<span style="color:#ff0044;font-weight:400">77</span>,<span style="color:#ff0044;font-weight:400">85</span>,<span style="color:#ff0044;font-weight:400">86</span>]<br /><br />slope, intercept, r, p, std_err = stats.linregress(x, y)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(r)</pre></div></p><p></p><p><strong><h3>Note:</h3></strong><h3> The result -0.76 shows that there is a relationship, not perfect, but it indicates that we could use linear regression in future predictions.</h3></p><p></p><p></p><p><h2>Predict Future Values</h2></p><p><h3>Now we can use the information we have gathered to predict future values.</h3></p><p><h3>Example: Let us try to predict the speed of a 10 years old car.</h3></p><p><h3>To do so, we need the same </h3><code><h3>myfunc()</h3></code><h3> function from the example above:</h3></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myfunc</span>(x):<br />  <span style="color:#ff9d00;font-weight:700">return</span> slope * x + intercept</pre></div></p><p></p><p></p><p><h3>Example</h3></p><p><h3>Predict the speed of a 10 years old car:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats<br /><br />x = [<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">7</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">17</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">11</span>,<span style="color:#ff0044;font-weight:400">12</span>,<span style="color:#ff0044;font-weight:400">9</span>,<span style="color:#ff0044;font-weight:400">6</span>]<br />y = [<span style="color:#ff0044;font-weight:400">99</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">88</span>,<span style="color:#ff0044;font-weight:400">111</span>,<span style="color:#ff0044;font-weight:400">86</span>,<span style="color:#ff0044;font-weight:400">103</span>,<span style="color:#ff0044;font-weight:400">87</span>,<span style="color:#ff0044;font-weight:400">94</span>,<span style="color:#ff0044;font-weight:400">78</span>,<span style="color:#ff0044;font-weight:400">77</span>,<span style="color:#ff0044;font-weight:400">85</span>,<span style="color:#ff0044;font-weight:400">86</span>]<br /><br />slope, intercept, r, p, std_err = stats.linregress(x, y)<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myfunc</span>(x):<br />  <span style="color:#ff9d00;font-weight:700">return</span> slope * x + intercept<br /><br />speed = myfunc(<span style="color:#ff0044;font-weight:400">10</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(speed)</pre></div></p><p><a href="https://www.w3schools.com/python/trypython.asp?filename=demo_ml_r_squared2">Run example »</a></p><p><h3>The example predicted a speed at 85.6, which we also could read from the diagram:</h3></p><p><a href="https://www.w3schools.com/python/img_linear_regression2.png"><img src="images/116-1.png" alt="images/116-1.png" /></a></p><p><h2>Bad Fit?</h2></p><p><h3>Let us create an example where linear regression would not be the best method to predict future values.</h3></p><p></p><p><h3>Example</h3></p><p><h3>These values for the x- and y-axis should result in a very bad fit for linear regression:</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats<br /><br />x = [<span style="color:#ff0044;font-weight:400">89</span>,<span style="color:#ff0044;font-weight:400">43</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">95</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">66</span>,<span style="color:#ff0044;font-weight:400">34</span>,<span style="color:#ff0044;font-weight:400">38</span>,<span style="color:#ff0044;font-weight:400">20</span>,<span style="color:#ff0044;font-weight:400">26</span>,<span style="color:#ff0044;font-weight:400">29</span>,<span style="color:#ff0044;font-weight:400">48</span>,<span style="color:#ff0044;font-weight:400">64</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">66</span>,<span style="color:#ff0044;font-weight:400">72</span>,<span style="color:#ff0044;font-weight:400">40</span>]<br />y = [<span style="color:#ff0044;font-weight:400">21</span>,<span style="color:#ff0044;font-weight:400">46</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">35</span>,<span style="color:#ff0044;font-weight:400">67</span>,<span style="color:#ff0044;font-weight:400">95</span>,<span style="color:#ff0044;font-weight:400">53</span>,<span style="color:#ff0044;font-weight:400">72</span>,<span style="color:#ff0044;font-weight:400">58</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">26</span>,<span style="color:#ff0044;font-weight:400">34</span>,<span style="color:#ff0044;font-weight:400">90</span>,<span style="color:#ff0044;font-weight:400">33</span>,<span style="color:#ff0044;font-weight:400">38</span>,<span style="color:#ff0044;font-weight:400">20</span>,<span style="color:#ff0044;font-weight:400">56</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">47</span>,<span style="color:#ff0044;font-weight:400">15</span>]<br /><br />slope, intercept, r, p, std_err = stats.linregress(x, y)<br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">myfunc</span>(x):<br />  <span style="color:#ff9d00;font-weight:700">return</span> slope * x + intercept<br /><br />mymodel = <span style="color:#ff9d00;font-weight:700">list</span>(<span style="color:#ff9d00;font-weight:700">map</span>(myfunc, x))<br /><br />plt.scatter(x, y)<br />plt.plot(x, mymodel)<br />plt.show()</pre></div></p><p></p><p><h3>Result:</h3></p><p><a href="https://www.w3schools.com/python/img_linear_regression_badfit.png"><img src="images/116-2.png" alt="images/116-2.png" /></a></p><p><a href="https://www.w3schools.com/python/trypython.asp?filename=demo_ml_bad_fit">Run example »</a></p><p><h3>And the </h3><code><h3>r</h3></code><h3> for relationship?</h3></p><p></p><p><h3>Example</h3></p><p><h3>You should get a very low </h3><code><h3>r</h3></code><h3> value.</h3></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy</span> <span style="color:#333333;font-weight:400">import</span> stats<br /><br />x = [<span style="color:#ff0044;font-weight:400">89</span>,<span style="color:#ff0044;font-weight:400">43</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">95</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">66</span>,<span style="color:#ff0044;font-weight:400">34</span>,<span style="color:#ff0044;font-weight:400">38</span>,<span style="color:#ff0044;font-weight:400">20</span>,<span style="color:#ff0044;font-weight:400">26</span>,<span style="color:#ff0044;font-weight:400">29</span>,<span style="color:#ff0044;font-weight:400">48</span>,<span style="color:#ff0044;font-weight:400">64</span>,<span style="color:#ff0044;font-weight:400">6</span>,<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">36</span>,<span style="color:#ff0044;font-weight:400">66</span>,<span style="color:#ff0044;font-weight:400">72</span>,<span style="color:#ff0044;font-weight:400">40</span>]<br />y = [<span style="color:#ff0044;font-weight:400">21</span>,<span style="color:#ff0044;font-weight:400">46</span>,<span style="color:#ff0044;font-weight:400">3</span>,<span style="color:#ff0044;font-weight:400">35</span>,<span style="color:#ff0044;font-weight:400">67</span>,<span style="color:#ff0044;font-weight:400">95</span>,<span style="color:#ff0044;font-weight:400">53</span>,<span style="color:#ff0044;font-weight:400">72</span>,<span style="color:#ff0044;font-weight:400">58</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">26</span>,<span style="color:#ff0044;font-weight:400">34</span>,<span style="color:#ff0044;font-weight:400">90</span>,<span style="color:#ff0044;font-weight:400">33</span>,<span style="color:#ff0044;font-weight:400">38</span>,<span style="color:#ff0044;font-weight:400">20</span>,<span style="color:#ff0044;font-weight:400">56</span>,<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">47</span>,<span style="color:#ff0044;font-weight:400">15</span>]<br /><br />slope, intercept, r, p, std_err = stats.linregress(x, y)<br /><br /><span style="color:#ff9d00;font-weight:700">print</span>(r)<br /><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Gradient Descent in Linear Regression</h1><br/><p><small>Gradient Descent in Linear Regression</small></p><p>In linear regression, the model targets to get the best-fit regression line to predict the value of y based on the given input value (x). While training the model, the model calculates the cost function which measures the Root Mean Squared error between the predicted value (pred) and true value (y). The model targets to minimize the cost function. </p><p>To minimize the cost function, the model needs to have the best value of θ<sub>1</sub> and θ<sub>2</sub>. Initially model selects θ<sub>1</sub> and θ<sub>2</sub> values randomly and then iteratively update these value in order to minimize the cost function until it reaches the minimum. By the time model achieves the minimum cost function, it will have the best θ<sub>1</sub> and θ<sub>2</sub> values. Using these finally updated values of θ<sub>1</sub> and θ<sub>2</sub> in the hypothesis equation of linear equation, the model predicts the value of x in the best manner it can. </p><p>Therefore, the question arises – <strong>How do θ</strong><strong><sub>1</sub></strong><strong> and θ</strong><strong><sub>2</sub></strong><strong> values get updated?</strong> </p><p><strong>Linear Regression Cost Function:</strong><a href="https://media.geeksforgeeks.org/wp-content/uploads/LR-cost-function-2.jpg"><img src="images/112-1.png" alt="images/112-1.png" /></a></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/LR-cost-function-1.jpg"><img src="images/112-2.png" alt="images/112-2.png" /></a></p><p><strong>Gradient Descent Algorithm For Linear Regression</strong> </p><p> </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102821/WhatsAppImage20221118at102308.jpeg"><img src="images/112-3.png" alt="images/112-3.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102820/WhatsAppImage20221118at102301.jpeg"><img src="images/112-4.png" alt="images/112-4.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102820/WhatsAppImage20221118at102303.jpeg"><img src="images/112-5.png" alt="images/112-5.png" /></a>  </p><p> <div class="codebox"><pre><br />-&gt; θj     : Weights of the hypothesis.<br />-&gt; hθ(xi) : predicted y value <span style="color:#ff9d00;font-weight:700">for</span> ith <span style="color:#ff9d00;font-weight:700">input</span>.<br />-&gt; j     : Feature index number (can be <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, ......, n).<br />-&gt; α     : Learning Rate of Gradient DescentWe graph cost function <span style="color:#333333;font-weight:400">as</span> a function of parameter estimates i.e. <br />parameter <span style="color:#ff9d00;font-weight:700">range</span> of our hypothesis function <span style="color:#ff9d00;font-weight:700">and</span> the cost resulting <span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">selecting</span> a particular <span style="color:#ff9d00;font-weight:700">set</span> of parameters. <br />We move downward towards pits <span style="color:#ff9d00;font-weight:700">in</span> the graph, to find the minimum value. The way to do this <span style="color:#ff9d00;font-weight:700">is</span> taking derivative of cost <br />function <span style="color:#333333;font-weight:400">as</span> explained <span style="color:#ff9d00;font-weight:700">in</span> the above figure. Gradient Descent step-downs the cost function <span style="color:#ff9d00;font-weight:700">in</span> the direction of the steepest <br />descent. The size of each step <span style="color:#ff9d00;font-weight:700">is</span> determined by parameter α known <span style="color:#333333;font-weight:400">as</span> Learning Rate. </pre></div><ul><li> the Gradient Descent algorithm, one can infer two points : </p><p> </p><p>• <strong>If slope is +ve</strong> : θ<sub>j</sub> = θ<sub>j</sub> – (+ve value). Hence value of θ<sub>j</sub></li></ul> decreases.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/theta-decrease.jpg"><img src="images/112-6.png" alt="images/112-6.png" /></a><ul><li><strong>If slope is -ve</strong> : θ<sub>j</sub> = θ<sub>j</sub> – (-ve value). Hence value of θ<sub>j</sub></li></ul> increases.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/theta-increase.jpg"><img src="images/112-7.png" alt="images/112-7.png" /></a><ul><li>e choice of correct learning rate is very important as it ensures that Gradient Descent converges in a reasonable time. : </p><p> </p><p>◇ If we choose <strong>α to be very large</strong></li></ul>, Gradient Descent can overshoot the minimum. It may fail to converge or even diverge. </p><p> </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/big-learning.jpg"><img src="images/112-8.png" alt="images/112-8.png" /></a><ul><li>If we choose α to be very small, Gradient Descent will take small steps to reach local minima and will take a longer time to reach minima. </li></ul></p><p> </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/small-learning.jpg"><img src="images/112-9.png" alt="images/112-9.png" /></a></p><p>For linear regression Cost, the Function graph is always convex shaped</p><p></p></div><div class='page'><h1 class='title level-3'>Updating the Parameters in Linear Regression</h1><br/><p><small>Updating the Parameters in Linear Regression</small></p><p><strong>Steps to update Parameter in Linear Regression</strong></p><p> </p><p><strong>Step 1:</strong></p><p><strong>Forward Propagation :</strong></p><p><strong>let the hypothesis function be y=mx+c</strong></p><p> </p><p><strong>Step 2:</strong></p><p><strong>Differentiation of Cost Function with respect to slope and constant :</strong></p><p>To find out the best fit line we have to minimize the cost function, we differentiate the cost function with respect to slope and constant &quot;J&quot;</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102821/WhatsAppImage20221118at102308.jpeg"><img src="images/113-1.png" alt="images/113-1.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102820/WhatsAppImage20221118at102301.jpeg"><img src="images/113-2.png" alt="images/113-2.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221118102820/WhatsAppImage20221118at102303.jpeg"><img src="images/113-3.png" alt="images/113-3.png" /></a></p><p></p></div><div class='page'><h1 class='title level-2'>Multiple Regression</h1><br/><p><small>Multiple Linear Regression Intuition</small></p><p>Now that you are reminded what simple linear regression, we can move onto multiple linear regression. MLR is same thing but with more than one input variables. Here it is how it looks in mathematical equation.</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221116173202/Screenshot20221116172521.jpg"><img src="images/115-1.png" alt="images/115-1.png" /></a>  </p><p>Depending on where you look, all variables can have different names, but I’ll try to keep it simple with other commonly used terms.</p><p>y — value we want to predict/dependent variable/predicted value</p><p>Xi — features / independent variable / expanatory variable / observed variable</p><p>Wi — coefficient for feature</p><p>b- bias /constant value</p><p>So simplified, we are predicting what value of y will be depending on features Xi and with coefficients Wi we are deciding how much each feature is affecting predicted value.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221116175444/Screenshot20221116175406.jpg"><img src="images/115-2.png" alt="images/115-2.png" /></a> Why is it called linear regression?</p><p>There are multiple features, but all coefficients and features in equation are linear. No variable has exponential higher than one. And that is why it is called linear. Otherwise we would have polynomial regression.</p><p><strong>Gradient Descent</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221116204044/Screenshot20221116203943.jpg"><img src="images/115-3.png" alt="images/115-3.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Linear Regression Model Assumption</h1><br/><p><small>Linear Regression Model Assumption</small></p><p>In the Linear Regression algorithm you have to take some assumption as it is a parametric approach which means it gives wrong output on some dataset which will not fulfill its condition&#39;s ,</p><p> </p><p><strong>Assumptions of Multiple  Linear Regression:</strong></p><p> </p><p><strong>Simple Linear Regression:</strong></p><p>(1)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-996c91e490d3c5b52640bbacc8390fe7_l3.svg"><img src="images/117-1.png" alt="images/117-1.png" /></a></p><p>(2)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0854aa5aa3c22e2f687e94de2e2876b1_l3.svg"><img src="images/117-2.png" alt="images/117-2.png" /></a><ol><li>uld be always be linear of degree &#39;1&#39;  else it gives poor result.</p><p>1. Error has zero meane</li><li>Error has constant variance</li><li>Errors are uncorrelated</li><li>Errors are normally distributedThe <em>second assumption</em> is known as <strong>Homoscedasticity</strong> and therefore, the violation of this assumption is known as <strong>Heteroscedasticity</strong></li></ol>.</p><p></p><p><h2>Homoscedasticity </h2><em><h2>vs</h2></em><h2> Heteroscedasticity:</h2></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190425172205/hetero.jpg"><img src="images/117-3.png" alt="images/117-3.png" /></a></p><p>Therefore, in simple terms, we can define <strong>heteroscedasticity</strong> as the condition in which the variance of error term or the residual term in a regression model varies. As you can see in the above diagram, in case of homoscedasticity, the data points are equally scattered while in case of heteroscedasticity the data points are not equally scattered.</p><p></p><p><h3>Possible reasons of arising Heteroscedasticity:</h3><ol><li>Often occurs in those data sets which have a large range between the largest and the smallest observed values i.e. when there are outliers.</li><li>When model is not correctly specified.</li><li>If observations are mixed with different measures of scale.</li><li>When incorrect transformation of data is used to perform the regression.</li><li>Skewness in the distribution of a regressor, and may be some other sources.</li></ol></p><p></p><p><h3>Effects of Heteroscedasticity:</h3><ul><li>As mentioned above that one of the assumption (assumption number 2) of linear regression is that there is no heteroscedasticity. Breaking this assumption means that <em>OLS (Ordinary Least Square)</em> estimators are not the <em>Best Linear Unbiased Estimator(BLUE)</em></li><li>nd their variance is not the lowest of all other unbiased estimators.</p><p>• Estimators are no longer <em>best/efficient.</em></li><li>The tests of hypothesis (like t-test, F-test) are no longer valid due to the inconsistency in the co-variance matrix of the estimated regression coefficients.</li></ul></p><p></p><p><strong>Identifying Heteroscedasticity with residual plots:</strong></p><p>As shown in the above figure, heteroscedasticity produces either outward opening funnel or outward closing funnel shape in residual plots.</p><p><strong>Identifying Heteroscedasticity Through Statistical Tests:</strong><ol><li> presence of heteroscedasticity can also be quantified using the algorithmic approach. There are some statistical tests or methods through which the presence or absence of heteroscedasticity can be established.</p><p>1. <strong>The Breush – Pegan Test:</strong></li><li> tests whether the variance of the errors from regression is dependent on the values of the independent variables. In that case, heteroskedasticity is present.</p><p>2. <strong>White test:</strong></li></ol> White test establishes whether the variance of the errors in a regression model is constant. To test for constant variance one undertakes an auxiliary regression analysis: this regresses the squared residuals from the original regression model onto a set of regressors that contain the original regressors along with their squares and cross-products.</p><p></p><p><h3>Corrections for heteroscedasticity:</h3><ol><li>We can use different specification for the model.</li><li>Weighted Least Squares method is one of the common statistical method. This is the generalization of ordinary least square and linear regression in which the errors co-variance matrix is allowed to be different from an identity matrix.</li><li><strong>Use MINQUE:</strong> The theory of <em><strong>Minimum Norm Quadratic Unbiased Estimation (MINQUE)</strong></em></li></ol> involves three stages. First, defining a general class of potential estimators as quadratic functions of the observed data, where the estimators relate to a vector of model parameters. Secondly, specifying certain constraints on the desired properties of the estimators, such as unbiasedness and third, choosing the optimal estimator by minimizing a “norm” which measures the size of the covariance matrix of the estimators.</p><p> </p><p><strong>Normality Distribution:</strong></p><p><strong> </strong>The data should in distributed normally such that the curve formed is bell shaped, means most of the errors in standard deviation graph should lies close to zero meanwhile we want error to be minimum as much as possible.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221119015907/WhatsAppImage20221118at144720.jpg"><img src="images/117-4.png" alt="images/117-4.png" /></a> <strong>Skewed Normal Distribution</strong></p><p><strong>when the data distributed in such a way that the curve tilt towards right and error increases significantly is called skewed distribution</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221119020138/WhatsAppImage20221118at144719.jpg"><img src="images/117-5.png" alt="images/117-5.png" /></a> </p></div><div class='page'><h1 class='title level-3'>Ordinary Least Square Method</h1><br/><p><small>Ordinary Least Square (OLS) Method</small></p><p><strong>Ordinary Least square method</strong></p><p>linear regression model establishes the relation between a dependent variable(<strong>y</strong>) and at least one independent variable(<strong>x</strong>) as : </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7075f811f3eaa335e9d3a956f5f6948d_l3.svg"><img src="images/118-1.png" alt="images/118-1.png" /></a></p><p>In <em>OLS</em> method, we have to choose the values of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7118fbdddf94fd5553ee143a70ae121e_l3.svg"><img src="images/118-2.png" alt="images/118-2.png" /></a>and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-3d165f3c53f7a87ac61f8e3811eec980_l3.svg"><img src="images/118-3.png" alt="images/118-3.png" /></a>such that, the total sum of squares of the difference between the calculated and observed values of y, is minimised. </p><p><strong>Formula for OLS:</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dddc9ec080651e4f62e0882944d69319_l3.svg"><img src="images/118-4.png" alt="images/118-4.png" /></a></p><p>Where, </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-03e9200a494b6ca42bfdf3a2bbe6ecff_l3.svg"><img src="images/118-5.png" alt="images/118-5.png" /></a>= predicted value for the ith observation </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-2da261491bec63e05837d994c62b0bc5_l3.svg"><img src="images/118-6.png" alt="images/118-6.png" /></a>= actual value for the ith observation </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d35b88fba7d36ec59218ce98bf43cc64_l3.svg"><img src="images/118-7.png" alt="images/118-7.png" /></a>= error/residual for the ith observation </p><p>n = total number of observations</p><p>To get the values of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-3d165f3c53f7a87ac61f8e3811eec980_l3.svg"><img src="images/118-8.png" alt="images/118-8.png" /></a>and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7118fbdddf94fd5553ee143a70ae121e_l3.svg"><img src="images/118-9.png" alt="images/118-9.png" /></a>which minimise S, we can take a partial derivative for each coefficient and equate it to zero.</p><p>The important part of OLS are their summary results,</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221120181753/OLS.jpg"><img src="images/118-10.png" alt="images/118-10.png" /></a> <strong>1. R-squared Value:</strong></p><p><strong>R-squared</strong> is a statistical measure that represents the goodness of fit of a regression model. The ideal value for r-square is 1. The closer the value of r-square to 1, the better is the model fitted.</p><p>R-square is a comparison of the residual sum of squares <em>(SS</em><em><sub>res</sub></em><em>) or RSS</em> with the total sum of squares<em>(SS</em><em><sub>tot</sub></em><em>) or TSS</em>. The total sum of squares is calculated by summation of squares of perpendicular distance between data points and the average line.</p><p> </p><p> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20190415230935/average-fitted-model1.png"><img src="images/118-11.png" alt="images/118-11.png" /></a> </p><p>The residual sum of squares is calculated by the summation of squares of perpendicular distance between data points and the best-fitted line. </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190415232400/best-fitted-model.png"><img src="images/118-12.png" alt="images/118-12.png" /></a> </p><p>R square is calculated by using the following formula :</p><p> <a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZwAAAB6CAMAAAC89RUgAAABs1BMVEX/////+/8AAAD//f/a2tq+vr55eXmtqa3p6enLy8vi4uKbm5vCwsKDg4NkZGRgXWCzr7MHAAf18fWSjpInIif5//+/z+L///uRkZH39/cfHx/x8fEAABBoe6Csu9iRdGEAACxQUFAQAAAqAADp1L01AAATAAC0tLQAACIAABk2NTMAACYAADD/9evh7fmMc1RAQEAbAAAPDw/w+f////Owucjn28ZKSkr/9+I7Wnx1jqQtOlW7p5KwxNk5UW2DbFbs6+ExHQAtLynPvaImKitIHQAANmgZNFgAFi9qgJxJa4VFEQA2UnybhF7z49KJnbxSMhEXSWpdNAB0Xz2qqJ5RQ0HHtKFOVF1YY3GdhnNCVGXR4Ox3UimFYz6Xm6Lj2tF4bmI3OkJiUzxeU0uKgHXE0NuynX2hlooAADpGMxZTYXdneYkAIDgAGUK3yuMEJV8jGwCRgVgdMlFaPiJAOClMMABXKgAhDwAAHkBsSwBYQRCTrMNaPwReTC9IapAdMkkAAEh3ips1DgB1WiFydWw4KxkvW4ZvSy7UxrgTHi0+RmYhIktXQC91VD8qGQNvXVApLlJoS5C+AAAQLklEQVR4nO1di18TSRLu1EAggSQCwiQEFwkR5THhkRBQouCGVTkluoaLC4jRVYOK6L58nKzr6h5n9FD3T77unldnMjN5yJCQm+/3A5IhzFTVV11d3V3dIGTDhg0bNowQdJOv7lqLcQBobcVf7lpLUQkSAGfx17mGZ4efB4j0A5yptSDlIzW3cP7b093jfZFaS2I1kktxWDzDf3eh1oJUglToIkLjlxq+5WB6YAnxJ/5RazEqQRLOInT5Sq3FOAAsQxSl4GqtxagEyxA5bCJXB/7a98QVe2otRyW4joNwBnqCDR/XBBzV0Pjx7tZaC1I+ZonICWgZOlQeVQ3CJH6nL60MR2stSdlIDWCRU/+8cb/WgliOzA2ckeYnfjg83NiwYcOGDRtWo7XJAIco0SwPbiNNA7WWzBB+MIC/1pLtNyaMNHXVWjJDBKcAFls1cDsbkBwX5sEb1GjaNFHP5FCZPUVXBxqPHBokmrUXA3VNDmrTk7m9AclBPqxpUVfqqWtycCsBCGquBRuRnCBWdEJ7sb2+yQnoyTzRVgtRLIZeCA9O1TU5Bt1OI4J0O+21FqJC+Os6odxPkBBev+MaffgOSOag62R7TSeDSQifsfYR+64jkXlgP2+oj1VY84f61q1/kDFcVo+viY6TsK86EpmtTwFunkYoThb1agirQ/jGFaLjsX29Z5uhzEJbFW7QxHS7C7fYcqtUjckx6XayXVUv0een2T8VZHIyMwMDMxM3uiQLZm/39i7euEU+ym+O9PbecZa5tIllntKTOQFrlZODqfYqbxZ+ZAv4ctVWVuRnBmaIrviL3i5/F2v6wzR9wj2idFd5kZ6EcK/O9dhtqH5xNPNilLGzqmMO5lyuTRDfJ2HufmsCHmByhGsw7c4+hG/Ku72BzOMwXbmoTjjpYodOeVCKxJKwU/n9KJbhkSsDl+67fqS3WIatJnc/4ECJo8jj+615gDLrIfVDeOzhqYqdsAV6KaY8xFBn5cthtYYpR19mgFScCbBN2sx7IrL46WS5IuvLnKjCloGBATLh4JxSpx2SsrjJ6muvrn9P1D5NvvWQb4TvGBGPfzZMdBzfLjcokRDepL2YrqITD7LrKxvyDeKMjml4goiwT5FYy4iRx00sdh6IsMKtsh/lL5Z5Fs5VLDFCUn/jYqJkWvSRePXcxAgl1BHDRLFl0VFXIuSmVMhs+U0ch/BezaXkV9dOC6Hv6U8248EkROnNL9Lvp5XrP5XdZmQUy5yT2iq/6SWq5/1tZfRgm84d8bOMtcJUd4HYNrVVoVgMPlFHJPhZpTkOv1TYkeuE8LRUJL5wz0kawGabv3RDyju3sOkFf9st2leN06YjEE1lHVNACUvT+JMCNQy9h7mC/g3fRIWulxGZnewF/ldKPOJfT9CILrwq7V98+k6ISBlIA1ONHBskBtyAiZERqL5IWTiv1JoloE/udIVJTQKYZRTV9yYSwk+yF+QQkQrNUC/PhtQuxAjJjt/ogxNwikolNr5xqqMUcJIkbeNX4Q/6bhlgS3KjOMAHlv0Uu/p3UfdxLs38tDAptdRH+JmE9Y3SrTG1JvWC4wVBnMQ1ftNDUEWGISEuOiIB/0r1wwTAGuuHCVZTfW/ya+Z65aiWuIquER1j7y6Wao38/HoK3nSTqCD6xix8RBodl2F44lu4I2uMBduWDJg6D5V2557CeYI4m2UtEf//o+DjC83tKtTuKkw8hX9W0F3170dtcoIZ3JFtNnIMzwAMV9idjxTOEzCJzzLJb+May2UZRZuVNSH+2akIif2iwWODH7SEPoezTf2Mf2RfKJ04kb8imVunChd2wmq8SJG7itXfiUW5+SRZF1WjlTCEHSpOu4dMryTAarkpvRmWC0yWUZvFwi68rKjfadfMsOVU8TLkrsunyO3m19QnM1CFmMcG4Z9JHstfPq6JK7OAb8NPMuEmDsPKm9dMdsSzFSf6m+5mNPPpYdVTYw//7EbXqav+C2Q7BNwM1DVG/hWWcoNGoA2IFmlfPZ4X+lqCZqgUs5NMy1woWUUU1C4vMuKlcLsXKAGCml4FWU2jzJ/tMIOV51pyaOaPbcB0X69UFdgEsaDP+UVPZL92VSfMNIdPEAmXm//1w3pc02b7S3ewJUEdseD9mPL+Z+b+pfucCe2qTk5tDrHBN2i5zHZIktDv5OjCn7ikmWEQO98cjT/h/9Jb/o4DIf/6rCgm03JcDIrGYIikA9r10BRDTg56rhNFU767Jc2cgCc3l+hnfbLO8/swURtWPDlHDTILF/AzjlOLbLAth9VUL0b4C5NSVDjYfrXtpjfL+AZKyTwLfyRHZUZiND1gkZbmAUj6laMGoO4+Sz2Gv1bBFs9gcfWD8OJP5XUSvhX9tIzJsTCMiNllQvZn/vfRr99smlOawXvq2avEoknat6UM8k9duGBEeykMaqqzCj9Rn+RvQsm5thOX1BYbV6OgiDxutwFxfBPAncFoi+serHXTrnrLtfK5khRpoDDzp/ik+ntKmr1Dq6dKmnkWJJETciCsbqqhENlJeCT2FHhkM9fc/AXeItpV33JtwpsKvHCquAYnduKx4vVJOVpeL72nd4MhVTvVJfj9fg8ZZq34Pesou+Lx+sRZ6GCz3+nz3qpglrWtqKmjgqmwWdltb5b20Vk5y9t40K0veBXgN7Gy4oiBd7U5vb4uqqmbKj1dQa6m54Vsqi/vSJwtY0YnfVw18euKp2TKRRMs6lzln8sRlf9Vcv1YqPR6zCd5PmVQ6rNi78YqnGGxDrpeKA4VpFcSJ+EyJgmY0BS2bKEq0Au62bUYR1ujKD0WlWUwFznYicZlF0rJ7WW8frbH6nuhnDu5kfBOyTrMWwLfhDsVNR4Ig5WNtCqAF1r0f5GHc1H019yesvKfgfVVsyHLz29+VJgIQ08Cqyykq1kUsggGXki4eIsTLu+QMm/T/zJw14SeMPybaSvZwW2rglqL7togxcIXWD8BPyhPDgM8MnOR57CmfDZFJ73izJWaw9ALsR/uQRPAW0W5nPnsVwI+qC63zPzdPqMJek0Ko4KBAPvbVvOdOwWfDZLP8tpa3xrCxAsxWguld3ea3YovUNS6wrLF4oXBoN4w9dDDrVMnUefnR3l1ltT9h64wshz0FnshGikakdYTToKv+OIMHLwglsOp44UB00BXa7j1yrgC0IDknNSranXpDnvqBSM6TR1HNW0FxOGHW1engXomxwO9HqcWAzo7dg49RmCmWNORet792my0x1inHzrc8BhpWr/bxIwkrufGXhWaDDUt2hBbN2g2QqONc4KGmjbccRg2Dgp1NL1iLQKHT1O9dedGnB5AKH2IDieUkCs66Dv/8FCd61s25ouWwzJfv0J7sMh+gX3eNlcn4LQX8ruwH+V01iG1q10qT+zEBhuRnOSQskdBBH/7fri+yRHXnZWKw/+QS0JDkkMP+1YrDmnpSr2TQ5fKA3INHl2NblBy3pMK4VZZU7o6W+/k/PW06FJjkiNMFpfH1Dk5YqnTgs8rgvY/jUlOnNYN5SVNfbSIqM7JIeVLHFpwekTQzLIxyUnAOk/2CoqKOungrs7JCcNOWrOLNpCHcxZWLNQKOWif1Ay3Awl4W8+KCntTmnFYeHFxYmSkgsJwEVwdwFTA+O4HzQbRBNW0xieKHAgcdQBzdv6PUWtiCGxyDHAwducK3kvvlOfb5BjAYm6kYXKnRAgKNh850t6JKDWuI0eam5BNjjEsJkeYh76BgRGYi3CEhFW44bkL8AQ5UP7dB6dzCI4hmxxDWEuOQzriJoG/4zfiVtj54QiHUpPkpBKyG8MmxxBWk0OOqcAN6LsHEY7jT8x1cw6UuYIbzir0kOvne2xyjGE1OeSYCULONiYnBR/FLgZfH+8TaeEcNjmGsJqcm8PruJ2E4SMebAqh4SfSA9F4xzElh7PJMYC13HCzQ+SUBWGP5ACkuZyaFinBdIWWHMgmxxTWkoM5uOhqb9v9cJbGM/5LB0gNBmVCobl1ZJNjBovJSfStOXdBbiMcTttCx8TXKLs7NRbhbHJMYDE59ICmvVMRqXvhUL6DpGn0d8JeaMmeITCDpdxw/DPcOHDGdpXOCRCG0DhJ3+hz6ak4NjkmsJYccogD7l7oPAB/pJOjA9FvEMreR/S3V2xyzKBjUYPrVUCkBZPwdzeHUnTYSQ4Z49B1nBZw+LdXbXLMUMyNw+V3dq3vCztovgObn+Mv4/ENpuJRFDlIiOOEwdEehPKf56J2QmCGYoO+75h2vYb9YAf3L9C3g+jPHZT5DTom4M00aUp3h+DOLrwVubHJMYJoRnG5WLLoN+LR8WVYn+NK/B6Jizf0B35WZ2snktYIOsmpFZz6MRs6EK3jkNbyRUs6aHlLaWpQp6MEO1ouVTYLXtfaCPUKah00P3UUAO5sRaQO+tMv0ZJmR2hTHrJ8JWxyDCBaJ7YLPY7gJvwdpWti/WORUlbHw8mHfTY51kK0jrD7oJvj6D8dwE1iebRkOsAJ82MtezY51oJaB4VDp5Eyes9hbkqT09VND3G0ybEQIjnkwD88HiFNAeVxhOtMLClm1/k8NShnk2M1RPuLB0aSf7XE8ddgCicHCjko41Mx8IRhwybHalDr8M/H1jvdK/AxwnEB8f8yrMvZWgE5PmNyCu7K6VwzlsAmxwDUc1Nw9M5ReDzNccVlgAZhTUsOWuliIC4RoJYycATZ5BiBGjEPx1Dw07B+jlbwcXb0U0jOp6MqRiVyDM9GYXDUJscQ1Ij0P7Fk4A89clC25YiClnWGHTusWQ3R62EdcanQnN60AGauQ0HBrI6dEFgNYhvh4XaUw2na8YgOOVwniwLa5m1yrIWDLhefI7PG8/qznQX7nBhqEP+6Y6ewF7LJ2V9g02T3YHSajkSHd8o2Ncp4fwPouLGl19oYBtknKTQwL+2KTxNg07jJJg0Oxy+X637Z5HDZdrq5o73T5E9QpqvLgzNrj6fLQ6oGkHvT6/N20QICrtnr83loXYFNjgFkx5V+lsuNalHThvMetlruwVpL22eytIoTwrVp1224QKqn9+CWa+UF2IXsJiifjcrBCZ+PSf8CbfUlTjkEOMeRf5K2RFau+8iJNrnhqN1yjGElOSiPR6Mo3UH+PTXZ9pGgu3HQag/ihCGy4QDlz9g720xgJTkORyfO0C8/jnBcEPct4tw3XQfnZoFs1XHYe0JNYS05mBFaV0hLQXCX81IuXedP9J2xt4CUgrXkUEbOyA/BAyNlC0gGQltRewuIOSwnZ1wd2nIBZgtIYij0d8TeAmIKq8nh9yDC1EAlQK6II1tALnJ2xacZLOaGE85fYIdCKBF6Ku88FHbhiZ0QmMFicuh/DpZeipOsu2OkzodWL+akiGeTYwCryUkoYSxPyhIwOU/xKMcb4WxySsNqcjb6pLID1H+xG3E0eaOnx3JI2Nu2dxmYwmJu4tBxViLnV3i07l6BtShJC15Ot7qUmkSbHANYyg2XuuF0+kQKuJMer8/nJeMclPU78eu3EXucY46DOIOw4DxC9mjCck4qtGFDxv8AzewjMDPHVpoAAAAASUVORK5CYII="><img src="images/118-13.png" alt="images/118-13.png" /></a></p><p> </p><p><strong>RSS is the residual sum of squares-: </strong>it is simple a cost function or defines as the deviation of predicted value from actual value.</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20220204144456/Screenshot20220204at24044PM.png"><img src="images/118-14.png" alt="images/118-14.png" /></a> </p><p><strong> TSS is the total sum of squares</strong>.-: defines as the deviation of actual value from the mean value.</p><p><a href="https://timeseriesreasoning.files.wordpress.com/2021/06/f70e6-1gzsnbi_wkdfzkjhz9esx0g.png"><img src="images/118-15.png" alt="images/118-15.png" /></a>The goodness of fit of regression models can be analyzed on the basis of the R-square method. The more the value of r-square near 1, the better is the model. </p><p> </p><p><strong>Note:</strong> The value of R-square can also be negative when the model fitted is worse than the average fitted model.</p><p><strong>F-Test:</strong></p><p>F-Test is any test that utilizes the F-Distribution table to fulfil its purpose (for eg: ANOVA). It compares the ratio of the variances of two populations and determines if they are statistically similar or not. </p><p><strong>Null hypothesis</strong> suggests that there is no relationship between the two variables. Null hypothesis is also exactly the opposite of the alternative hypothesis. Null hypothesis is generally what researchers or scientists try to disprove and if the null hypothesis gets accepted then we have to make changes in our opinion i.e. we have to make changes in our original opinion or statement in order to match null hypothesis. Null hypothesis is represented as H0. If my alternative hypothesis is that <strong>55% of boys in my town are taller than girls</strong> then my alternative hypothesis will be that <strong>55% of boys in my town are not taller than girls. </strong></p><p><strong>Alternative hypothesis</strong> is a method for reaching a conclusion and making inferences and judgements about certain facts or a statement. This is done on the basis of the data which is available. Usually, the statement which we check regarding the null hypothesis is commonly known as the alternative hypothesis. Most of the times alternative hypothesis is exactly the opposite of the null hypothesis. This is what generally researchers or scientists try to approve. Alternative hypothesis is represented as Ha or H1. If my null hypothesis is<strong> that 55% of boys in my town are not taller than girls</strong> then my alternative hypothesis will be that <strong>55% of boys in my town are taller than girls.</strong></p><p> </p><p></p></div><div class='page'><h1 class='title level-2'>Polynomial Linear Regression</h1><br/><p><small>Polynomial Linear Regression Intuition</small></p><p> </p><p><strong>Polynomial Regression </strong>is a form of linear regression in which the relationship between the independent variable x and dependent variable y is modeled as an <em>nth </em>degree polynomial. Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted E(y |x)</p><p><strong>Why Polynomial Regression:</strong><ul><li> </p><p>• There are some relationships that a researcher will hypothesize is curvilinear. Clearly, such types of cases will include a polynomial term.</li><li>Inspection of residuals. If we try to fit a linear model to curved data, a scatter plot of residuals (Y-axis) on the predictor (X-axis) will have patches of many positive residuals in the middle. Hence in such a situation, it is not appropriate.</li><li>An assumption in usual multiple linear regression analysis is that all the independent variables are independent. In polynomial regression model, this assumption is not satisfied.</li></ul></p><p></p><p><strong>Uses of Polynomial Regression:</strong><ul><li>These are basically used to define or describe non-linear phenomena such as: </p><p> </p><p>◇ The growth rate of tissues.</li><li>Progression of disease epidemics</li><li>Distribution of carbon isotopes in lake sediments</li></ul></p><p></p><p>The basic goal of regression analysis is to model the expected value of a dependent variable y in terms of the value of an independent variable x. In simple regression, we used the following equation – </p><p> </p><p><strong>y</strong> = a + bx + eHere y is a dependent variable, a is the y-intercept, b is the slope and e is the error rate.</p><p>In many cases, this linear model will not work out For example if we analyzing the production of chemical synthesis in terms of temperature at which the synthesis take place in such cases we use a quadratic model </p><p> </p><p><strong>y</strong> = a + b1x + b2^2 + eHere y is the dependent variable on x, a is the y-intercept and e is the error rate.</p><p>In general, we can model it for nth value. </p><p> </p><p><strong>y</strong> = a + b1x + b2x^2 +....+ bnx^nSince regression function is linear in terms of unknown variables, hence these models are linear from the point of estimation.</p><p>Hence through the Least Square technique, let’s compute the response value that is y.</p><p><strong>Polynomial Regression in Python:</strong> </p><p>To get the Dataset used for the analysis of Polynomial Regression, </p><p></p><p><strong>Step 1:</strong> Import libraries and dataset </p><p>Import the important libraries and the dataset we are using to perform Polynomial Regression. </p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Importing the libraries</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br />  <br /><span style="color:#0088ff;font-weight:400"># Importing the dataset</span><br />datas = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;data.csv&#39;</span>)<br />datas <br /></pre></div></p><p><img src="images/119-1.png" alt="images/119-1.png" /></p><p></p><p><strong>Step 2:</strong> Dividing the dataset into 2 components</p><p>Divide dataset into two components that is X and y.X will contain the Column between 1 and 2. y will contain the 2 columns. </p><p><code></code></p><p><code></code><div class="codebox"><pre>X = datas.iloc[:, <span style="color:#ff0044;font-weight:400">1</span>:<span style="color:#ff0044;font-weight:400">2</span>].values<br />y = datas.iloc[:, <span style="color:#ff0044;font-weight:400">2</span>].values<br /></pre></div></p><p><strong>Step 3: </strong>Fitting Linear Regression to the dataset</p><p>Fitting the linear Regression model On two components. </p><p> </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Fitting Linear Regression to the dataset</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.linear_model</span> <span style="color:#333333;font-weight:400">import</span> LinearRegression<br />lin = LinearRegression()<br />  <br />lin.fit(X, y)<br /></pre></div> </p><p></p><p><strong>Step 4: </strong>Fitting Polynomial Regression to the dataset</p><p>Fitting the Polynomial Regression model on two components X and y. </p><p> </p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Fitting Polynomial Regression to the dataset</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.preprocessing</span> <span style="color:#333333;font-weight:400">import</span> PolynomialFeatures<br />  <br />poly = PolynomialFeatures(degree = <span style="color:#ff0044;font-weight:400">4</span>)<br />X_poly = poly.fit_transform(X)<br />  <br />poly.fit(X_poly, y)<br />lin2 = LinearRegression()<br />lin2.fit(X_poly, y) <br /></pre></div></p><p></p><p><strong>Step 5: </strong>In this step, we are Visualising the Linear Regression results using a scatter plot. </p><p> </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Visualising the Linear Regression results</span><br />plt.scatter(X, y, color = <span style="color:#3ad900;font-weight:400">&#39;blue&#39;</span>)<br />  <br />plt.plot(X, lin.predict(X), color = <span style="color:#3ad900;font-weight:400">&#39;red&#39;</span>)<br />plt.title(<span style="color:#3ad900;font-weight:400">&#39;Linear Regression&#39;</span>)<br />plt.xlabel(<span style="color:#3ad900;font-weight:400">&#39;Temperature&#39;</span>)<br />plt.ylabel(<span style="color:#3ad900;font-weight:400">&#39;Pressure&#39;</span>)<br />  <br />plt.show() <br /></pre></div></p><p><img src="images/119-2.png" alt="images/119-2.png" /></p><p> </p><p><strong>Advantages of using Polynomial Regression:</strong><ul><li> </p><p>◇ A broad range of functions can be fit under it.</li><li>Polynomial basically fits a wide range of curvatures.</li><li>Polynomial provides the best approximation of the relationship between dependent and independent variables.</li></ul></p><p></p><p><strong>Disadvantages of using Polynomial Regression</strong><ul><li> </p><p>◇ These are too sensitive to the outliers.</li><li>The presence of one or two outliers in the data can seriously affect the results of nonlinear analysis.</li><li>In addition, there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.</li></ul></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Support Vector</h1><br/><p><small>Support Vector Regression Intuition</small></p><p><strong>What are Support Vector Machines?</strong> Support Vector Machine (SVM) is a relatively simple <strong>Supervised Machine Learning Algorithm</strong> used for classification and/or regression. It is more preferred for classification but is sometimes very useful for regression as well. Basically, SVM finds a hyper-plane that creates a boundary between the types of data.</p><p> In 2-dimensional space, this hyper-plane is nothing but a line. In SVM, we plot each data item in the dataset in an N-dimensional space, where N is the number of features/attributes in the data. Next, find the optimal hyperplane to separate the data. So by this, you must have understood that inherently, SVM can only perform binary classification (i.e., choose between two classes). However, there are various techniques to use for multi-class problems. <strong>Support Vector Machine for Multi-CLass Problems</strong><ul><li>o perform SVM on multi-class problems, we can create a binary classifier for each class of the data. The two results of each classifier will be :</p><p> </p><p>• The data point belongs to that class OR</li><li>The data point does not belong to that class.</li></ul></p><p></p><p>For example, in a class of fruits, to perform multi-class classification, we can create a binary classifier for each fruit. For say, the ‘mango’ class, there will be a binary classifier to predict if it IS a mango OR it is NOT a mango.</p><p> The classifier with the highest score is chosen as the output of the SVM. <strong>SVM for complex (Non Linearly Separable)</strong> SVM works very well without any modifications for linearly separable data. <strong>Linearly Separable Data </strong>is any data that can be plotted in a graph and can be separated into classes using a straight line.</p><p> </p><p>Let’s consider two independent variables x1, x2 and one dependent variable which is either a blue circle or a red circle.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211162942/Capture.JPG"><img src="images/120-1.png" alt="images/120-1.png" /></a></p><p></p><p>From the figure above its very clear that there are multiple lines (our hyperplane here is a line because we are considering only two input features x1, x2) that segregates our data points or does a classification between red and blue circles. So how do we choose the best line or in general the best hyperplane that segregates our data points.</p><p><strong>Selecting the best hyper-plane:</strong></p><p>One reasonable choice as the best hyperplane is the one that represents the largest separation or margin between the two classes. </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211181531/Capture.JPG"><img src="images/120-2.png" alt="images/120-2.png" /></a></p><p>So we choose the hyperplane whose distance from it to the nearest data point on each side is maximized. If such a hyperplane exists it is known as the maximum-margin hyperplane/hard margin. So from the above figure, we choose L2.</p><p>Let’s consider a scenario like shown below</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211190544/Capture.JPG"><img src="images/120-3.png" alt="images/120-3.png" /></a></p><p></p><p>Here we have one blue ball in the boundary of the red ball. So how does SVM classify the data? It’s simple! The blue ball in the boundary of red ones is an outlier of blue balls. The SVM algorithm has the characteristics to ignore the outlier and finds the best hyperplane that maximizes the margin. SVM is robust to outliers.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211191138/Capture.JPG"><img src="images/120-4.png" alt="images/120-4.png" /></a></p><p>So in this type of data points what SVM does is, it finds maximum margin as done with previous data sets along with that it adds a penalty each time a point crosses the margin. So the margins in these type of cases are called soft margin. When there is a soft margin to the data set, the SVM tries to minimize <em>(1/margin+∧(∑penalty))</em>. Hinge loss is a commonly used penalty. If no violations no hinge loss.If violations hinge loss proportional to the distance of violation.</p><p>Till now, we were talking about linearly separable data(the group of blue balls and red balls are separable by a straight line/linear line). What to do if data are not linearly separable?</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211183907/Capture.JPG"><img src="images/120-5.png" alt="images/120-5.png" /></a></p><p></p><p>Say, our data is like shown in the figure above.SVM solves this by creating a new variable using a kernel. We call a point x<sub>i </sub>on the line and we create a new variable y<sub>i</sub> as a function of distance from origin o.so if we plot this we get something like as shown below</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20201211185229/Capture.JPG"><img src="images/120-6.png" alt="images/120-6.png" /></a></p><p>In this case, the new variable y is created as a function of distance from the origin. A non-linear function that creates a new variable is referred to as kernel.</p><p><strong>SVM Kernel:</strong></p><p>The SVM kernel is a function that takes low dimensional input space and transforms it into higher-dimensional space, ie it converts non separable problem to separable problem. It is mostly useful in non-linear separation problems. Simply put the kernel, it does some extremely complex data transformations then finds out the process to separate the data based on the labels or outputs defined.</p><p> </p><p></p></div><div class='page'><h1 class='title level-2'>Decision Tree</h1><br/><p><h2>Decision Tree Regression Intuition</h2></p><p><strong>Decision Tree</strong> is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart-like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label. </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/Decision_Tree-2.png"><img src="images/121-1.png" alt="images/121-1.png" /></a></p><p><em>A decision tree for the concept PlayTennis.</em> </p><p><strong>Construction of Decision Tree:</strong> A tree can be <em>“learned”</em> by splitting the source set into subsets based on an attribute value test. This process is repeated on each derived subset in a recursive manner called<em> recursive partitioning</em>. The recursion is completed when the subset at a node all has the same value of the target variable, or when splitting no longer adds value to the predictions. The construction of a decision tree classifier does not require any domain knowledge or parameter setting, and therefore is appropriate for exploratory knowledge discovery. Decision trees can handle high-dimensional data. In general decision tree classifier has good accuracy. Decision tree induction is a typical inductive approach to learn knowledge on classification. </p><p><strong>Entropy: </strong></p><p>As discussed above entropy helps us to build an appropriate decision tree for selecting the best splitter. Entropy can be defined as a measure of the purity of the sub split. Entropy always lies between 0 to 1. The entropy of any split can be calculated by this formula. </p><p> <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d991880243e8c3a99715639bb5bb18de_l3.svg"><img src="images/121-2.png" alt="images/121-2.png" /></a></p><p>The algorithm calculates the entropy of each feature after every split and as the splitting continues on, it selects the best feature and starts splitting according to it. For a detailed calculation of entropy with an example, you can refer to <a href="https://www.geeksforgeeks.org/decision-tree-introduction-example/">this article</a>. </p><p><strong>Gini Impurity: </strong></p><p>The internal working of Gini impurity is also somewhat similar to the working of entropy in the Decision Tree. In the Decision Tree algorithm, both are used for building the tree by splitting as per the appropriate features but there is quite a difference in the computation of both the methods. Gini Impurity of features after splitting can be calculated by using this formula. </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d3c1830d02be83e49f77f663a2069042_l3.svg"><img src="images/121-3.png" alt="images/121-3.png" /></a></p><p> </p><p>For the detailed computation of the Gini Impurity with examples, you can refer to <a href="https://www.geeksforgeeks.org/decision-tree-introduction-example/">this article</a>. By using the above formula gini Impurity of feature/split is being calculated. </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200620180439/Gini-Impurity-vs-Entropy.png"><img src="images/121-4.png" alt="images/121-4.png" /></a><strong>Information gain:</strong></p><p>Information gain is the entropy difference of target and information 1 with respect to target. </p><p><strong>Lets Take an example to understand the split in decision tree</strong></p><p>In above dataset of golf we have <strong>Outlook,Temperature,Humidity,Wind as</strong> Input parameters and playing golf is output parameter, to spit the data we must have the knowledge of entropy of parent node. </p><p> </p><p>Now that we know these parameters, we can start the construction of the decision tree. First, we need to determine the root node of the decision tree. As the dataset is split into two subtypes — Attributes and Class, we calculate the entropy for both, and the following Entropies are obtained.</p><p><span style="indent:1;">E(Play Golf)</span></p><p><span style="indent:1;">E(Play Golf, Outlook)</span></p><p><span style="indent:1;">E(Play Golf, Temperature)</span></p><p><span style="indent:1;">E(Play Golf, Humidity)</span></p><p><span style="indent:1;">E(Play Golf, Windy)</span></p><p><span style="indent:1;">After the calculation of the Entropies, we calculate the Information Gain.</span></p><p><span style="indent:1;">Gain(PlayGolf, Outlook) = Entropy(PlayGolf) — Entropy(PlayGolf, Outlook)</span></p><p><span style="indent:1;">Gain(PlayGolf, Temperature) = Entropy(PlayGolf) — Entropy(PlayGolf, Temparature)</span></p><p><span style="indent:1;">Gain(PlayGolf, Humidity) = Entropy(PlayGolf) — Entropy(PlayGolf, Humidity)</span></p><p><span style="indent:1;">Gain(PlayGolf, Windy) = Entropy(PlayGolf) — Entropy(PlayGolf, Windy)</span></p><p>Now that we have all the necessary values, we can start the splitting. The first split i.e the root node is decided on the attribute which gives us the highest information gain. In this case, it is the Outlook attribute. The further splits will be decided based on which attribute gives us the homogeneous groups. The complete decision tree is shown below.</p><p></p></div><div class='page'><h1 class='title level-2'>Random Forest</h1><br/><p><h1>Random Forest Regression Intuition</h1></p><p>Every decision tree has high variance, but when we combine all of them together in parallel then the resultant variance is low as each decision tree gets perfectly trained on that particular sample data, and hence the output doesn’t depend on one decision tree but on multiple decision trees. In the case of a classification problem, the final output is taken by using the majority voting classifier. In the case of a regression problem, the final output is the mean of all the outputs. This part is called <strong>Aggregation</strong>. </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200516180708/Capture482.png"><img src="images/122-1.png" alt="images/122-1.png" /></a></p><p></p><p>Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as <strong>bagging</strong><ul><li>The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees. </p><p>Random Forest has multiple decision trees as base learning models. We randomly perform row sampling and feature sampling from the dataset forming sample datasets for every model. This part is called Bootstrap.</p><p>We need to approach the Random Forest regression technique like any other machine learning technique </p><p>• Design a specific question or data and get the source to determine the required data.</li><li>Make sure the data is in an accessible format else convert it to the required format.</li><li>Specify all noticeable anomalies and missing data points that may be required to achieve the required data.</li><li>Create a machine learning model</li><li>Set the baseline model that you want to achieve</li><li>Train the data machine learning model.</li><li>Provide an insight into the model with test data</li><li>Now compare the performance metrics of both the test data and the predicted data from the model.</li><li>If it doesn’t satisfy your expectations, you can try improving your model accordingly or dating your data, or using another data modeling technique.</li><li>At this stage, you interpret the data you have gained and report accordingly. </li></ul></p><p></p><p>You will be using a similar sample technique in the below example. </p><p>Below is a step-by-step sample implementation of Random Forest Regression<strong>.</strong></p><p><strong>Implementation:</strong></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Importing the libraries</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd  <br /></pre></div></p><p></p><p><strong>Step 2:</strong> Import and print the dataset </p><p><div class="codebox"><pre><br />data = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;Salaries.csv&#39;</span>)<br /><span style="color:#ff9d00;font-weight:700">print</span>(data)</pre></div> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190530103400/Screenshot-1471.png"><img src="images/122-2.png" alt="images/122-2.png" /></a> </p><p><strong>Step 3:</strong> Select all rows and column 1 from dataset to x and all rows and column 2 as y </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># the coding was not shown which is like that</span><br />x= df.iloc [:, : -<span style="color:#ff0044;font-weight:400">1</span>] <span style="color:#0088ff;font-weight:400"># ” : ” means it will select all rows,    “: -1 ” means that it will ignore last column</span><br />y= df.iloc [:, -<span style="color:#ff0044;font-weight:400">1</span> :] <span style="color:#0088ff;font-weight:400"># ” : ” means it will select all rows,    “-1 : ” means that it will ignore all columns except the last one</span><br /><span style="color:#0088ff;font-weight:400"># the “iloc()” function enables us to select a particular cell of the dataset, that is, it helps us select a value that belongs to a particular row or column from a set of values of a data frame or dataset.</span><br /></pre></div> </p><p><strong>Step 4:</strong> Fit Random forest regressor to the dataset </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Fitting Random Forest Regression to the dataset</span><br /><span style="color:#0088ff;font-weight:400"># import the regressor</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.ensemble</span> <span style="color:#333333;font-weight:400">import</span> RandomForestRegressor<br />  <br /> <span style="color:#0088ff;font-weight:400"># create regressor object</span><br />regressor = RandomForestRegressor(n_estimators = <span style="color:#ff0044;font-weight:400">100</span>, random_state = <span style="color:#ff0044;font-weight:400">0</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># fit the regressor with x and y data</span><br />regressor.fit(x, y) <br /></pre></div></p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190530103506/Screenshot-1502.png"><img src="images/122-3.png" alt="images/122-3.png" /></a></p></div><div class='page'><h1 class='title level-2'>Classification Algorithms</h1><br/><p> 	</p></div><div class='page'><h1 class='title level-3'>Logistic Regression</h1><br/><p><small>Logistic Regression Intuition</small></p><p>This article discusses the basics of Logistic Regression and its implementation in Python. Logistic regression is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X.</p><p>Contrary to popular belief, logistic regression is a regression model. The model builds a regression model to predict the probability that a given data entry belongs to the category numbered as “1”. Just like Linear regression assumes that the data follows a linear function, Logistic regression models the data using the sigmoid function.</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d5a2d94c6e6bda6abd7d6230a844a02f_l3.svg"><img src="images/124-1.png" alt="images/124-1.png" /></a></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190522162153/sigmoid-function-300x138.png"><img src="images/124-2.png" alt="images/124-2.png" /></a></p><p>Logistic regression becomes a classification technique only when a decision threshold is brought into the picture. The setting of the threshold value is a very important aspect of Logistic regression and is dependent on the classification problem itself.</p><p>The decision for the value of the threshold value is majorly affected by the values of <a href="https://www.geeksforgeeks.org/confusion-matrix-machine-learning/">precision and recall.</a><ol><li>eally, we want both precision and recall to be 1, but this seldom is the case.</p><p>In the case of a Precision-Recall tradeoff, we use the following arguments to decide upon the threshold:-</p><p><strong>1. Low Precision/High Recall:</strong></li><li> applications where we want to reduce the number of false negatives without necessarily reducing the number of false positives, we choose a decision value that has a low value of Precision or a high value of Recall. For example, in a cancer diagnosis application, we do not want any affected patient to be classified as not affected without giving much heed to if the patient is being wrongfully diagnosed with cancer. This is because the absence of cancer can be detected by further medical diseases but the presence of the disease cannot be detected in an already rejected candidate.</p><p><strong>2. High Precision/Low Recall:</strong></li></ol> In applications where we want to reduce the number of false positives without necessarily reducing the number of false negatives, we choose a decision value that has a high value of Precision or a low value of Recall. For example, if we are classifying customers whether they will react positively or negatively to a personalized advertisement, we want to be absolutely sure that the customer will react positively to the advertisement because otherwise, a negative reaction can cause a loss of potential sales from the customer.</p><p>Based on the number of categories, Logistic regression can be classified as: <ol><li>. <strong>binomial:</strong></li><li>rget variable can have only 2 possible types: “0” or “1” which may represent “win” vs “loss”, “pass” vs “fail”, “dead” vs “alive”, etc.</p><p>2. <strong>multinomial:</strong></li><li>rget variable can have 3 or more possible types which are not ordered(i.e. types have no quantitative significance) like “disease A” vs “disease B” vs “disease C”.</p><p>3. <strong>ordinal:</strong></li></ol> it deals with target variables with ordered categories. For example, a test score can be categorized as:“very poor”, “poor”, “good”, “very good”. Here, each category can be given a score like 0, 1, 2, 3.</p><p> </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232307/gif-5.gif"><img src="images/124-3.png" alt="images/124-3.png" /></a></p><p> </p><p><em>The reason for taking</em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5af66bcf172069271c104ee161144dff_l3.svg"><img src="images/124-4.png" alt="images/124-4.png" /></a>= 1 is pretty clear now.</p><p><em>We needed to do a matrix product, but there was no</em></p><p><em>actual</em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5af66bcf172069271c104ee161144dff_l3.svg"><img src="images/124-5.png" alt="images/124-5.png" /></a>multiplied to<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-79eeecc89fdada9b62205e9673fcc5c9_l3.svg"><img src="images/124-6.png" alt="images/124-6.png" /></a>in original hypothesis formula. So, we defined<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5af66bcf172069271c104ee161144dff_l3.svg"><img src="images/124-7.png" alt="images/124-7.png" /></a>= 1. </p><p>Now, if we try to apply Linear Regression to the above problem, we are likely to get continuous values using the hypothesis we discussed above. Also, it does not make sense for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ddbf46f0d32738e21526c4fa02035964_l3.svg"><img src="images/124-8.png" alt="images/124-8.png" /></a>to take values larger than 1 or smaller than 0. </p><p>So, some modifications are made to the hypothesis for classification: </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232331/gif-6.gif"><img src="images/124-9.png" alt="images/124-9.png" /></a></p><p>where,</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232357/gif-7.gif"><img src="images/124-10.png" alt="images/124-10.png" /></a></p><p>is called <strong>logistic function</strong> or the <strong>sigmoid function</strong>. </p><p>Here is a plot showing g(z): </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/logistic-function.png"><img src="images/124-11.png" alt="images/124-11.png" /></a><ul><li> can infer from the above graph that: </p><p> </p><p>• g(z) tends towards 1 as</li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-626af879c74e54b3cc803bc6fb28aa59_l3.svg"><img src="images/124-12.png" alt="images/124-12.png" /></a><ul><li>g(z) tends towards 0 as</li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c0c949d7aa66ed64131ebd95558cbcf5_l3.svg"><img src="images/124-13.png" alt="images/124-13.png" /></a><ul><li>g(z) is always bounded between 0 and 1</li></ul></p><p></p><p>So, now, we can define conditional probabilities for 2 labels(0 and 1) for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e6ac62b8bb4d87ddf53c1ebceddecc25_l3.svg"><img src="images/124-14.png" alt="images/124-14.png" /></a>observation as:</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232429/gif-8.gif"><img src="images/124-15.png" alt="images/124-15.png" /></a></p><p>We can write it more compactly as:</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232455/gif-9.gif"><img src="images/124-16.png" alt="images/124-16.png" /></a></p><p>Now, we define another term, <strong>likelihood of parameters</strong> as:</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232522/gif-10.gif"><img src="images/124-17.png" alt="images/124-17.png" /></a></p><p> </p><p><em>Likelihood is nothing but the probability of data(training examples), given a model and specific parameter values(here,</em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f4cd8c23ebd8e95ef11e3140dfde94c9_l3.svg"><img src="images/124-18.png" alt="images/124-18.png" /></a>). It measures the support provided by the data for each possible value of the<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f4cd8c23ebd8e95ef11e3140dfde94c9_l3.svg"><img src="images/124-19.png" alt="images/124-19.png" /></a>. We obtain it by multiplying all<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f4cd8c23ebd8e95ef11e3140dfde94c9_l3.svg"><img src="images/124-20.png" alt="images/124-20.png" /></a>for given<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f4cd8c23ebd8e95ef11e3140dfde94c9_l3.svg"><img src="images/124-21.png" alt="images/124-21.png" /></a>. </p><p><em> </em></p><p>And for easier calculations, we take<strong> log-likelihood:</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232615/gif-11.gif"><img src="images/124-22.png" alt="images/124-22.png" /></a></p><p>The <strong>cost function</strong> for logistic regression is proportional to the inverse of the likelihood of parameters. Hence, we can obtain an expression for cost function, J using log-likelihood equation as:</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232647/gif-12.gif"><img src="images/124-23.png" alt="images/124-23.png" /></a></p><p>and our aim is to estimate<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6085143752e49b8d83aa1c702203e5db_l3.svg"><img src="images/124-24.png" alt="images/124-24.png" /></a>so that cost function is minimized !!</p><p> </p><p><strong>Using Gradient descent algorithm</strong></p><p>Firstly, we take partial derivatives of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f7fdef498cca09680863e5dc425199e9_l3.svg"><img src="images/124-25.png" alt="images/124-25.png" /></a>w.r.t each<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d0353a512f9f3c13d46d19c1ba57a9b1_l3.svg"><img src="images/124-26.png" alt="images/124-26.png" /></a>to derive the stochastic gradient descent rule(we present only the final derived value here):</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20210722232711/gif-13.gif"><img src="images/124-27.png" alt="images/124-27.png" /></a></p><p>Here, y and h(x) represents the response vector and predicted response vector(respectively). Also,<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5ef24fc37edee7da5c262e3f43085ea3_l3.svg"><img src="images/124-28.png" alt="images/124-28.png" /></a>is the vector representing the observation values for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-062016a57150ca99030fcf9a7a624705_l3.svg"><img src="images/124-29.png" alt="images/124-29.png" /></a>feature. </p><p>Now, in order to get min<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f7fdef498cca09680863e5dc425199e9_l3.svg"><img src="images/124-30.png" alt="images/124-30.png" /></a>,</p><p>where<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d7de125e9ccd6efe6430ab6ef4c33db1_l3.svg"><img src="images/124-31.png" alt="images/124-31.png" /></a>is called <strong>learning rate</strong> and needs to be set explicitly. </p><p></p></div><div class='page'><h1 class='title level-3'>KNN Algorithm</h1><br/><p><small>KNN Algorithm Intuition</small></p><p>K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining and intrusion detection.</p><p>It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as <a href="https://en.wikipedia.org/wiki/Mixture_model">GMM</a>, which assume a Gaussian distribution of the given data).</p><p>We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute.</p><p>As an example, consider the following table of data points containing two features: </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/graph1-8.png"><img src="images/125-1.png" alt="images/125-1.png" /></a></p><p>Now, given another set of data points (also called testing data), allocate these points a group by analyzing the training set. Note that the unclassified points are marked as ‘White’.</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/graph2-2.png"><img src="images/125-2.png" alt="images/125-2.png" /></a></p><p>K in KNN is a parameter that refers to the number of the nearest neighbours to include in the majority voting process.</p><p><strong>How do we choose K?</strong></p><p>Sqrt(n), where n is a total number of data points(if in case n is even we have to make the value  odd by adding 1 or subtracting 1 that helps in select better)</p><p><strong>When to use KNN?</strong></p><p>We can use KNN when Dataset is labelled and noise-free and it’s must be small because KNN is a <em>“Lazy learner”</em>. Let’s understand KNN algorithm with the help of an example</p><p><table class="table"><tr><th>NAME</th><th>AGE</th><th>GENDER</th><th>CLASS OF SPORTS</th></tr><tr><td>Ajay</td><td>32</td><td>0</td><td>Football</td></tr><tr><td>Mark</td><td>40</td><td>0</td><td>Neither</td></tr><tr><td>Sara</td><td>16</td><td>1</td><td>Cricket</td></tr><tr><td>Zaira</td><td>34</td><td>1</td><td>Cricket</td></tr><tr><td>Sachin</td><td>55</td><td>0</td><td>Neither</td></tr><tr><td>Rahul</td><td>40</td><td>0</td><td>Cricket</td></tr><tr><td>Pooja</td><td>20</td><td>1</td><td>Neither</td></tr><tr><td>Smith</td><td>15</td><td>0</td><td>Cricket</td></tr><tr><td>Laxmi</td><td>55</td><td>1</td><td>Football</td></tr><tr><td>Michael</td><td>15</td><td>0</td><td>Football</td></tr></table></p><p>Here male is denoted with numeric value 0 and female with 1. Let’s find in which class of people Angelina will lie whose k factor is 3 and age is 5. So we have to find out the distance using </p><p><em>  d=√((x2-x1)²+(y2-y1)²) to find the distance between any two points.</em></p><p>So let’s find out the distance between Ajay and Angelina using formula  </p><p><em>d=√((age2-age1)²+(gender2-gender1)²)</em></p><p><em>d=√((5-32)²+(1-0)²)</em></p><p><em>d=√729+1</em></p><p><em><span style="background-color:#f9f9f9;">d=27.02</span></em></p><p></p><p>Similarly, we find out all distance one by one.</p><p><table class="table"><tr><th>Distance between Angelina and</th><th>Distance</th></tr><tr><td>Ajay</td><td>27.02</td></tr><tr><td>Mark</td><td>35.01</td></tr><tr><td>Sara</td><td>11.00</td></tr><tr><td>Zaira</td><td>9.00</td></tr><tr><td>Sachin</td><td>50.01</td></tr><tr><td>Rahul</td><td>35.01</td></tr><tr><td>Pooja</td><td>15.00</td></tr><tr><td>Smith</td><td>10.00</td></tr><tr><td>Laxmi</td><td>50.00</td></tr><tr><td>Michael</td><td>10.05</td></tr></table></p><p>So the value of <em><strong>k </strong></em>factor is 3 for Angelina. And the closest to 3 is 9,10,10.5 that is closest to Angelina are Zaira, Smith and Michael.</p><p>                           </p><p>                                       Zaira         9           cricket</p><p>                                      Michael      10         cricket    </p><p>                                      smith          10.5      football</p><p>so according to KNN algorithm, Angelina will be in the class of people who like cricket. So this is how KNN algorithm works.  </p><p></p><p><small>KNN Algorithm Intuition</small></p><p>K-Nearest Neighbours is one of the most basic yet essential classification algorithms in Machine Learning. It belongs to the supervised learning domain and finds intense application in pattern recognition, data mining and intrusion detection.</p><p>It is widely disposable in real-life scenarios since it is non-parametric, meaning, it does not make any underlying assumptions about the distribution of data (as opposed to other algorithms such as <a href="https://en.wikipedia.org/wiki/Mixture_model">GMM</a>, which assume a Gaussian distribution of the given data).</p><p>We are given some prior data (also called training data), which classifies coordinates into groups identified by an attribute.</p><p>As an example, consider the following table of data points containing two features: </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/graph1-8.png"><img src="images/125-3.png" alt="images/125-3.png" /></a></p><p>Now, given another set of data points (also called testing data), allocate these points a group by analyzing the training set. Note that the unclassified points are marked as ‘White’.</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/graph2-2.png"><img src="images/125-4.png" alt="images/125-4.png" /></a></p><p>K in KNN is a parameter that refers to the number of the nearest neighbours to include in the majority voting process.</p><p><strong>How do we choose K?</strong></p><p>Sqrt(n), where n is a total number of data points(if in case n is even we have to make the value  odd by adding 1 or subtracting 1 that helps in select better)</p><p><strong>When to use KNN?</strong></p><p>We can use KNN when Dataset is labelled and noise-free and it’s must be small because KNN is a <em>“Lazy learner”</em>. Let’s understand KNN algorithm with the help of an example</p><p><table class="table"><tr><th>NAME</th><th>AGE</th><th>GENDER</th><th>CLASS OF SPORTS</th></tr><tr><td>Ajay</td><td>32</td><td>0</td><td>Football</td></tr><tr><td>Mark</td><td>40</td><td>0</td><td>Neither</td></tr><tr><td>Sara</td><td>16</td><td>1</td><td>Cricket</td></tr><tr><td>Zaira</td><td>34</td><td>1</td><td>Cricket</td></tr><tr><td>Sachin</td><td>55</td><td>0</td><td>Neither</td></tr><tr><td>Rahul</td><td>40</td><td>0</td><td>Cricket</td></tr><tr><td>Pooja</td><td>20</td><td>1</td><td>Neither</td></tr><tr><td>Smith</td><td>15</td><td>0</td><td>Cricket</td></tr><tr><td>Laxmi</td><td>55</td><td>1</td><td>Football</td></tr><tr><td>Michael</td><td>15</td><td>0</td><td>Football</td></tr></table></p><p>Here male is denoted with numeric value 0 and female with 1. Let’s find in which class of people Angelina will lie whose k factor is 3 and age is 5. So we have to find out the distance using </p><p><em>  d=√((x2-x1)²+(y2-y1)²) to find the distance between any two points.</em></p><p>So let’s find out the distance between Ajay and Angelina using formula  </p><p><em>d=√((age2-age1)²+(gender2-gender1)²)</em></p><p><em>d=√((5-32)²+(1-0)²)</em></p><p><em>d=√729+1</em></p><p><em><span style="background-color:#f9f9f9;">d=27.02</span></em></p><p></p><p>Similarly, we find out all distance one by one.</p><p><table class="table"><tr><th>Distance between Angelina and</th><th>Distance</th></tr><tr><td>Ajay</td><td>27.02</td></tr><tr><td>Mark</td><td>35.01</td></tr><tr><td>Sara</td><td>11.00</td></tr><tr><td>Zaira</td><td>9.00</td></tr><tr><td>Sachin</td><td>50.01</td></tr><tr><td>Rahul</td><td>35.01</td></tr><tr><td>Pooja</td><td>15.00</td></tr><tr><td>Smith</td><td>10.00</td></tr><tr><td>Laxmi</td><td>50.00</td></tr><tr><td>Michael</td><td>10.05</td></tr></table></p><p>So the value of <em><strong>k </strong></em>factor is 3 for Angelina. And the closest to 3 is 9,10,10.5 that is closest to Angelina are Zaira, Smith and Michael.</p><p>                           </p><p>                                       Zaira         9           cricket</p><p>                                      Michael      10         cricket    </p><p>                                      smith          10.5      football</p><p>so according to KNN algorithm, Angelina will be in the class of people who like cricket. So this is how KNN algorithm works.  </p><p></p></div><div class='page'><h1 class='title level-3'>Naive Bayes</h1><br/><p><h3>Naive Bayes classifiers are a collection of classification algorithms based on </h3><strong><h3>Bayes’ Theorem</h3></strong><h3>. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.</h3></p><p><h3>To start with, let us consider a dataset, Consider a fictional dataset that describes the weather conditions for playing a game of golf. Given the weather conditions, each tuple classifies the conditions as fit(“Yes”) or unfit(“No”) for playing golf.</h3></p><p><table class="table"><tr><th>0</th><th>Rainy</th><th>Hot</th><th>High</th><th>False</th><th>No</th></tr><tr><td>1</td><td>Rainy</td><td>Hot</td><td>High</td><td>True</td><td>No</td></tr><tr><td>2</td><td>Overcast</td><td>Hot</td><td>High</td><td>False</td><td>Yes</td></tr><tr><td>3</td><td>Sunny</td><td>Mild</td><td>High</td><td>False</td><td>Yes</td></tr><tr><td>4</td><td>Sunny</td><td>Cool</td><td>Normal</td><td>False</td><td>Yes</td></tr><tr><td>5</td><td>Sunny</td><td>Cool</td><td>Normal</td><td>True</td><td>No</td></tr><tr><td>6</td><td>Overcast</td><td>Cool</td><td>Normal</td><td>True</td><td>Yes</td></tr><tr><td>7</td><td>Rainy</td><td>Mild</td><td>High</td><td>False</td><td>No</td></tr><tr><td>8</td><td>Rainy</td><td>Cool</td><td>Normal</td><td>False</td><td>Yes</td></tr><tr><td>9</td><td>Sunny</td><td>Mild</td><td>Normal</td><td>False</td><td>Yes</td></tr><tr><td>10</td><td>Rainy</td><td>Mild</td><td>Normal</td><td>True</td><td>Yes</td></tr><tr><td>11</td><td>Overcast</td><td>Mild</td><td>High</td><td>True</td><td>Yes</td></tr><tr><td>12</td><td>Overcast</td><td>Hot</td><td>Normal</td><td>False</td><td>Yes</td></tr><tr><td>13</td><td>Sunny</td><td>Mild</td><td>High</td><td>True</td><td>No</td></tr></table></p><p><h3>The dataset is divided into two parts, namely, </h3><strong><h3>feature matrix</h3></strong><h3> and the </h3><strong><h3>response vector</h3></strong><h3>.</h3><ul><li>Feature matrix contains all the vectors(rows) of dataset in which each vector consists of the value of <strong>dependent features</strong></li><li>In above dataset, features are ‘Outlook’, ‘Temperature’, ‘Humidity’ and ‘Windy’.</p><p>• Response vector contains the value of <strong>class variable</strong></li></ul>(prediction or output) for each row of feature matrix. In above dataset, the class variable name is ‘Play golf</p><p></p><p><strong><h3>Assumption:</h3></strong></p><p><h3>The fundamental Naive Bayes assumption is that each feature makes an:</h3><ul><li>independent</li><li>equal</li></ul></p><p></p><p><h3>contribution to the outcome</h3></p><p><h3>With relation to our dataset, this concept can be understood as</h3><ul><li>We assume that no pair of features are dependent. For example, the temperature being ‘Hot’ has nothing to do with the humidity or the outlook being ‘Rainy’ has no effect on the winds. Hence, the features are assumed to be <strong>independent</strong></li><li>◇ Secondly, each feature is given the same weight(or importance). For example, knowing only temperature and humidity alone can’t predict the outcome accurately. None of the attributes is irrelevant and assumed to be contributing <strong>equally</strong></li></ul> to the outcome</p><p></p><p><strong><h3>Bayes’ Theorem</h3></strong></p><p><h3>Bayes’ Theorem finds the probability of an event occurring given the probability of another event that has already occurred. Bayes’ theorem is stated mathematically as the following equation:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7777aa719ea14857115695676adc0914_l3.svg"><img src="images/126-1.png" alt="images/126-1.png" /></a></p><p><h3>where A and B are events and P(B) ≠ 0.</h3><ul><li>Basically, we are trying to find probability of event A, given the event B is true. Event B is also termed as <strong>evidence</strong></li><li>◇ P(A) is the <strong>priori</strong></li><li>f A (the prior probability, i.e. Probability of event before evidence is seen). The evidence is an attribute value of an unknown instance(here, it is event B).</p><p>◇ P(A|B) is a posteriori probability of B, i.e. probability of event after evidence is seen</li></ul></p><p></p><p><h3>Now, with regards to our dataset, we can apply Bayes’ theorem in following way:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e85875a7ff9e9b557eab6281cc7ff078_l3.svg"><img src="images/126-2.png" alt="images/126-2.png" /></a></p><p><h3>where, y is class variable and X is a dependent feature vector (of size </h3><em><h3>n</h3></em><h3>) where:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5385a4693c3fb17811cf36593978a601_l3.svg"><img src="images/126-3.png" alt="images/126-3.png" /></a></p><p><h3>Just to clear, an example of a feature vector and corresponding class variable can be: (refer 1st row of dataset)</h3></p><p><h3>X = (Rainy, Hot, High, False) y = No</h3></p><p><h3>So basically, P(y|X) here means, the probability of “Not playing golf” given that the weather conditions are “Rainy outlook”, “Temperature is hot”, “high humidity” and “no wind”.</h3></p><p><h3></h3></p><p><h3></h3><strong><h3>Naive assumption</h3></strong></p><p><h3>Now, its time to put a naive assumption to the Bayes’ theorem, which is, </h3><strong><h3>independence</h3></strong><h3> among the features. So now, we split </h3><strong><h3>evidence</h3></strong><h3> into the independent parts.</h3></p><p><h3>Now, if any two events A and B are independent, then,</h3></p><p><h3>P(A,B) = P(A)P(B)</h3></p><p><h3>Hence, we reach to the result:</h3></p><p><h3> </h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1c3f5ab570cf0ab3f43d5c18c645b67a_l3.svg"><img src="images/126-4.png" alt="images/126-4.png" /></a></p><p><h3>which can be expressed as:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-8171c1fe2cbd3ed62bc3f40d682c0512_l3.svg"><img src="images/126-5.png" alt="images/126-5.png" /></a></p><p><h3>Now, as the denominator remains constant for a given input, we can remove that term:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c778553cb5a67518205ac6ea18502398_l3.svg"><img src="images/126-6.png" alt="images/126-6.png" /></a></p><p><h3>Now, we need to create a classifier model. For this, we find the probability of given set of inputs for all possible values of the class variable </h3><em><h3>y</h3></em><h3> and pick up the output with maximum probability. This can be expressed mathematically as:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f3637f468262bfbb4accb97da8110028_l3.svg"><img src="images/126-7.png" alt="images/126-7.png" /></a></p><p><h3>So, finally, we are left with the task of calculating P(y) and P(x</h3><sub>i</sub><h3> | y).</h3></p><p><h3>Please note that P(y) is also called </h3><strong><h3>class probability</h3></strong><h3> and P(x</h3><sub>i</sub><h3> | y) is called </h3><strong><h3>conditional probability</h3></strong><h3>.</h3></p><p><h3>The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of P(x</h3><sub>i</sub><h3> | y).</h3></p><p><h3>Let us try to apply the above formula manually on our weather dataset. For this, we need to do some precomputations on our dataset.We need to find P(x</h3><sub>i</sub><h3> | y</h3><sub>j</sub><h3>) for each x</h3><sub>i</sub><h3> in X and y</h3><sub>j</sub><h3> in y. All these calculations have been demonstrated in the tables below:</h3><a href="https://media.geeksforgeeks.org/wp-content/uploads/naive-bayes-classification.png"><img src="images/126-8.png" alt="images/126-8.png" /></a></p><p><h3> </h3></p><p><h3>So, in the figure above, we have calculated P(x</h3><sub>i</sub><h3> | y</h3><sub>j</sub><h3>) for each x</h3><sub>i</sub><h3> in X and y</h3><sub>j</sub><h3> in y manually in the tables 1-4. For example, probability of playing golf given that the temperature is cool, i.e P(temp. = cool | play golf = Yes) = 3/9.</h3></p><p><h3>Also, we need to find class probabilities (P(y)) which has been calculated in the table 5. For example, P(play golf = Yes) = 9/14.So now, we are done with our pre-computations and the classifier is ready!</h3></p><p><h3>Let us test it on a new set of features (let us call it today):</h3></p><p><h3>today = (Sunny, Hot, Normal, False)So, probability of playing golf is given by:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c6067bf0bf53532b6701c72215bc0758_l3.svg"><img src="images/126-9.png" alt="images/126-9.png" /></a></p><p><h3>and probability to not play golf is given by:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ed23967bcb3871bd6919752aa396a167_l3.svg"><img src="images/126-10.png" alt="images/126-10.png" /></a></p><p><h3>Since, P(today) is common in both probabilities, we can ignore P(today) and find proportional probabilities as:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e061a86d4158d65787e64c4cdfd15f17_l3.svg"><img src="images/126-11.png" alt="images/126-11.png" /></a></p><p><h3>and</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-176cc113842cb9f7bf3e645e10381bec_l3.svg"><img src="images/126-12.png" alt="images/126-12.png" /></a></p><p><h3>Now, since</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c11dfe6cbfca4b42282dff3c7689a4ae_l3.svg"><img src="images/126-13.png" alt="images/126-13.png" /></a></p><p><h3>These numbers can be converted into a probability by making the sum equal to 1 (normalization):</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d743d4c0f318303820d38a8b533d07d8_l3.svg"><img src="images/126-14.png" alt="images/126-14.png" /></a></p><p><h3>and</h3><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1c3af0ce1707cd819282d764d8b71f63_l3.svg"><img src="images/126-15.png" alt="images/126-15.png" /></a></p><p><h3>Since</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0214e299f25961601b470dab459842c0_l3.svg"><img src="images/126-16.png" alt="images/126-16.png" /></a></p><p><h3>So, prediction that golf would be played is ‘Yes’The method that we discussed above is applicable for discrete data. In case of continuous data, we need to make some assumptions regarding the distribution of values of each feature. The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of P(x</h3><sub>i</sub><h3> | y).</h3></p><p><strong><h3>Gaussian Naive Bayes classifier</h3></strong><h3>I: </h3></p><p><h3>n Gaussian Naive Bayes, continuous values associated with each feature are assumed to be distributed according to a </h3><strong><h3>Gaussian distribution</h3></strong><h3>. A Gaussian distribution is also called </h3><h3>Normal distribution</h3><h3>. When plotted, it gives a bell shaped curve which is symmetric about the mean of the feature values as shown below:</h3></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/naive-bayes-classification-1.png"><img src="images/126-17.png" alt="images/126-17.png" /></a></p><p><h3>The likelihood of the features is assumed to be Gaussian, hence, conditional probability is given by:</h3></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7fb78d7323fcbade0cb664161a8e84c4_l3.svg"><img src="images/126-18.png" alt="images/126-18.png" /></a></p></div><div class='page'><h1 class='title level-2'>Clustering Algorithm</h1><br/></div><div class='page'><h1 class='title level-3'>K-Means Clustering</h1><br/><p><small>K-Means Clustering Intro</small></p><p><span style="color:#4d5156;">K-Means Clustering is </span><em><strong>an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters</strong></em><span style="color:#4d5156;">.</span><ol><li> will help if you think of items as points in an n-dimensional space).  The algorithm will categorize the items into k groups or clusters of similarity. To calculate that similarity, we will use the euclidean distance as measurement.</p><p>The algorithm works as follows:  </p><p>1. First, we initialize k points, called means or cluster centroids, randomly.</li><li>We categorize each item to its closest mean and we update the mean’s coordinates, which are the averages of the items categorized in that cluster so far.</li><li>We repeat the process for a given number of iterations and at the end, we have our clusters.</li></ol></p><p>The “points” mentioned above are called means because they are the mean values of the items categorized in them. To initialize these means, we have a lot of options. An intuitive method is to initialize the means at random items in the data set. Another method is to initialize the means at random values between the boundaries of the data set (if for a feature <em>x</em> the items have values in [0,3], we will initialize the means with values for <em>x</em> at [0,3]).</p><p>The above algorithm in pseudocode is as follows:  </p><p>Initialize k means with random values</p><p></p><p><div class="codebox"><pre>--&gt; For a given number of iterations:<br />    <br />    --&gt; Iterate through items:<br />    <br />        --&gt; Find the mean closest to the item by calculating <br />        the euclidean distance of the item <span style="color:#ff9d00;font-weight:700">with</span> each of the means<br />        <br />        --&gt; Assign item to mean<br />        <br />        --&gt; Update mean by shifting it to the average of the items <span style="color:#ff9d00;font-weight:700">in</span> that cluste</pre></div>r<a href="https://media.geeksforgeeks.org/wp-content/uploads/20221123151151/WhatsAppImage20221123at135215.jpeg"><img src="images/128-1.png" alt="images/128-1.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221123151153/WhatsAppImage20221123at135207.jpeg"><img src="images/128-2.png" alt="images/128-2.png" /></a>  </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221123151152/WhatsAppImage20221123at135214.jpeg"><img src="images/128-3.png" alt="images/128-3.png" /></a> <a href="https://media.geeksforgeeks.org/wp-content/uploads/20221123151153/WhatsAppImage20221123at135213.jpeg"><img src="images/128-4.png" alt="images/128-4.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Elbow Method for optimal value of K</h1><br/><p><small>Elbow Method for optimal value of k in KMeans</small></p><p>A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The <strong>Elbow Method</strong> is one of the most popular methods to determine this optimal value of k.</p><p>We now demonstrate the given method using the K-Means clustering technique using the <strong>Sklearn</strong> library of python.</p><p> </p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.cluster</span> <span style="color:#333333;font-weight:400">import</span> KMeans<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn</span> <span style="color:#333333;font-weight:400">import</span> metrics<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">scipy.spatial.distance</span> <span style="color:#333333;font-weight:400">import</span> cdist<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt <br /></pre></div></p><p></p><p><strong>Step 2: Creating and Visualizing the dat</strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Creating the data</span><br />x1 = np.array([<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">9</span>, <span style="color:#ff0044;font-weight:400">9</span>, <span style="color:#ff0044;font-weight:400">8</span>])<br />x2 = np.array([<span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">3</span>])<br />X = np.array(<span style="color:#ff9d00;font-weight:700">list</span>(<span style="color:#ff9d00;font-weight:700">zip</span>(x1, x2))).reshape(<span style="color:#ff9d00;font-weight:700">len</span>(x1), <span style="color:#ff0044;font-weight:400">2</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># Visualizing the data</span><br />plt.plot()<br />plt.xlim([<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">10</span>])<br />plt.ylim([<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">10</span>])<br />plt.title(<span style="color:#3ad900;font-weight:400">&#39;Dataset&#39;</span>)<br />plt.scatter(x1, x2)<br /><br />plt.show() <br /></pre></div></p><p></p><p><img src="images/129-1.png" alt="images/129-1.png" /> </p><p>We iterate the values of k from 1 to 9 and calculate the values of distortions for each value of k and calculate the distortion and inertia for each value of k in the given range.</p><p><strong>Step 3: Building the clustering model and calculating the values of the Distortion and Inertia:</strong></p><p></p><p><div class="codebox"><pre>distortions = []<br />inertias = []<br />mapping1 = {}<br />mapping2 = {}<br />K = <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">10</span>)<br />  <br /><span style="color:#ff9d00;font-weight:700">for</span> k <span style="color:#ff9d00;font-weight:700">in</span> K:<br />    <span style="color:#0088ff;font-weight:400"># Building and fitting the model</span><br />    kmeanModel = KMeans(n_clusters=k).fit(X)<br />    kmeanModel.fit(X)<br />  <br />    distortions.append(<span style="color:#ff9d00;font-weight:700">sum</span>(np.min(cdist(X, kmeanModel.cluster_centers_,<br />                                        <span style="color:#3ad900;font-weight:400">&#39;euclidean&#39;</span>), axis=<span style="color:#ff0044;font-weight:400">1</span>)) / X.shape[<span style="color:#ff0044;font-weight:400">0</span>])<br />    inertias.append(kmeanModel.inertia_)<br />  <br />    mapping1[k] = <span style="color:#ff9d00;font-weight:700">sum</span>(np.min(cdist(X, kmeanModel.cluster_centers_,<br />                                   <span style="color:#3ad900;font-weight:400">&#39;euclidean&#39;</span>), axis=<span style="color:#ff0044;font-weight:400">1</span>)) / X.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    mapping2[k] = kmeanModel.inertia_ <br /></pre></div></p><p></p><p><div class="codebox"><pre>plt.plot(K, distortions, <span style="color:#3ad900;font-weight:400">&#39;bx-&#39;</span>)<br />plt.xlabel(<span style="color:#3ad900;font-weight:400">&#39;Values of K&#39;</span>)<br />plt.ylabel(<span style="color:#3ad900;font-weight:400">&#39;Distortion&#39;</span>)<br />plt.title(<span style="color:#3ad900;font-weight:400">&#39;The Elbow Method using Distortion&#39;</span>)<br />plt.show() <br /></pre></div></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190606105550/distortion1.png"><img src="images/129-2.png" alt="images/129-2.png" /></a></p></div><div class='page'><h1 class='title level-3'>K-Means Clustering with Scipy</h1><br/><p><small>K- means clustering with SciPy</small></p><p>The K-Means clustering is one of the partitioning approaches and each cluster will be represented with a calculated centroid. All the data points in the cluster will have a minimum distance from the computed centroid.</p><p><strong>Scipy</strong> is an open-source library that can be used for complex computations. It is mostly used with NumPy arrays. It can be installed by running the command given below.</p><p><em>pip install scipy</em><ol><li>has dedicated packages for the process of clustering. There are two modules that can offer clustering methods. </p><p>1. cluster.vq</li><li>cluster.hierarchy</li></ol></p><p></p><p><h2>cluster.vq </h2></p><p>This module gives the feature of <strong>vector quantization </strong>to use with the K-Means clustering method. The quantization of vectors plays a major role in reducing the distortion and improving the accuracy. Mostly the distortion here is calculated using the Euclidean distance between the centroid and each vector. Based on this the vector od data points are assigned to a cluster.</p><p></p><p><h2>cluster.hierarchy</h2></p><p>This module provides methods for general hierarchical clustering and its types such as agglomerative clustering. It has various routines that can be used for applying statistical methods on the hierarchies, visualizing the clusters, plotting the clusters, checking linkages in the clusters, and also checking whether two different hierarchies are equivalent.</p><p>In this article, cluster.vq module will be used to carry out the K-Means clustering.</p><p></p><p><h2>K-Means clustering with Scipy library</h2><ol><li> K-means clustering can be done on given data by executing the following steps.</p><p>1. Normalize the data points.</li><li>Compute the centroids (referred to as code and the 2D array of centroids is referred to as code book).</li><li>Form clusters and assign the data points (referred to as mapping from code book).</li></ol></p><p></p><p><h3>cluster.vq.whiten() </h3></p><p>This method is used to normalize the data points. Normalization is very important when the attributes considered are of different units. For example, if the length is given in meters and breadth is given in inches, it may produce an unequal variance for the vectors. It is always preferred to have unit variance while performing K-Means clustering to get accurate clusters. Thus, the data array has to pass to whiten() method before any other steps.</p><p><em><strong>cluster.vq.whiten(input_array, check_finite)</strong></em></p><p><em>Parameters:</em><ol><li><em>input_array : The array of data points to be normalized.</em></li><li><em>check_finite : If set to true, checks whether the input matrix contains only finite numbers. If set to false, ignores checking.</em></li></ol></p><p></p><p><h3>cluster.vq.kmeans()</h3></p><p>This vq module has two methods namely kmeans() and kmeans2(). </p><p>The <strong>kmeans()</strong> method uses a threshold value which on becoming less than or equal to the change in distortion in the last iteration, the algorithm terminates. This method returns the centroids calculated and the mean value of the Euclidean distances between the observations and the centroids. </p><p> </p><p><em><strong>cluster.vq.kmeans(input_array, k, iterations, threshold, check_finite)</strong></em></p><p><em>Parameters:</em><ol><li><em>input_array : The array of data points to be normalized.</em></li><li><em>k : No.of.clusters (centroids)</em></li><li><em>iterations : No.of.iterations to perform kmeans so that distortion is minimized. If k is specified it is ignored.</em></li><li><em>threshold : An integer value which if becomes less than or equal to change in distortion in last iteration, the algorithm terminates.</em></li><li><em>check_finite : If set to true, checks whether the input matrix contains only finite numbers. If set to false, ignores checking.</em></li></ol></p><p>The <strong>kmeans2() </strong>method does not use the threshold value to check for convergence. It has more parameters that decide the method of initialization of centroids, a method to handle empty clusters, and validating whether the input matrices contain only finite numbers. This method returns centroids and the clusters to which the vector belongs.</p><p><em><strong>cluster.vq.kmeans2(input_array, k, iterations, threshold, minit, missing, check_finite)</strong></em></p><p><em>Parameters:</em><ol><li><em>input_array : The array of data points to be normalized.</em></li><li><em>k : No.of.clusters (centroids)</em></li><li><em>iterations : No.of.iterations to perform kmeans so that distortion is minimized. If k is specified it is ignored.</em></li><li><em>threshold : An integer value which if becomes less than or equal to change in distortion in last iteration, the algorithm terminates.</em></li><li><em>minit : A string which denotes the initialization method of the centroids. Possible values are </em><em><strong>‘random’, ‘points’, ‘++’, ‘matrix’</strong></em><em>.</em></li><li><em>missing : A string which denotes action upon empty clusters. Possible values are </em><em><strong>‘warn’, ‘raise’</strong></em><em>.</em></li><li><em>check_finite : If set to true, checks whether the input matrix contains only finite numbers. If set to false, ignores checking.</em></li></ol></p><p></p><p><h3>cluster.vq.vq()</h3></p><p>This method maps the observations to appropriate centroids which are calculated by the kmeans() method. It requires the input matrices to be normalized. It takes the normalized inputs and generated code-book as input. It returns the index in the code-book to which the observation corresponds to and the distance between the observation and its code (centroid).</p><p></p></div><div class='page'><h1 class='title level-3'>Random Init improvement</h1><br/><p><small>Random Init improvement in K-Means</small></p><p>Random initialization trap is a problem that occurs in the K-means algorithm. In random initialization trap when the centroids of the clusters to be generated are explicitly defined by the User then inconsistency may be created and this may sometimes lead to generating wrong clusters in the dataset. So random initialization trap may sometimes prevent us from developing the correct clusters. </p><p><strong>Example :</strong> </p><p>Suppose you have a dataset with the following points shown in the picture and you want to generate three clusters in this dataset according to their attributes by performing K-means clustering. From the figure, we can get the intuition what are the clusters that are required to be generated. K-means will perform clustering on the basis of the centroids fed into the algorithm and generate the required clusters according to these centroids.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200206014327/rand1.png"><img src="images/131-1.png" alt="images/131-1.png" /></a></p><p><strong>First Trial</strong> </p><p>Suppose we choose 3 sets of centroids according to the figure shown below. The clusters that are generated corresponding to these centroids are shown in the figure below.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200206014758/rand2.png"><img src="images/131-2.png" alt="images/131-2.png" /></a><strong>Final Model</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200206015629/rand3.png"><img src="images/131-3.png" alt="images/131-3.png" /></a><strong>Second Trial</strong> </p><p>Consider another case in which we choose another set of centroids for the dataset as shown. Now the set of clusters generated will be different from the clusters generated in the previous practice. </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200206020039/rand4.png"><img src="images/131-4.png" alt="images/131-4.png" /></a></p><p><strong>Final model</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20200206020912/rand5.png"><img src="images/131-5.png" alt="images/131-5.png" /></a>Similarly we may get different model outputs on the same dataset. This condition where a different set of clusters is generated when a different set of centroids are provided to the K-means algorithm making it inconsistent and unreliable is called the Random initialization trap.</p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124020206/imgonlinecomuaresizeCVGOsLsl1ks2hN0G.jpg"><img src="images/131-6.png" alt="images/131-6.png" /></a>  </p><p><strong>Implementation:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124020317/imgonlinecomuaresizeRUjs9WPowx.jpg"><img src="images/131-7.png" alt="images/131-7.png" /></a></p><p></p></div><div class='page'><h1 class='title level-2'>Feature Engineering</h1><br/></div><div class='page'><h1 class='title level-3'>Feature Selection Correlation Matrix</h1><br/><p><small>Feature Selection - with Correlation Matrix</small><ol><li>1. <strong><h2>1. Correlation Matrix</h2></strong></li></ol></p><p>A <em><strong>correlation matrix</strong></em> is simply a table which displays the correlation coefficients for different variables. The matrix depicts the correlation between all the possible pairs of values in a table. It is a powerful tool to summarize a large dataset and to identify and visualize patterns in the given data.</p><p>A correlation matrix consists of rows and columns that show the variables. Each cell in a table contains the correlation coefficient</p><p></p><p> <img src="images/133-1.png" alt="images/133-1.png" /></p><p>Implementation:</p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><br /><span style="color:#0088ff;font-weight:400"># import data</span><br />my_df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&quot;feature_selection_sample_data.csv&quot;</span>)<br /><br /><span style="color:#0088ff;font-weight:400"># run correlation matrix and plot</span><br />f, ax = plt.subplots(figsize=(<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">8</span>))<br />corr = my_df.corr()<br />sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool),<br />            cmap=sns.diverging_palette(<span style="color:#ff0044;font-weight:400">220</span>, <span style="color:#ff0044;font-weight:400">10</span>, as_cmap=<span style="color:#ff0044;font-weight:400">True</span>),<br />            square=<span style="color:#ff0044;font-weight:400">True</span>, ax=ax) </pre></div></p><p></p><p><strong>Let&#39;s take an example of dataset</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124023150/imgonlinecomuaresizeUpzOszuJcOXBIR.jpg"><img src="images/133-2.png" alt="images/133-2.png" /></a>  </p><p><strong>MIN-Max scaling:</strong></p><p><strong>MinMaxScaler</strong> scales all the data features in the range <em>[0, 1]</em> or else in the range <em>[-1, 1]</em> if there are negative values in the dataset. This scaling compresses all the inliers in the narrow range <em>[0, 0.005]</em>. </p><p>In the presence of outliers, StandardScaler does not guarantee balanced feature scales, due to the influence of the outliers while computing the empirical mean and standard deviation. This leads to the shrinkage in the range of the feature values. </p><p>   </p><p>   <img src="images/133-3.png" alt="images/133-3.png" /></p><p>   </p><p>     </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124023655/imgonlinecomuaresizeSaMl4v4S5Pu.jpg"><img src="images/133-4.png" alt="images/133-4.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Feature Selection Extra Tree Classifier</h1><br/><p><small>Feature Selection - with Extra Tree Classifier</small></p><p><strong>Extremely Randomized Trees Classifier(Extra Trees Classifier)</strong> is a type of ensemble learning technique which aggregates the results of multiple de-correlated decision trees collected in a “forest” to output it’s classification result. In concept, it is very similar to a Random Forest Classifier and only differs from it in the manner of construction of the decision trees in the forest.</p><p></p><p>Each Decision Tree in the Extra Trees Forest is constructed from the original training sample. Then, at each test node, Each tree is provided with a random sample of k features from the feature-set from which each decision tree must select the best feature to split the data based on some mathematical criteria (typically the Gini Index). This random sample of features leads to the creation of multiple de-correlated decision trees.</p><p>To perform feature selection using the above forest structure, during the construction of the forest, for each feature, the normalized total reduction in the mathematical criteria used in the decision of feature of split (Gini Index if the Gini Index is used in the construction of the forest) is computed. This value is called the Gini Importance of the feature. To perform feature selection, each feature is ordered in descending order according to the Gini Importance of each feature and the user selects the top k features according to his/her choice.</p><p>Consider the following data:-</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190719133406/data8.png"><img src="images/134-1.png" alt="images/134-1.png" /></a></p><p>Let us build a hypothetical Extra Trees Forest for the above data with <strong>five decision trees</strong> and the value of k which decides the number of features in a random sample of features be <strong>two</strong>. Here the decision criteria used will be Information Gain. First, we calculate the entropy of the data. Note the formula for calculating the entropy is:-</p><p><img src="images/134-2.png" alt="images/134-2.png" /></p><p>where c is the number of unique class labels and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d9fdb3a89f4dd9c043c9847440b7d75b_l3.svg"><img src="images/134-3.png" alt="images/134-3.png" /></a>is the proportion of rows with output label is i.</p><p>Therefore for the given data, the <strong>entropy</strong> is:-</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a38ff6d55917477bd431cb59fd61a8a3_l3.svg"><img src="images/134-4.png" alt="images/134-4.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6d338ecea02506250bb9a9c6ab30b164_l3.svg"><img src="images/134-5.png" alt="images/134-5.png" /></a><ul><li>t the decision trees be constructed such that:-</p><p>• <strong>1st Decision Tree gets data with the features Outlook and Temperature:</strong></li></ul></p><p></p><p>Note that the formula for Information Gain is:-</p><p><img src="images/134-6.png" alt="images/134-6.png" /></p><p>Thus,</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124110023/Screenshot20221124105725.jpg"><img src="images/134-7.png" alt="images/134-7.png" /></a>  </p><p><strong>2nd Decision Tree gets data with the features Temperature and Wind:</strong></p><p>Using the above-given formulas:-</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124110511/Screenshot20221124110354.jpg"><img src="images/134-8.png" alt="images/134-8.png" /></a> Computing total Info Gain for each feature:-</p><p><strong>Total Info Gain for Outlook     =     0.246+0.246   = 0.492</strong></p><p></p><p><strong>Total Info Gain for Temperature = 0.029+0.029+0.029 = 0.087</strong></p><p></p><p><strong>Total Info Gain for Humidity    = 0.151+0.151+0.151 = 0.453</strong></p><p></p><p><strong>Total Info Gain for Wind        =     0.048+0.048   = 0.096 </strong>Thus the most important variable to determine the output label according to the above constructed Extra Trees Forest is the feature “Outlook”.</p><p> </p><p>The below given code will demonstrate how to do feature selection by using Extra Trees Classifiers.</p><p></p><p><strong>Step 1: Importing the required libraries</strong></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.ensemble</span> <span style="color:#333333;font-weight:400">import</span> ExtraTreesClassifier <br /></pre></div></p><p><strong>Step 2: Loading and Cleaning the Data</strong></p><p><code></code></p><p><code></code><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Changing the working location to the location of the file</span><br />cd C:\Users\Dev\Desktop\Kaggle<br />  <br /><span style="color:#0088ff;font-weight:400"># Loading the data</span><br />df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;data.csv&#39;</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># Separating the dependent and independent variables</span><br />y = df[<span style="color:#3ad900;font-weight:400">&#39;Play Tennis&#39;</span>]<br />X = df.drop(<span style="color:#3ad900;font-weight:400">&#39;Play Tennis&#39;</span>, axis = <span style="color:#ff0044;font-weight:400">1</span>)<br />  <br />X.head() <br /></pre></div></p><p><strong>Step 3: Building the Extra Trees Forest and computing the individual feature importances</strong></p><p><code></code></p><p><code></code><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Building the model</span><br />extra_tree_forest = ExtraTreesClassifier(n_estimators = <span style="color:#ff0044;font-weight:400">5</span>,<br />                                        criterion =<span style="color:#3ad900;font-weight:400">&#39;entropy&#39;</span>, max_features = <span style="color:#ff0044;font-weight:400">2</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># Training the model</span><br />extra_tree_forest.fit(X, y)<br />  <br /><span style="color:#0088ff;font-weight:400"># Computing the importance of each feature</span><br />feature_importance = extra_tree_forest.feature_importances_<br />  <br /><span style="color:#0088ff;font-weight:400"># Normalizing the individual importances</span><br />feature_importance_normalized = np.std([tree.feature_importances_ <span style="color:#ff9d00;font-weight:700">for</span> tree <span style="color:#ff9d00;font-weight:700">in</span> <br />                                        extra_tree_forest.estimators_],<br />                                        axis = <span style="color:#ff0044;font-weight:400">0</span>) <br /></pre></div></p><p></p><p><strong>Step 4: Visualizing and Comparing the results</strong></p><p></p><p><div class="codebox"><pre>plt.bar(X.columns, feature_importance_normalized)<br />plt.xlabel(<span style="color:#3ad900;font-weight:400">&#39;Feature Labels&#39;</span>)<br />plt.ylabel(<span style="color:#3ad900;font-weight:400">&#39;Feature Importances&#39;</span>)<br />plt.title(<span style="color:#3ad900;font-weight:400">&#39;Comparison of different Feature Importances&#39;</span>)<br />plt.show() <br /></pre></div></p><p></p><p><img src="images/134-9.png" alt="images/134-9.png" /></p></div><div class='page'><h1 class='title level-3'>Select K Best Method</h1><br/><p><small>SelectK Best Method</small></p><p>Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the transform method:</p><p></p><p><strong>SelectKBest </strong>removes all but the k highest scoring features</p><p><strong>SelectPercentile</strong> removes all but a user-specified highest scoring percentage of features</p><p>using common univariate statistical tests for each feature: false positive rate SelectFpr, false discovery rate SelectFdr, or family wise error SelectFwe.</p><p><strong>GenericUnivariateSelect</strong> allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.</p><p></p><p></p><p>For instance, we can perform a χ2 test to the samples to retrieve only the two best features as follows:</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221124111552/WhatsAppImage20221124at111409.jpeg"><img src="images/135-1.png" alt="images/135-1.png" /></a> </p></div><div class='page'><h1 class='title level-3'>Principal Component Analysis Implementation</h1><br/><p><small>Principal Component Analysis(PCA) Implementation</small></p><p><strong>Principal Component Analysis (PCA) </strong>is a statistical procedure that uses an orthogonal transformation that converts a set of correlated variables to a set of uncorrelated variables. PCA is the most widely used tool in exploratory data analysis and in machine learning for predictive models. Moreover, PCA is an unsupervised statistical technique used to examine the interrelations among a set of variables. It is also known as a general factor analysis where regression determines a line of best fit.</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br />%matplotlib inline <br /></pre></div></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Here we are using inbuilt dataset of scikit learn</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.datasets</span> <span style="color:#333333;font-weight:400">import</span> load_breast_cancer<br />  <br /><span style="color:#0088ff;font-weight:400"># instantiating</span><br />cancer = load_breast_cancer()<br />  <br /><span style="color:#0088ff;font-weight:400"># creating dataframe</span><br />df = pd.DataFrame(cancer[<span style="color:#3ad900;font-weight:400">&#39;data&#39;</span>], columns = cancer[<span style="color:#3ad900;font-weight:400">&#39;feature_names&#39;</span>])<br />  <br /><span style="color:#0088ff;font-weight:400"># checking head of dataframe</span><br />df.head() <br /></pre></div></p><p></p><p><strong>Output:</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/o.png"><img src="images/136-1.png" alt="images/136-1.png" /></a></p><p><strong>Code #2:</strong></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Importing standardscalar module </span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.preprocessing</span> <span style="color:#333333;font-weight:400">import</span> StandardScaler<br />  <br />scalar = StandardScaler()<br />  <br /><span style="color:#0088ff;font-weight:400"># fitting</span><br />scalar.fit(df)<br />scaled_data = scalar.transform(df)<br />  <br /><span style="color:#0088ff;font-weight:400"># Importing PCA</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.decomposition</span> <span style="color:#333333;font-weight:400">import</span> PCA<br />  <br /><span style="color:#0088ff;font-weight:400"># Let&#39;s say, components = 2</span><br />pca = PCA(n_components = <span style="color:#ff0044;font-weight:400">2</span>)<br />pca.fit(scaled_data)<br />x_pca = pca.transform(scaled_data)<br />  <br />x_pca.shape <br /></pre></div></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># giving a larger plot</span><br />plt.figure(figsize =(<span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">6</span>))<br />  <br />plt.scatter(x_pca[:, <span style="color:#ff0044;font-weight:400">0</span>], x_pca[:, <span style="color:#ff0044;font-weight:400">1</span>], c = cancer[<span style="color:#3ad900;font-weight:400">&#39;target&#39;</span>], cmap =<span style="color:#3ad900;font-weight:400">&#39;plasma&#39;</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># labeling x and y axes</span><br />plt.xlabel(<span style="color:#3ad900;font-weight:400">&#39;First Principal Component&#39;</span>)<br />plt.ylabel(<span style="color:#3ad900;font-weight:400">&#39;Second Principal Component&#39;</span>) <br /></pre></div></p><p><strong>Output:</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/m.png"><img src="images/136-2.png" alt="images/136-2.png" /></a></p><p> </p><p><div class="codebox"><pre>pca.components_ <br /></pre></div></p><p><strong>Output:</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/a-5.png"><img src="images/136-3.png" alt="images/136-3.png" /></a></p><p></p><p><div class="codebox"><pre>df_comp = pd.DataFrame(pca.components_, columns = cancer[<span style="color:#3ad900;font-weight:400">&#39;feature_names&#39;</span>])<br />  <br />plt.figure(figsize =(<span style="color:#ff0044;font-weight:400">14</span>, <span style="color:#ff0044;font-weight:400">6</span>))<br />  <br /><span style="color:#0088ff;font-weight:400"># plotting heatmap</span><br />sns.heatmap(df_comp) <br /></pre></div></p><p></p><p><strong>Output:</strong></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/a1-4.png"><img src="images/136-4.png" alt="images/136-4.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>PCA</h1><br/><p><small>Principal Component Analysis</small></p><p>The main guiding principle for<strong> Principal Component Analysis</strong> is FEATURE EXTRACTION i.e. “Features of a data set should be less as well as the similarity between each other is very less.” In PCA, a new set of features are extracted from the original features which are quite dissimilar in nature.  So, an <strong>n-dimensional feature space</strong> gets transformed into an <strong>m-dimensional feature space.</strong>, where the dimensions are orthogonal to each other. </p><p><strong>Concept of Orthogonality: </strong>(In order to understand this topic, we have to go to the vector space concept in linear algebra) <strong>Vector Space </strong>is a set of vectors. They can be represented as a linear combination of the smaller set of vectors called <strong>BASIS VECTORS. </strong>So any vector ‘v’ in a vector space can be represented as: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a22f5e7faebea149b92f8a10f5a3ed3f_l3.svg"><img src="images/137-1.png" alt="images/137-1.png" /></a></p><p>where <em><strong>a</strong></em> represent ‘n’ scalars and u represents the basis vectors. Basis vectors are orthogonal to each other. Orthogonality of vectors can be thought of an extension of the vectors being perpendicular in a 2-D vector space<strong>. </strong>So our feature vector (data-set) can be transformed into a set of principal components (just like the basis vectors).</p><p><strong>Objectives of PCA:</strong><ol><li><strong> </strong>The new features are distinct i.e. the covariance between the new features (in case of PCA, they are the principal components) is <strong>0</strong></li><li>. The principal components are generated in order of the variability in the data that it captures. Hence, the first principal component should capture the maximum variability, the second one should capture the next highest variability etc.</li><li>The sum of the variance of the new features / the principal components should be equal to the sum of the variance of the original features.</li></ol></p><p><strong>Working of PCA: </strong></p><p>PCA works on a process called <strong>Eigenvalue Decomposition </strong><ul><li> a covariance matrix of a data set. The steps are as follows:</p><p>• First, calculate the covariance matrix of a data set.</li><li>Then, calculate the eigenvectors of the covariance matrix.</li><li>The eigenvector having the highest eigenvalue represents the direction in which there is the highest variance. So this will help in identifying the first principal component.</li><li>The eigenvector having the next highest eigenvalue represents the direction in which data has the highest remaining variance and also orthogonal to the first direction. So, this helps in identifying the second principal component.</li><li>Like this,<strong> </strong></li></ul>identify the top ‘k’ eigenvectors having top ‘k’ eigenvalues to get the ‘k’ principal components.</p><p></p><p><strong>Numerical for PCA :</strong></p><p>Consider the following dataset </p><p><table class="table"><tr><th>x1</th><th>2.5</th><th>0.5</th><th>2.2</th><th>1.9</th><th>3.1</th><th>2.3</th><th>2.0</th><th>1.0</th><th>1.5</th><th>1.1</th></tr><tr><td>x2</td><td>2.4</td><td>0.7</td><td>2.9</td><td>2.2</td><td>3.0</td><td>2.7</td><td>1.6</td><td>1.1</td><td>1.6</td><td>0.9</td></tr></table></p><p></p><p><strong><h4>Step 1: Standardize the Dataset </h4></strong></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c4c5b1d5592cd1b76bee8c3e830edcde_l3.svg"><img src="images/137-2.png" alt="images/137-2.png" /></a>= 1.81 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f35fba83156bbd4f5690a5bfc8ff4122_l3.svg"><img src="images/137-3.png" alt="images/137-3.png" /></a></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dcfebe10bd259feb900da37689cc1baa_l3.svg"><img src="images/137-4.png" alt="images/137-4.png" /></a>= 1.91 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0f9387441d8ae8581e351332713dd684_l3.svg"><img src="images/137-5.png" alt="images/137-5.png" /></a></p><p>We will change the dataset. </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e5def4fc68b6c762acdc66313c3e48de_l3.svg"><img src="images/137-6.png" alt="images/137-6.png" /></a></p><p></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1077ff231f6711dd39dcc16b7718f259_l3.svg"><img src="images/137-7.png" alt="images/137-7.png" /></a></p><p></p><p><table class="table"><tr><th> </th><th>0.69</th><th>-1.31</th><th>0.39</th><th>0.09</th><th>1.29</th><th>0.49</th><th>0.19</th><th>-0.81</th><th>-0.31</th><th>-0.71</th></tr><tr><td> </td><td>0.49</td><td>-1.21</td><td>0.99</td><td>0.29</td><td>1.09</td><td>0.79</td><td>-0.31</td><td>-0.81</td><td>-0.31</td><td>-1.01</td></tr></table></p><p></p><p><strong><h4>Step 2: Find the Eigenvalues and eigenvectors</h4></strong></p><p><strong>Correlation Matrix c =</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-873cee2a84a8f1c6f74324cac243f0bc_l3.svg"><img src="images/137-8.png" alt="images/137-8.png" /></a></p><p></p><p><strong>where, X is the Dataset Matrix</strong> (In this numerical, it is a 10 X 2 matrix) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-33cd71b6f33cf408b1f386cb0f391305_l3.svg"><img src="images/137-9.png" alt="images/137-9.png" /></a>is the transpose of the X (In this numerical, it is a 2 X 10 matrix) and N is the number of elements = 10</p><p>So,<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7cdd2117e95bb3853d4a4edca207ce25_l3.svg"><img src="images/137-10.png" alt="images/137-10.png" /></a></p><p>{So in order to calculate the Correlation Matrix, we have to do the multiplication of the Dataset Matrix with its transpose}</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6a38ba90e9d97f104f70efc39ae00bfe_l3.svg"><img src="images/137-11.png" alt="images/137-11.png" /></a></p><p>Using the equation,<strong> | C – </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-aecb62e9958e616dc3d446373e4277a9_l3.svg"><img src="images/137-12.png" alt="images/137-12.png" /></a>I |  = 0– <strong>equation (i) </strong>where { \lambda is the eigenvalue and I is the Identity Matrix }</p><p>So solving equation (i) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1ede3c9df3863a12781e502a31010625_l3.svg"><img src="images/137-13.png" alt="images/137-13.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c274bdf232aa36cbffc8e35b67e6be52_l3.svg"><img src="images/137-14.png" alt="images/137-14.png" /></a></p><p>Taking the determinant of the left side, we get</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-4d2e41c9067afa4237a53977047865b4_l3.svg"><img src="images/137-15.png" alt="images/137-15.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5e9f85d6f2bc8235a452453bac0eca96_l3.svg"><img src="images/137-16.png" alt="images/137-16.png" /></a></p><p>We get two values for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ed65800ff4c838fd06014bf5d86b329c_l3.svg"><img src="images/137-17.png" alt="images/137-17.png" /></a>, that are<strong> (</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-18.png" alt="images/137-18.png" /></a>) = 1.28403 and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-19.png" alt="images/137-19.png" /></a>) = 0.0490834. Now we have to find the eigenvectors for the eigenvalues<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-20.png" alt="images/137-20.png" /></a><strong>and</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-21.png" alt="images/137-21.png" /></a></p><p><strong>To find the eigenvectors from the eigenvalues, we will use the following approach:</strong></p><p>First, we will find the eigenvectors for the eigenvalue 1.28403 by using the equation<strong> </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ae55ecc9f93b4bb07132f019aab2640d_l3.svg"><img src="images/137-22.png" alt="images/137-22.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd0733dd0e900b0b987a2d9775a67f0f_l3.svg"><img src="images/137-23.png" alt="images/137-23.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d2e1afa5e121c04f08e30f0eebf537d1_l3.svg"><img src="images/137-24.png" alt="images/137-24.png" /></a></p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 1.28403x ; <strong>x = 0.922049 y</strong></p><p>(x and y belongs to the matrix X) so if we put y = 1, x comes out to be 0.922049. So now the updated X matrix will look like: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e654c073911bcaffe7066f9c3da84b03_l3.svg"><img src="images/137-25.png" alt="images/137-25.png" /></a></p><p><em><strong>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</strong></em></p><p><em>A. Find the square root of the sum of the squares of the element in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a4fb71213257e41f1606dad504ec90ad_l3.svg"><img src="images/137-26.png" alt="images/137-26.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a3c7dd34e75023aaeb79c01ad050dcd_l3.svg"><img src="images/137-27.png" alt="images/137-27.png" /></a><em> </em></p><p><em><strong>So now we found the eigenvectors for the eigenvector</strong></em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-efb28e3f1d41baedccf71316b09ba2de_l3.svg"><img src="images/137-28.png" alt="images/137-28.png" /></a>, they are 0.67787 and 0.73518</p><p><strong>Secondly, we will find the eigenvectors for the eigenvalue 0.0490834 by using the equation {Same approach as of previous step)</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-02f24d28041e7b96d86c41519355209e_l3.svg"><img src="images/137-29.png" alt="images/137-29.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-21eda558c35bced5aa4560b1dc8a807d_l3.svg"><img src="images/137-30.png" alt="images/137-30.png" /></a></p><p> </p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 0.0490834x;<strong> y = -0.922053</strong></p><p>(x and y belongs to the matrix X) so if we put x = 1, y comes out to be -0.922053 So now the updated X matrix will look like: </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-62f8097c21b2dba1bc99a70cf36d5e24_l3.svg"><img src="images/137-31.png" alt="images/137-31.png" /></a></p><p><em>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</em></p><p><em>A. Find the square root of the sum of the squares of the elements in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5948d70b11aeb8bfac16df41cbb520be_l3.svg"><img src="images/137-32.png" alt="images/137-32.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-374fa298c50267eca14d83f39d7024a2_l3.svg"><img src="images/137-33.png" alt="images/137-33.png" /></a></p><p><em><strong>So now we found the eigenvectors for the eigenvector \lambda_2, they are 0.735176 and 0.677873</strong></em></p><p>Sum of eigenvalues (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-34.png" alt="images/137-34.png" /></a>) and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-35.png" alt="images/137-35.png" /></a>) = 1.28403 + 0.0490834 = 1.33 =  Total Variance {Majority of variance comes from<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-36.png" alt="images/137-36.png" /></a>}</p><p></p><p><strong><h4>Step 3: Arrange Eigenvalues</h4></strong></p><p>The eigenvector with the highest eigenvalue is the Principal Component<strong> </strong>of the dataset. So in this case, eigenvectors of lambda1 are the principal components. </p><p>{Basically in order to complete the numerical we have to only solve till this step, but if we have to prove why we have chosen that particular eigenvector we have to follow the steps from 4 to 6<strong>}</strong></p><p></p><p><strong><h4>Step 4: Form Feature Vector</h4></strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-031b38cb799d8e1cb85a329b087d822c_l3.svg"><img src="images/137-37.png" alt="images/137-37.png" /></a>This is the FEATURE VECTOR for Numerical</p><p>Where first column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-38.png" alt="images/137-38.png" /></a>&amp; second column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-39.png" alt="images/137-39.png" /></a></p><p></p><p><strong><h4>Step 5: Transform Original Dataset</h4></strong></p><p>Use the equation Z = X V</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-89ab42274353da25ce0eb5278e46a56c_l3.svg"><img src="images/137-40.png" alt="images/137-40.png" /></a></p><p></p><p><strong><h4>Step 6: Reconstructing Data</h4></strong></p><p>Use the equation X =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dd54ba3675ed57330305c6c2a4b409ce_l3.svg"><img src="images/137-41.png" alt="images/137-41.png" /></a>(<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5a0defca83f45f94dbf87d6b852b6309_l3.svg"><img src="images/137-42.png" alt="images/137-42.png" /></a>is Transpose of V), X = Row Zero Mean Data</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d00cc81492ac1b388e80d13358095e1a_l3.svg"><img src="images/137-43.png" alt="images/137-43.png" /></a></p><p>So in order to reconstruct the original data, we follow:</p><p><strong>Row Original DataSet = Row Zero Mean Data + Original Mean </strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd22f811b5c8d4d78ad8325901627e66_l3.svg"><img src="images/137-44.png" alt="images/137-44.png" /></a></p><p>So for the eigenvectors of first eigenvalue, data can be reconstructed similar to the original dataset. Thus we can say that the Principal Component of the dataset is<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e4099ed0cb7a779c501d2a89950fd0c1_l3.svg"><img src="images/137-45.png" alt="images/137-45.png" /></a>is 1.28403 followed by <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-46.png" alt="images/137-46.png" /></a><strong>that is 0.0490834</strong></p><p></p><p></p><p>Report An Issue</p><p></p><p></p><p><small>Principal Component Analysis</small></p><p>The main guiding principle for<strong> Principal Component Analysis</strong> is FEATURE EXTRACTION i.e. “Features of a data set should be less as well as the similarity between each other is very less.” In PCA, a new set of features are extracted from the original features which are quite dissimilar in nature.  So, an <strong>n-dimensional feature space</strong> gets transformed into an <strong>m-dimensional feature space.</strong>, where the dimensions are orthogonal to each other. </p><p><strong>Concept of Orthogonality: </strong>(In order to understand this topic, we have to go to the vector space concept in linear algebra) <strong>Vector Space </strong>is a set of vectors. They can be represented as a linear combination of the smaller set of vectors called <strong>BASIS VECTORS. </strong>So any vector ‘v’ in a vector space can be represented as: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a22f5e7faebea149b92f8a10f5a3ed3f_l3.svg"><img src="images/137-47.png" alt="images/137-47.png" /></a></p><p>where <em><strong>a</strong></em> represent ‘n’ scalars and u represents the basis vectors. Basis vectors are orthogonal to each other. Orthogonality of vectors can be thought of an extension of the vectors being perpendicular in a 2-D vector space<strong>. </strong>So our feature vector (data-set) can be transformed into a set of principal components (just like the basis vectors).</p><p><strong>Objectives of PCA:</strong><ol><li><strong> </strong>The new features are distinct i.e. the covariance between the new features (in case of PCA, they are the principal components) is <strong>0</strong></li><li>. The principal components are generated in order of the variability in the data that it captures. Hence, the first principal component should capture the maximum variability, the second one should capture the next highest variability etc.</li><li>The sum of the variance of the new features / the principal components should be equal to the sum of the variance of the original features.</li></ol></p><p><strong>Working of PCA: </strong></p><p>PCA works on a process called <strong>Eigenvalue Decomposition </strong><ul><li> a covariance matrix of a data set. The steps are as follows:</p><p>• First, calculate the covariance matrix of a data set.</li><li>Then, calculate the eigenvectors of the covariance matrix.</li><li>The eigenvector having the highest eigenvalue represents the direction in which there is the highest variance. So this will help in identifying the first principal component.</li><li>The eigenvector having the next highest eigenvalue represents the direction in which data has the highest remaining variance and also orthogonal to the first direction. So, this helps in identifying the second principal component.</li><li>Like this,<strong> </strong></li></ul>identify the top ‘k’ eigenvectors having top ‘k’ eigenvalues to get the ‘k’ principal components.</p><p></p><p><strong>Numerical for PCA :</strong></p><p>Consider the following dataset </p><p><table class="table"><tr><th>x1</th><th>2.5</th><th>0.5</th><th>2.2</th><th>1.9</th><th>3.1</th><th>2.3</th><th>2.0</th><th>1.0</th><th>1.5</th><th>1.1</th></tr><tr><td>x2</td><td>2.4</td><td>0.7</td><td>2.9</td><td>2.2</td><td>3.0</td><td>2.7</td><td>1.6</td><td>1.1</td><td>1.6</td><td>0.9</td></tr></table></p><p></p><p><strong><h4>Step 1: Standardize the Dataset </h4></strong></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c4c5b1d5592cd1b76bee8c3e830edcde_l3.svg"><img src="images/137-48.png" alt="images/137-48.png" /></a>= 1.81 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f35fba83156bbd4f5690a5bfc8ff4122_l3.svg"><img src="images/137-49.png" alt="images/137-49.png" /></a></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dcfebe10bd259feb900da37689cc1baa_l3.svg"><img src="images/137-50.png" alt="images/137-50.png" /></a>= 1.91 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0f9387441d8ae8581e351332713dd684_l3.svg"><img src="images/137-51.png" alt="images/137-51.png" /></a></p><p>We will change the dataset. </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e5def4fc68b6c762acdc66313c3e48de_l3.svg"><img src="images/137-52.png" alt="images/137-52.png" /></a></p><p></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1077ff231f6711dd39dcc16b7718f259_l3.svg"><img src="images/137-53.png" alt="images/137-53.png" /></a></p><p></p><p><table class="table"><tr><th> </th><th>0.69</th><th>-1.31</th><th>0.39</th><th>0.09</th><th>1.29</th><th>0.49</th><th>0.19</th><th>-0.81</th><th>-0.31</th><th>-0.71</th></tr><tr><td> </td><td>0.49</td><td>-1.21</td><td>0.99</td><td>0.29</td><td>1.09</td><td>0.79</td><td>-0.31</td><td>-0.81</td><td>-0.31</td><td>-1.01</td></tr></table></p><p></p><p><strong><h4>Step 2: Find the Eigenvalues and eigenvectors</h4></strong></p><p><strong>Correlation Matrix c =</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-873cee2a84a8f1c6f74324cac243f0bc_l3.svg"><img src="images/137-54.png" alt="images/137-54.png" /></a></p><p></p><p><strong>where, X is the Dataset Matrix</strong> (In this numerical, it is a 10 X 2 matrix) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-33cd71b6f33cf408b1f386cb0f391305_l3.svg"><img src="images/137-55.png" alt="images/137-55.png" /></a>is the transpose of the X (In this numerical, it is a 2 X 10 matrix) and N is the number of elements = 10</p><p>So,<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7cdd2117e95bb3853d4a4edca207ce25_l3.svg"><img src="images/137-56.png" alt="images/137-56.png" /></a></p><p>{So in order to calculate the Correlation Matrix, we have to do the multiplication of the Dataset Matrix with its transpose}</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6a38ba90e9d97f104f70efc39ae00bfe_l3.svg"><img src="images/137-57.png" alt="images/137-57.png" /></a></p><p>Using the equation,<strong> | C – </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-aecb62e9958e616dc3d446373e4277a9_l3.svg"><img src="images/137-58.png" alt="images/137-58.png" /></a>I |  = 0– <strong>equation (i) </strong>where { \lambda is the eigenvalue and I is the Identity Matrix }</p><p>So solving equation (i) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1ede3c9df3863a12781e502a31010625_l3.svg"><img src="images/137-59.png" alt="images/137-59.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c274bdf232aa36cbffc8e35b67e6be52_l3.svg"><img src="images/137-60.png" alt="images/137-60.png" /></a></p><p>Taking the determinant of the left side, we get</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-4d2e41c9067afa4237a53977047865b4_l3.svg"><img src="images/137-61.png" alt="images/137-61.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5e9f85d6f2bc8235a452453bac0eca96_l3.svg"><img src="images/137-62.png" alt="images/137-62.png" /></a></p><p>We get two values for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ed65800ff4c838fd06014bf5d86b329c_l3.svg"><img src="images/137-63.png" alt="images/137-63.png" /></a>, that are<strong> (</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-64.png" alt="images/137-64.png" /></a>) = 1.28403 and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-65.png" alt="images/137-65.png" /></a>) = 0.0490834. Now we have to find the eigenvectors for the eigenvalues<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-66.png" alt="images/137-66.png" /></a><strong>and</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-67.png" alt="images/137-67.png" /></a></p><p><strong>To find the eigenvectors from the eigenvalues, we will use the following approach:</strong></p><p>First, we will find the eigenvectors for the eigenvalue 1.28403 by using the equation<strong> </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ae55ecc9f93b4bb07132f019aab2640d_l3.svg"><img src="images/137-68.png" alt="images/137-68.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd0733dd0e900b0b987a2d9775a67f0f_l3.svg"><img src="images/137-69.png" alt="images/137-69.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d2e1afa5e121c04f08e30f0eebf537d1_l3.svg"><img src="images/137-70.png" alt="images/137-70.png" /></a></p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 1.28403x ; <strong>x = 0.922049 y</strong></p><p>(x and y belongs to the matrix X) so if we put y = 1, x comes out to be 0.922049. So now the updated X matrix will look like: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e654c073911bcaffe7066f9c3da84b03_l3.svg"><img src="images/137-71.png" alt="images/137-71.png" /></a></p><p><em><strong>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</strong></em></p><p><em>A. Find the square root of the sum of the squares of the element in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a4fb71213257e41f1606dad504ec90ad_l3.svg"><img src="images/137-72.png" alt="images/137-72.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a3c7dd34e75023aaeb79c01ad050dcd_l3.svg"><img src="images/137-73.png" alt="images/137-73.png" /></a><em> </em></p><p><em><strong>So now we found the eigenvectors for the eigenvector</strong></em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-efb28e3f1d41baedccf71316b09ba2de_l3.svg"><img src="images/137-74.png" alt="images/137-74.png" /></a>, they are 0.67787 and 0.73518</p><p><strong>Secondly, we will find the eigenvectors for the eigenvalue 0.0490834 by using the equation {Same approach as of previous step)</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-02f24d28041e7b96d86c41519355209e_l3.svg"><img src="images/137-75.png" alt="images/137-75.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-21eda558c35bced5aa4560b1dc8a807d_l3.svg"><img src="images/137-76.png" alt="images/137-76.png" /></a></p><p> </p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 0.0490834x;<strong> y = -0.922053</strong></p><p>(x and y belongs to the matrix X) so if we put x = 1, y comes out to be -0.922053 So now the updated X matrix will look like: </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-62f8097c21b2dba1bc99a70cf36d5e24_l3.svg"><img src="images/137-77.png" alt="images/137-77.png" /></a></p><p><em>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</em></p><p><em>A. Find the square root of the sum of the squares of the elements in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5948d70b11aeb8bfac16df41cbb520be_l3.svg"><img src="images/137-78.png" alt="images/137-78.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-374fa298c50267eca14d83f39d7024a2_l3.svg"><img src="images/137-79.png" alt="images/137-79.png" /></a></p><p><em><strong>So now we found the eigenvectors for the eigenvector \lambda_2, they are 0.735176 and 0.677873</strong></em></p><p>Sum of eigenvalues (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-80.png" alt="images/137-80.png" /></a>) and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-81.png" alt="images/137-81.png" /></a>) = 1.28403 + 0.0490834 = 1.33 =  Total Variance {Majority of variance comes from<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-82.png" alt="images/137-82.png" /></a>}</p><p></p><p><strong><h4>Step 3: Arrange Eigenvalues</h4></strong></p><p>The eigenvector with the highest eigenvalue is the Principal Component<strong> </strong>of the dataset. So in this case, eigenvectors of lambda1 are the principal components. </p><p>{Basically in order to complete the numerical we have to only solve till this step, but if we have to prove why we have chosen that particular eigenvector we have to follow the steps from 4 to 6<strong>}</strong></p><p></p><p><strong><h4>Step 4: Form Feature Vector</h4></strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-031b38cb799d8e1cb85a329b087d822c_l3.svg"><img src="images/137-83.png" alt="images/137-83.png" /></a>This is the FEATURE VECTOR for Numerical</p><p>Where first column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-84.png" alt="images/137-84.png" /></a>&amp; second column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-85.png" alt="images/137-85.png" /></a></p><p></p><p><strong><h4>Step 5: Transform Original Dataset</h4></strong></p><p>Use the equation Z = X V</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-89ab42274353da25ce0eb5278e46a56c_l3.svg"><img src="images/137-86.png" alt="images/137-86.png" /></a></p><p></p><p><strong><h4>Step 6: Reconstructing Data</h4></strong></p><p>Use the equation X =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dd54ba3675ed57330305c6c2a4b409ce_l3.svg"><img src="images/137-87.png" alt="images/137-87.png" /></a>(<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5a0defca83f45f94dbf87d6b852b6309_l3.svg"><img src="images/137-88.png" alt="images/137-88.png" /></a>is Transpose of V), X = Row Zero Mean Data</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d00cc81492ac1b388e80d13358095e1a_l3.svg"><img src="images/137-89.png" alt="images/137-89.png" /></a></p><p>So in order to reconstruct the original data, we follow:</p><p><strong>Row Original DataSet = Row Zero Mean Data + Original Mean </strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd22f811b5c8d4d78ad8325901627e66_l3.svg"><img src="images/137-90.png" alt="images/137-90.png" /></a></p><p>So for the eigenvectors of first eigenvalue, data can be reconstructed similar to the original dataset. Thus we can say that the Principal Component of the dataset is<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e4099ed0cb7a779c501d2a89950fd0c1_l3.svg"><img src="images/137-91.png" alt="images/137-91.png" /></a>is 1.28403 followed by <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-92.png" alt="images/137-92.png" /></a><strong>that is 0.0490834</strong></p><p></p><p></p><p>Report An Issue</p><p></p><p></p><p><small>Principal Component Analysis</small></p><p>The main guiding principle for<strong> Principal Component Analysis</strong> is FEATURE EXTRACTION i.e. “Features of a data set should be less as well as the similarity between each other is very less.” In PCA, a new set of features are extracted from the original features which are quite dissimilar in nature.  So, an <strong>n-dimensional feature space</strong> gets transformed into an <strong>m-dimensional feature space.</strong>, where the dimensions are orthogonal to each other. </p><p><strong>Concept of Orthogonality: </strong>(In order to understand this topic, we have to go to the vector space concept in linear algebra) <strong>Vector Space </strong>is a set of vectors. They can be represented as a linear combination of the smaller set of vectors called <strong>BASIS VECTORS. </strong>So any vector ‘v’ in a vector space can be represented as: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a22f5e7faebea149b92f8a10f5a3ed3f_l3.svg"><img src="images/137-93.png" alt="images/137-93.png" /></a></p><p>where <em><strong>a</strong></em> represent ‘n’ scalars and u represents the basis vectors. Basis vectors are orthogonal to each other. Orthogonality of vectors can be thought of an extension of the vectors being perpendicular in a 2-D vector space<strong>. </strong>So our feature vector (data-set) can be transformed into a set of principal components (just like the basis vectors).</p><p><strong>Objectives of PCA:</strong><ol><li><strong> </strong>The new features are distinct i.e. the covariance between the new features (in case of PCA, they are the principal components) is <strong>0</strong></li><li>. The principal components are generated in order of the variability in the data that it captures. Hence, the first principal component should capture the maximum variability, the second one should capture the next highest variability etc.</li><li>The sum of the variance of the new features / the principal components should be equal to the sum of the variance of the original features.</li></ol></p><p><strong>Working of PCA: </strong></p><p>PCA works on a process called <strong>Eigenvalue Decomposition </strong><ul><li> a covariance matrix of a data set. The steps are as follows:</p><p>• First, calculate the covariance matrix of a data set.</li><li>Then, calculate the eigenvectors of the covariance matrix.</li><li>The eigenvector having the highest eigenvalue represents the direction in which there is the highest variance. So this will help in identifying the first principal component.</li><li>The eigenvector having the next highest eigenvalue represents the direction in which data has the highest remaining variance and also orthogonal to the first direction. So, this helps in identifying the second principal component.</li><li>Like this,<strong> </strong></li></ul>identify the top ‘k’ eigenvectors having top ‘k’ eigenvalues to get the ‘k’ principal components.</p><p></p><p><strong>Numerical for PCA :</strong></p><p>Consider the following dataset </p><p><table class="table"><tr><th>x1</th><th>2.5</th><th>0.5</th><th>2.2</th><th>1.9</th><th>3.1</th><th>2.3</th><th>2.0</th><th>1.0</th><th>1.5</th><th>1.1</th></tr><tr><td>x2</td><td>2.4</td><td>0.7</td><td>2.9</td><td>2.2</td><td>3.0</td><td>2.7</td><td>1.6</td><td>1.1</td><td>1.6</td><td>0.9</td></tr></table></p><p></p><p><strong><h4>Step 1: Standardize the Dataset </h4></strong></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c4c5b1d5592cd1b76bee8c3e830edcde_l3.svg"><img src="images/137-94.png" alt="images/137-94.png" /></a>= 1.81 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f35fba83156bbd4f5690a5bfc8ff4122_l3.svg"><img src="images/137-95.png" alt="images/137-95.png" /></a></p><p>Mean for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dcfebe10bd259feb900da37689cc1baa_l3.svg"><img src="images/137-96.png" alt="images/137-96.png" /></a>= 1.91 =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0f9387441d8ae8581e351332713dd684_l3.svg"><img src="images/137-97.png" alt="images/137-97.png" /></a></p><p>We will change the dataset. </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e5def4fc68b6c762acdc66313c3e48de_l3.svg"><img src="images/137-98.png" alt="images/137-98.png" /></a></p><p></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1077ff231f6711dd39dcc16b7718f259_l3.svg"><img src="images/137-99.png" alt="images/137-99.png" /></a></p><p></p><p><table class="table"><tr><th> </th><th>0.69</th><th>-1.31</th><th>0.39</th><th>0.09</th><th>1.29</th><th>0.49</th><th>0.19</th><th>-0.81</th><th>-0.31</th><th>-0.71</th></tr><tr><td> </td><td>0.49</td><td>-1.21</td><td>0.99</td><td>0.29</td><td>1.09</td><td>0.79</td><td>-0.31</td><td>-0.81</td><td>-0.31</td><td>-1.01</td></tr></table></p><p></p><p><strong><h4>Step 2: Find the Eigenvalues and eigenvectors</h4></strong></p><p><strong>Correlation Matrix c =</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-873cee2a84a8f1c6f74324cac243f0bc_l3.svg"><img src="images/137-100.png" alt="images/137-100.png" /></a></p><p></p><p><strong>where, X is the Dataset Matrix</strong> (In this numerical, it is a 10 X 2 matrix) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-33cd71b6f33cf408b1f386cb0f391305_l3.svg"><img src="images/137-101.png" alt="images/137-101.png" /></a>is the transpose of the X (In this numerical, it is a 2 X 10 matrix) and N is the number of elements = 10</p><p>So,<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7cdd2117e95bb3853d4a4edca207ce25_l3.svg"><img src="images/137-102.png" alt="images/137-102.png" /></a></p><p>{So in order to calculate the Correlation Matrix, we have to do the multiplication of the Dataset Matrix with its transpose}</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6a38ba90e9d97f104f70efc39ae00bfe_l3.svg"><img src="images/137-103.png" alt="images/137-103.png" /></a></p><p>Using the equation,<strong> | C – </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-aecb62e9958e616dc3d446373e4277a9_l3.svg"><img src="images/137-104.png" alt="images/137-104.png" /></a>I |  = 0– <strong>equation (i) </strong>where { \lambda is the eigenvalue and I is the Identity Matrix }</p><p>So solving equation (i) </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1ede3c9df3863a12781e502a31010625_l3.svg"><img src="images/137-105.png" alt="images/137-105.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c274bdf232aa36cbffc8e35b67e6be52_l3.svg"><img src="images/137-106.png" alt="images/137-106.png" /></a></p><p>Taking the determinant of the left side, we get</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-4d2e41c9067afa4237a53977047865b4_l3.svg"><img src="images/137-107.png" alt="images/137-107.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5e9f85d6f2bc8235a452453bac0eca96_l3.svg"><img src="images/137-108.png" alt="images/137-108.png" /></a></p><p>We get two values for<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ed65800ff4c838fd06014bf5d86b329c_l3.svg"><img src="images/137-109.png" alt="images/137-109.png" /></a>, that are<strong> (</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-110.png" alt="images/137-110.png" /></a>) = 1.28403 and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-111.png" alt="images/137-111.png" /></a>) = 0.0490834. Now we have to find the eigenvectors for the eigenvalues<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-112.png" alt="images/137-112.png" /></a><strong>and</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-113.png" alt="images/137-113.png" /></a></p><p><strong>To find the eigenvectors from the eigenvalues, we will use the following approach:</strong></p><p>First, we will find the eigenvectors for the eigenvalue 1.28403 by using the equation<strong> </strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ae55ecc9f93b4bb07132f019aab2640d_l3.svg"><img src="images/137-114.png" alt="images/137-114.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd0733dd0e900b0b987a2d9775a67f0f_l3.svg"><img src="images/137-115.png" alt="images/137-115.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d2e1afa5e121c04f08e30f0eebf537d1_l3.svg"><img src="images/137-116.png" alt="images/137-116.png" /></a></p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 1.28403x ; <strong>x = 0.922049 y</strong></p><p>(x and y belongs to the matrix X) so if we put y = 1, x comes out to be 0.922049. So now the updated X matrix will look like: </p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e654c073911bcaffe7066f9c3da84b03_l3.svg"><img src="images/137-117.png" alt="images/137-117.png" /></a></p><p><em><strong>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</strong></em></p><p><em>A. Find the square root of the sum of the squares of the element in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a4fb71213257e41f1606dad504ec90ad_l3.svg"><img src="images/137-118.png" alt="images/137-118.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9a3c7dd34e75023aaeb79c01ad050dcd_l3.svg"><img src="images/137-119.png" alt="images/137-119.png" /></a><em> </em></p><p><em><strong>So now we found the eigenvectors for the eigenvector</strong></em><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-efb28e3f1d41baedccf71316b09ba2de_l3.svg"><img src="images/137-120.png" alt="images/137-120.png" /></a>, they are 0.67787 and 0.73518</p><p><strong>Secondly, we will find the eigenvectors for the eigenvalue 0.0490834 by using the equation {Same approach as of previous step)</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-02f24d28041e7b96d86c41519355209e_l3.svg"><img src="images/137-121.png" alt="images/137-121.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-21eda558c35bced5aa4560b1dc8a807d_l3.svg"><img src="images/137-122.png" alt="images/137-122.png" /></a></p><p> </p><p>Solving the matrices, we get</p><p>0.616556x + 0.615444y = 0.0490834x;<strong> y = -0.922053</strong></p><p>(x and y belongs to the matrix X) so if we put x = 1, y comes out to be -0.922053 So now the updated X matrix will look like: </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-62f8097c21b2dba1bc99a70cf36d5e24_l3.svg"><img src="images/137-123.png" alt="images/137-123.png" /></a></p><p><em>IMP: Till now we haven’t reached to the eigenvectors, we have to a bit of modifications in the X matrix. They are as follows:</em></p><p><em>A. Find the square root of the sum of the squares of the elements in X matrix i.e.</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5948d70b11aeb8bfac16df41cbb520be_l3.svg"><img src="images/137-124.png" alt="images/137-124.png" /></a></p><p><em>B. Now divide the elements of the X matrix by the number 1.3602 (just found that)</em></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-374fa298c50267eca14d83f39d7024a2_l3.svg"><img src="images/137-125.png" alt="images/137-125.png" /></a></p><p><em><strong>So now we found the eigenvectors for the eigenvector \lambda_2, they are 0.735176 and 0.677873</strong></em></p><p>Sum of eigenvalues (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-126.png" alt="images/137-126.png" /></a>) and (<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-127.png" alt="images/137-127.png" /></a>) = 1.28403 + 0.0490834 = 1.33 =  Total Variance {Majority of variance comes from<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-128.png" alt="images/137-128.png" /></a>}</p><p></p><p><strong><h4>Step 3: Arrange Eigenvalues</h4></strong></p><p>The eigenvector with the highest eigenvalue is the Principal Component<strong> </strong>of the dataset. So in this case, eigenvectors of lambda1 are the principal components. </p><p>{Basically in order to complete the numerical we have to only solve till this step, but if we have to prove why we have chosen that particular eigenvector we have to follow the steps from 4 to 6<strong>}</strong></p><p></p><p><strong><h4>Step 4: Form Feature Vector</h4></strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-031b38cb799d8e1cb85a329b087d822c_l3.svg"><img src="images/137-129.png" alt="images/137-129.png" /></a>This is the FEATURE VECTOR for Numerical</p><p>Where first column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f0e4084a97b49b7112c27606505f4e6a_l3.svg"><img src="images/137-130.png" alt="images/137-130.png" /></a>&amp; second column are the eigenvectors of<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ca23d4644827d930543e08665e508753_l3.svg"><img src="images/137-131.png" alt="images/137-131.png" /></a></p><p></p><p><strong><h4>Step 5: Transform Original Dataset</h4></strong></p><p>Use the equation Z = X V</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-89ab42274353da25ce0eb5278e46a56c_l3.svg"><img src="images/137-132.png" alt="images/137-132.png" /></a></p><p></p><p><strong><h4>Step 6: Reconstructing Data</h4></strong></p><p>Use the equation X =<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-dd54ba3675ed57330305c6c2a4b409ce_l3.svg"><img src="images/137-133.png" alt="images/137-133.png" /></a>(<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5a0defca83f45f94dbf87d6b852b6309_l3.svg"><img src="images/137-134.png" alt="images/137-134.png" /></a>is Transpose of V), X = Row Zero Mean Data</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d00cc81492ac1b388e80d13358095e1a_l3.svg"><img src="images/137-135.png" alt="images/137-135.png" /></a></p><p>So in order to reconstruct the original data, we follow:</p><p><strong>Row Original DataSet = Row Zero Mean Data + Original Mean </strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fd22f811b5c8d4d78ad8325901627e66_l3.svg"><img src="images/137-136.png" alt="images/137-136.png" /></a></p><p>So for the eigenvectors of first eigenvalue, data can be reconstructed similar to the original dataset. Thus we can say that the Principal Component of the dataset is<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-e4099ed0cb7a779c501d2a89950fd0c1_l3.svg"><img src="images/137-137.png" alt="images/137-137.png" /></a>is 1.28403 followed by <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1fa49aa6bf155130a4e931e885080c0c_l3.svg"><img src="images/137-138.png" alt="images/137-138.png" /></a><strong>that is 0.0490834</strong></p><p></p><p></p><p>Report An Issue</p><p></p><p></p></div><div class='page'><h1 class='title level-3'>TSNE</h1><br/><p><small>TSNE</small></p><p><strong>T-distributed Stochastic Neighbor Embedding (t-SNE)</strong> is a nonlinear dimensionality reduction technique for embedding high-dimensional data for visualization in a low-dimensional space of two or three dimensions.</p><p></p><p><strong>What is Dimensionality Reduction?</strong> </p><p>Dimensionality Reduction is the technique of representing n-dimensions data(multidimensional data with many features) in 2 or 3 dimensions.</p><p>An example of dimensionality reduction can be discussed as a classification problem i.e. student will play football or not that relies on both temperature and humidity can be collapsed into just one underlying feature, since both of the features are correlated to a high degree. Hence, we can reduce the number of features in such problems. A 3-D classification problem can be hard to visualize, whereas a 2-D one can be mapped to simple 2-dimensional space and a 1-D problem to a simple line.</p><p><strong>How does t-SNE works?</strong> </p><p></p><p>t-SNE a non-linear dimensionality reduction algorithm <span style="color:#8ff0a4;">finds patterns</span> in the data based on the similarity of data points with features, the similarity of points is calculated as the conditional probability that a point A would choose point B as its neighbour. </p><p></p><p>It then tries to <span style="color:#8ff0a4;">minimize</span> the difference between these conditional probabilities </p><p>(or similarities) in higher-dimensional and lower-dimensional space for a perfect representation of data points in lower-dimensional space.</p><p> </p><p><strong>Space and Time Complexity:</strong> </p><p></p><p>The algorithm computes pairwise conditional probabilities and tries to minimize the sum of the difference of the probabilities in higher and lower dimensions. This involves a lot of calculations and computations. So the algorithm takes a lot of time and space to compute. t-SNE has a quadratic time and space complexity in the number of data points.</p><p><strong>Code: Python code implementing T-SNE on MNIST dataset</strong></p><p></p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Importing Necessary Modules.</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> pandas <span style="color:#333333;font-weight:400">as</span> pd<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.manifold</span> <span style="color:#333333;font-weight:400">import</span> TSNE<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.preprocessing</span> <span style="color:#333333;font-weight:400">import</span> StandardScaler <br />											</pre></div></p><p></p><p><strong>Code #1: Reading data</strong></p><p><div class="codebox"><pre><br />df = pd.read_csv(<span style="color:#3ad900;font-weight:400">&#39;mnist_train.csv&#39;</span>)<br /> <br /><span style="color:#0088ff;font-weight:400"># print first five rows of df</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(df.head(<span style="color:#ff0044;font-weight:400">4</span>))<br /> <br /><span style="color:#0088ff;font-weight:400"># save the labels into a variable l.</span><br />l = df[<span style="color:#3ad900;font-weight:400">&#39;label&#39;</span>]<br /> <br /><span style="color:#0088ff;font-weight:400"># Drop the label feature and store the pixel data in d.</span><br />d = df.drop(<span style="color:#3ad900;font-weight:400">&quot;label&quot;</span>, axis = <span style="color:#ff0044;font-weight:400">1</span>) <br /></pre></div></p><p></p><p></p><p><strong>Output: </strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190420195440/Screenshot-2019-04-20-at-7.53.53-PM.png"><img src="images/138-1.png" alt="images/138-1.png" /></a></p><p><strong>Code #2:</strong> Data-preprocessing </p><p><code></code></p><p><code></code><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Data-preprocessing: Standardizing the data</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.preprocessing</span> <span style="color:#333333;font-weight:400">import</span> StandardScaler<br /> <br />standardized_data = StandardScaler().fit_transform(data)<br /><span style="color:#ff9d00;font-weight:700">print</span>(standardized_data.shape) <br /><br /><span style="color:#0088ff;font-weight:400"># TSNE</span><br /><span style="color:#0088ff;font-weight:400"># Picking the top 1000 points as TSNE</span><br /><span style="color:#0088ff;font-weight:400"># takes a lot of time for 15K points</span><br />data_1000 = standardized_data[<span style="color:#ff0044;font-weight:400">0</span>:<span style="color:#ff0044;font-weight:400">1000</span>, :]<br />labels_1000 = labels[<span style="color:#ff0044;font-weight:400">0</span>:<span style="color:#ff0044;font-weight:400">1000</span>]<br /><br />model = TSNE(n_components = <span style="color:#ff0044;font-weight:400">2</span>, random_state = <span style="color:#ff0044;font-weight:400">0</span>)<br /><span style="color:#0088ff;font-weight:400"># configuring the parameters</span><br /><span style="color:#0088ff;font-weight:400"># the number of components = 2</span><br /><span style="color:#0088ff;font-weight:400"># default perplexity = 30</span><br /><span style="color:#0088ff;font-weight:400"># default learning rate = 200</span><br /><span style="color:#0088ff;font-weight:400"># default Maximum number of iterations</span><br /><span style="color:#0088ff;font-weight:400"># for the optimization = 1000</span><br /><br />tsne_data = model.fit_transform(data_1000)<br /><br /><span style="color:#0088ff;font-weight:400"># creating a new data frame which</span><br /><span style="color:#0088ff;font-weight:400"># help us in plotting the result data</span><br />tsne_data = np.vstack((tsne_data.T, labels_1000)).T<br />tsne_df = pd.DataFrame(data = tsne_data,<br />	columns =(<span style="color:#3ad900;font-weight:400">&quot;Dim_1&quot;</span>, <span style="color:#3ad900;font-weight:400">&quot;Dim_2&quot;</span>, <span style="color:#3ad900;font-weight:400">&quot;label&quot;</span>))<br /><br /><span style="color:#0088ff;font-weight:400"># Plotting the result of tsne</span><br />sn.FacetGrid(tsne_df, hue =<span style="color:#3ad900;font-weight:400">&quot;label&quot;</span>, size = <span style="color:#ff0044;font-weight:400">6</span>).map(<br />	plt.scatter, <span style="color:#3ad900;font-weight:400">&#39;Dim_1&#39;</span>, <span style="color:#3ad900;font-weight:400">&#39;Dim_2&#39;</span>).add_legend()<br /><br />plt.show()<br /></pre></div> </p><p><strong>Output: </strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190420195513/Screenshot-2019-04-20-at-7.54.25-PM.png"><img src="images/138-2.png" alt="images/138-2.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>K-Fold Cross Validation</h1><br/><p><small>K-Fold Cross Validation</small></p><p><strong>K-Fold Cross Validation</strong></p><p></p><p>In this method, we split the data-set into k number of subsets(known as folds) </p><p></p><p>then we perform training on the all the subsets but leave one(k-1) subset for the evaluation of the trained model. In this method, we iterate k times with a different subset reserved for testing purpose each time.</p><p></p><p><em><strong>Note:</strong></em></p><p></p><p>It is always suggested that the value of k should be 10 as the lower value </p><p>of k is takes towards validation and higher value of k leads to LOOCV method.</p><p></p><p><strong>Example</strong></p><p>The diagram below shows an example of the training subsets and evaluation subsets generated in k-fold cross-validation. Here, we have total 25 instances. In first iteration we use the first 20 percent of data for evaluation, and the remaining 80 percent for training([1-5] testing and [5-25] training) while in the second iteration we use the second subset of 20 percent for evaluation, and the remaining three subsets of the data for training([5-10] testing and [1-5 and 10-25] training), and so on.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/crossValidation.jpg"><img src="images/139-1.png" alt="images/139-1.png" /></a></p><p>Total instances: 25</p><p>Value of k     : 5 </p><p></p><p>No. Iteration              Training set observations                     Testing set observations</p><p> 1      [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]   [0 1 2 3 4]</p><p> 2      [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]   [5 6 7 8 9]</p><p> 3      [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]   [10 11 12 13 14]</p><p> 4      [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]   [15 16 17 18 19]</p><p> 5      [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]</p><p> </p><p> <strong>Comparison of train/test split to cross-validation</strong><ol><li>antages of train/test split:</p><p>1. This runs K times faster than Leave One Out cross-validation because K-fold cross-validation repeats the train/test split K-times.</li><li>Simpler to examine the detailed results of the testing process.</li></ol></p><p>Advantages of cross-validation:<ol><li>More accurate estimate of out-of-sample accuracy.</li><li>More “efficient” use of data as every observation is used for both training and testing.</li></ol></p><p>Python code for k fold cross-validation.</p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># importing cross-validation from sklearn package.</span><br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn</span> <span style="color:#333333;font-weight:400">import</span> cross_validation<br /><br /><span style="color:#0088ff;font-weight:400"># value of K is 10.</span><br />data = cross_validation.KFold(<span style="color:#ff9d00;font-weight:700">len</span>(train_set), n_folds=<span style="color:#ff0044;font-weight:400">10</span>, indices=<span style="color:#ff0044;font-weight:400">False</span>)<br /></pre></div></p></div><div class='page'><h1 class='title level-1'>Deep Learning</h1><br/></div><div class='page'><h1 class='title level-2'>Convolution Neural Network</h1><br/><p><h2>Convolutional Neural Network (CNN)</h2></p><p><strong>Convolutional </strong><strong><a href="https://www.geeksforgeeks.org/neural-networks-a-beginners-guide/">Neural Network</a></strong><strong>(CNN) :</strong><ul><li>A convolutional neural network, or CNN, is a deep learning neural network sketched for processing structured arrays of data such as portrayals.</li><li>CNN are very satisfactory at picking up on design in the input image, such as lines, gradients, circles, or even eyes and faces.</li><li>This characteristic that makes convolutional neural network so robust for computer vision.</li><li>CNN can run directly on a underdone image and do not need any preprocessing.</li><li>A convolutional neural network is a feed forward neural network, seldom with up to 20.</li><li>The strength of a convolutional neural network comes from a particular kind of layer called the convolutional layer.</li><li>CNN contains many convolutional layers assembled on top of each other, each one competent of recognizing more sophisticated shapes.</li><li>With three or four convolutional layers it is viable to recognize handwritten digits and with 25 layers it is possible to differentiate human faces.</li><li>The agenda for this sphere is to activate machines to view the world as humans do, perceive it in a alike fashion and even use the knowledge for a multitude of duty such as image and video recognition, image inspection and classification, media recreation, recommendation systems, natural language processing, etc.</li></ul></p><p></p><p><strong>Convolutional Neural Network Design :</strong><ul><li>The construction of a convolutional neural network is a multi-layered feed-forward neural network, made by assembling many unseen layers on top of each other in a particular order.</li><li>It is the sequential design that give permission to CNN to learn hierarchical attributes.</li><li>In CNN, some of them followed by grouping layers and hidden layers are typically convolutional layers followed by activation layers.</li><li>The pre-processing needed in a ConvNet is kindred to that of the related pattern of neurons in the human brain and was motivated by the organization of the Visual Cortex.</li></ul></p><p></p><p><strong>Case Study of CNN for Diabetic retinopathy :</strong><ul><li>Diabetic retinopathy also known as diabetic eye disease, is a medical state in which destruction occurs to the retina due to diabetes mellitus, It is a major cause of blindness in advance countries.</li><li>Diabetic retinopathy influence up to 80 percent of those who have had diabetes for 20 years or more.</li><li>The overlong a person has diabetes, the higher his or her chances of growing diabetic retinopathy.</li><li>It is also the main cause of blindness in people of age group 20-64.</li><li>Diabetic retinopathy is the outcome of destruction to the small blood vessels and neurons of the retina.</li></ul></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Need Of CNN</h1><br/><p><h2>Need of CNN</h2></p><p>Before starting with the importance of CNN, we should understand why do we use CNN or what was the need to develop a CNN model when we had fully connected neural networks available. </p><p><strong>Need of CNN and why to use CNN over fully connected neural networks:</strong></p><p></p><p>In an ANN model each feature was ingested in the input layer and then each neuron of the input layer was connected with neurons of the hidden layer. Then weights were assigned to the channels between these neurons.</p><p> These neurons would take the input and weight then add the bias term and apply the activation function to produce the output that is to be ingested to the next layer. Hence output was produced in this way.</p><p></p><p></p><p>Now let us consider that we have to solve a problem where our input data is going to be an image. We know that our computer understands image in forms of matrices. To process an image we need to enter each pixel to each neuron, for a 100x100 colored image we have to provide 100x100x3(3 for RGB) input neurons. Now each matrix has a size of 100x100 and exists 3 times for each RGB color which comes out to be 30,000. The main problem that arises now is that we have to provide 30,000 weights from the input layer to the first hidden layer. Now just think how much weights do we need from 1 layer to 2 layer to 3rd until the output layer. </p><p></p><p>Yes it would be an exponential growth as the number of parameters would drastically increase as we increase the number of neurons in the hidden layer. This was just for an image i.e., composed of 100x100 pixels, just think if the images would be 1920x1080 and contains more than 3 colors. Training such huge datasets might lead to overfitting and also loss of important parameters as there is already a large number of parameters. Also the minor details of each individual images might also get lost in the process. But keep in mind an important thing that for small classification models like to predict whether the picture is of a dog or not we can use ANN networks. </p><p>Because of all these problems that arose in the ANN, CNN was introduced. CNN is more accurate and is an efficient way of dealing with image classification problems. In a simple ANN model if we input an image it would convert it to a simple 1D vector before training the model. CNNs are preferred for image classification problems because of their abilities to deal with images. CNNs unlike ANNs doesn&#39;t convert an image to 1D vector in the start but first ingests the image through multiple convolutional layers where due to sparse interaction and selective parameter sharing we are left with only important aspects of the image. Then after the convolved layer we flatten the convolved image and pass it to the dense layer.</p><p> </p><p></p></div><div class='page'><h1 class='title level-3'>Importance of CNN</h1><br/><p><small>Importance of CNN</small></p><p>Let’s analyze the advantages of a convolutional neural network over a simple deep learning network. </p><p><strong>Weight sharing:</strong> </p><p>It makes use of Local Spatial coherence that provides same weights to some of the edges, In this way, this weight sharing minimizes the cost of computing. This is especially useful when GPU is low power or missing. </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190528195150/Screenshot-3051.png"><img src="images/144-1.png" alt="images/144-1.png" /></a></p><p><strong>Memory Saving:</strong> </p><p>The reduced number of parameters helps in memory saving. For e.g. in case of MNIST dataset to recognize digits, if we use a CNN with single hidden layer and 10 nodes, it would require few hundred nodes but if we use a simple deep neural network, it would require around 19000 parameters. </p><p></p><p><strong>Independent of local variations in Image:</strong> </p><p>Let’s consider if we are training our fully connected neural network for face recognition with head-shot images of people, Now if we test it on an image which is not a head-shot image but full body image then it may fail to recognize. Since the convolutional neural network makes use of convolution operation, they are independent of local variations in the image. </p><p></p><p><strong>Equivariance: </strong></p><p>Equivariance is the property of CNNs and one that can be seen as a specific type of parameter sharing. Conceptually, a function can be considered equivariance if, upon a change in the input, a similar change is reflected in the output. Mathematically, it can be represented as f(g(x)) = g(f(x)). It turns out that convolutions are equivariant to many data transformation operations which helps us to identify, how a particular change in input will affect the output. This helps us to identify any drastic change in the output and retain the reliability of the model. </p><p><strong>Independent of Transformations:</strong> </p><p></p><p>CNNs are much more independent to geometrical transformations like Scaling, Rotation etc. </p><p><strong>Example of Translation independence – </strong>CNN identifies object correctly </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190528200250/Screenshot-2992-1024x363.png"><img src="images/144-2.png" alt="images/144-2.png" /></a></p><p><strong>Example of Rotation independence –</strong> CNN identifies object correctly </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190528200418/Screenshot-3061-1024x338.png"><img src="images/144-3.png" alt="images/144-3.png" /></a></p><p> </p><p></p></div><div class='page'><h1 class='title level-3'>Working of CNN</h1><br/><p><small>Working of Convolutional Neural Network (CNN)</small><ol><li>this article, we are going to see the working of convolution neural networks with TensorFlow a powerful machine learning library to create neural networks.</p><p>Now to know, how a convolution neural network lets break it into parts. the 3 most important parts of this convolution neural networks are,</p><p>1. Convolution</li><li>Pooling</li><li>Flattening</li></ol></p><p>These 3 actions are the very special things that make convolution neural networks perform way better compared with other artificial neural networks. Now, let’s discuss them in detail,</p><p></p><p><h2>Convolution</h2></p><p>Think about a 28*28 image like a MINST dataset which is basically a handwritten digits recognition. To build a model to recognize the digits with a simple artificial neural network we will feed each pixels value individually as a feature input inside the model and that is 784 input nodes and you will have a couple of hidden layers and the model may perform well but the problem here is the model will not be able to recognize the important features in the image. It will blindly read the pixels and spit the output.  </p><p>But an image that is so small in size like this MINST dataset (28 by 28 image) which will give the model 784 inputs each node should divide into hidden layers and there will be a lot of weight assigned and obviously there will be a tremendous amount of calculation. Now think of an image in the size of 1920 by 1080 an Ultra HD, If we follow the same method, practically there will be 2 million input nodes and even we take a hidden layer of 64 nodes which is not at all enough for this large input we will have 130 million weights and there will be an insane amount of calculation and your machine cannot even think of managing that much calculations at a time.</p><p>So for this, we first need to find the important features of an image,</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20211129095034/Importantfeaturesoftheimage.png"><img src="images/145-1.png" alt="images/145-1.png" /></a></p><p>By finding these important features we can leave some unwanted pixels back without compromising our output quality. With this method, we can give the model a human level of image recognition in the real world. So for this, we have convolution.</p><p>Convolution is the most confused and hardest topic over the internet, but simply it is just searching the image by sliding a filter (kernel) across the image to find different features of the image. Kernels are just 2D matrices with different weights in them. Basically, this kernel will pass over the image replacing the pixel values with the average of the sum of its weight on the respective part of the image. These kernels are an amazing way to find the most important features in the image.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20211129095155/convolution.png"><img src="images/145-2.png" alt="images/145-2.png" /></a></p><p>We will apply a number of randomly generated kernels to the image for finding many different features of the images  </p><p>So after applying this convolution layer to our model we need to pool the features.</p><p></p><p><h2>Pooling</h2></p><p>Now that you have found the important features of the image, still, the amount of input is very large and our machine could not be able to handle this amount of inputs. So here is where pooling comes.  </p><p>Pooling is just reducing the size of the image without losing the features that we found with convolution. For example, a MaxPooling method will take in a shape of a matrix and return the larger value in that range. By doing this we can compress the image without losing the important features of this image.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20211129095403/Pooling.png"><img src="images/145-3.png" alt="images/145-3.png" /></a></p><p></p><p><h2>Flattening</h2></p><p>Flattening is nothing but converting a 3D or 2D matrix into a 1D input for the model this will be our last step to process the image and connect the inputs to a fully connected dense layer for further classification.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20211129095537/Pooling1.png"><img src="images/145-4.png" alt="images/145-4.png" /></a></p><p><strong>To sum up, The way a convolution neural network works is:</strong><ul><li>Applying convolution to find different importand features inside the image   </li></ul></p><p></p><p><em><strong>   </strong></em><em>syntax: model.add(layers.Conv2D(no. of kernels, size of the kernel, activation=’relu’, input_shape)</em><ul><li> </p><p>◇ Applying pooling to compress the image without losing its features   </li></ul></p><p></p><p><em><strong>   </strong></em><em>syntax:  model.add(layers.MaxPooling2D((size of the kernel)))</em><ul><li>  FLattening it to a 1-dimensional input from a 3D[color images] or 2D [Black and white images] to pass into the model   </li></ul></p><p></p><p><em>  </em><em><strong> </strong></em><em>syntax: model.add(layers.Flatten()</em><ul><li>Fully connected input and hidden layers to play with weights and biases and activation functions and optimizers.</li><li>Wola! You have built the best image classifier.</li></ul></p><p></p><p></p><p><h3>A typical CNN model will look like:</h3></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Importing the library</span><br /><span style="color:#333333;font-weight:400">import</span> tensorflow <span style="color:#333333;font-weight:400">as</span> tf<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">tensorflow</span> <span style="color:#333333;font-weight:400">import</span> keras<br /><br /><span style="color:#0088ff;font-weight:400"># Designing the model</span><br />model = tf.keras.models.Sequential([<br />	<span style="color:#0088ff;font-weight:400"># Convolutional layer1</span><br />	tf.keras.layers.Conv2D(<br />		<span style="color:#ff0044;font-weight:400">32</span>, (<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">3</span>), activation=<span style="color:#3ad900;font-weight:400">&#39;relu&#39;</span>, input_shape=(<span style="color:#ff0044;font-weight:400">32</span>, <span style="color:#ff0044;font-weight:400">32</span>, <span style="color:#ff0044;font-weight:400">3</span>))<br />	tf.keras.layers.MaxPooling2D((<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>)) <span style="color:#0088ff;font-weight:400"># Pooling</span><br />	<span style="color:#0088ff;font-weight:400"># COnvolutional layer2</span><br />	tf.keras.layers.Conv2D(<span style="color:#ff0044;font-weight:400">64</span>, (<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">3</span>), activation=<span style="color:#3ad900;font-weight:400">&#39;relu&#39;</span>)<br />	tf.keras.layers.MaxPooling2D((<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>)) <span style="color:#0088ff;font-weight:400"># Pooling</span><br />	<span style="color:#0088ff;font-weight:400"># COnvolutional layer3</span><br />	tf.keras.layers.Conv2D(<span style="color:#ff0044;font-weight:400">64</span>, (<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">3</span>), activation=<span style="color:#3ad900;font-weight:400">&#39;relu&#39;</span>)<br />	tf.keras.layers.MaxPooling2D((<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>)) <span style="color:#0088ff;font-weight:400"># Pooling</span><br />	<span style="color:#0088ff;font-weight:400"># Flattening the input</span><br />	tf.keras.layers.Flatten(),<br />	<span style="color:#0088ff;font-weight:400"># Fully connected layers</span><br />	tf.keras.layers.Dense(<span style="color:#ff0044;font-weight:400">128</span>, activation=<span style="color:#3ad900;font-weight:400">&#39;relu&#39;</span>),<br />	tf.keras.layers.Dense(<span style="color:#ff0044;font-weight:400">256</span>, activation=<span style="color:#3ad900;font-weight:400">&#39;relu&#39;</span>),<br />	tf.keras.layers.Dense(<span style="color:#ff0044;font-weight:400">10</span>, activation=<span style="color:#3ad900;font-weight:400">&#39;softmax&#39;</span>)<br />])<br /><br /><span style="color:#0088ff;font-weight:400"># Compiling the model</span><br />model.compile(optimizer=<span style="color:#3ad900;font-weight:400">&#39;adam&#39;</span>,<br />			loss=tf.keras.losses.SparseCategoricalCrossentropy(<br />				from_logits=<span style="color:#ff0044;font-weight:400">True</span>),<br />			metrics=[<span style="color:#3ad900;font-weight:400">&#39;accuracy&#39;</span>])<br /><br /><span style="color:#0088ff;font-weight:400"># FItting the data to a model</span><br />history = model.fit(train_images, train_labels, epochs=<span style="color:#ff0044;font-weight:400">10</span>,<br />					validation_data=(test_images, test_labels))<br /></pre></div> </p><p></p><p></p><p></p><p></p><p><strong>Output:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20211129095907/Untitled1-660x301.png"><img src="images/145-5.png" alt="images/145-5.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Introduction to CNN</h1><br/><p><h2>Introduction to Convolution Neural Network</h2><ol><li>ore diving into the Convolution Neural Network, let us first revisit some concepts of Neural Network. In a regular Neural Network there are three types of layers:</p><p> </p><p>1. <strong>Input Layers:</strong></li><li>’s the layer in which we give input to our model. The number of neurons in this layer is equal to the total number of features in our data (number of pixels in the case of an image).</p><p>2. <strong>Hidden Layer:</strong></li></ol> The input from the Input layer is then feed into the hidden layer.</p><p>  There can be many hidden layers depending upon our model and data size. <ol><li>h hidden layer can have different numbers of neurons which are generally greater than the number of features. </p><p>The output from each layer is computed by matrix multiplication of output of the previous layer with learnable weights of that layer and then by the addition of learnable biases followed by activation function which makes the network nonlinear.</p><p>3. <strong>Output Layer:</strong></li></ol> The output from the hidden layer is then fed into a logistic function like sigmoid or softmax which converts the output of each class into the probability score of each class.</p><p></p><p>The data is then fed into the model and output from each layer is obtained this step is called feedforward, we then calculate the error using an error function, </p><p>some common error functions are cross-entropy, square loss error, etc.</p><p> After that, we backpropagate into the model by calculating the derivatives. </p><p> This step is called Backpropagation which basically is used to minimize the loss.</p><p> </p><p><strong>Convolution Neural Network</strong></p><p>Convolution Neural Networks or covnets are neural networks that share their parameters. Imagine you have an image. It can be represented as a cuboid having its length, width (dimension of the image), and height (as images generally have red, green, and blue channels). </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/cnn-2-300x133.jpg"><img src="images/141-1.png" alt="images/141-1.png" /></a></p><p>Now imagine taking a small patch of this image and running a small neural network on it, with say, k outputs and represent them vertically.</p><p> Now slide that neural network across the whole image, as a result, we will get another image with different width, height, and depth. Instead of just R, G, and B channels now we have more channels but lesser width and height. This operation is called Convolution. </p><p> If the patch size is the same as that of the image it will be a regular neural network. Because of this small patch, we have fewer weights. </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-08-15-13-55-59-300x217.png"><img src="images/141-2.png" alt="images/141-2.png" /></a><em>Image source: Deep Learning Udacity</em><ul><li>w let’s talk about a bit of mathematics that is involved in the whole convolution process. </p><p> </p><p>• Convolution layers consist of a set of learnable filters (a patch in the above image). Every filter has small width and height and the same depth as that of input volume (3 if the input layer is image input).</li><li>For example, if we have to run convolution on an image with dimension 34x34x3. The possible size of filters can be axax3, where ‘a’ can be 3, 5, 7, etc but small as compared to image dimension.</li><li>During forward pass, we slide each filter across the whole input volume step by step where each step is called stride (which can have value 2 or 3 or even 4 for high dimensional images) and compute the dot product between the weights of filters and patch from input volume.</li><li>As we slide our filters we’ll get a 2-D output for each filter and we’ll stack them together and as a result, we’ll get output volume having a depth equal to the number of filters. The network will learn all the filters.</li></ul></p><p></p><p> </p><p><strong>Layers used to build ConvNets</strong></p><p>A covnets is a sequence of layers, and every layer transforms one volume to another through a differentiable function. </p><p><strong>Types of layers:</strong><ol><li>et’s take an example by running a covnets on of image of dimension 32 x 32 x 3. </p><p> </p><p>1. <strong>Input Layer:</strong></li><li>is layer holds the raw input of the image with width 32, height 32, and depth 3.</p><p>2. <strong>Convolution Layer:</strong></li><li>is layer computes the output volume by computing the dot product between all filters and image patches. Suppose we use a total of 12 filters for this layer we’ll get output volume of dimension 32 x 32 x 12.</p><p>3. <strong>Activation Function Layer:</strong></li><li>is layer will apply an element-wise activation function to the output of the convolution layer. Some common activation functions are RELU: max(0, x), Sigmoid: 1/(1+e^-x), Tanh, Leaky RELU, etc. The volume remains unchanged hence output volume will have dimension 32 x 32 x 12.</p><p>4. <strong>Pool Layer:</strong> This layer is periodically inserted in the covnets and its main function is to reduce the size of volume which makes the computation fast reduces memory and also prevents overfitting. Two common types of pooling layers are <strong>max pooling</strong> and <strong>average pooling</strong></li></ol>. If we use a max pool with 2 x 2 filters and stride 2, the resultant volume will be of dimension 16x16x12. </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-08-15-17-04-02.png"><img src="images/141-3.png" alt="images/141-3.png" /></a><em>Image source: cs231n.stanford.edu</em><ol><li><strong>Fully-Connected Layer:</strong></li></ol> This layer is a regular neural network layer that takes input from the previous layer and computes the class scores and outputs the 1-D array of size equal to the number of classes. </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2017-08-15-17-22-40.png"><img src="images/141-4.png" alt="images/141-4.png" /></a><em>Image source: cs231n.stanford.edu</em><ol><li> </li></ol></p><p>References: <a href="http://cs231n.stanford.edu/">Stanford Convolution Neural Network Course (CS231n)</a></p><p></p></div><div class='page'><h1 class='title level-3'>Introduction to Padding</h1><br/><p><h2>CNN | Introduction to Padding</h2><h2></h2></p><p><h2></h2></p><p><strong><h4>Problem with Simple Convolution Layers</h4></strong><ul><li>For a gray scale (n x n) image and (f x f) filter/kernel, the dimensions of the image resulting from a convolution operation is <strong>(n – f + 1) x (n – f + 1)</strong></li></ul>. </p><p>For example, for an (8 x 8) image and (3 x 3) filter, the output resulting after convolution operation would be of size (6 x 6). Thus, the image shrinks every time a convolution operation is performed. This places an upper limit to the number of times such an operation could be performed before the image reduces to nothing thereby precluding us from building deeper networks.<ul><li>Also, the pixels on the corners and the edges are used much less than those in the middle. </li></ul></p><p>For example, </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190721011218/Screenshot-2019-07-16-at-1.35.20-AM.png"><img src="images/146-1.png" alt="images/146-1.png" /></a><ul><li>Clearly, pixel A is touched in just one convolution operation and pixel B is touched in 3 convolution operations, while pixel C is touched in 9 convolution operations. In general, pixels in the middle are used more often than pixels on corners and edges. Consequently, the information on the borders of images is not preserved as well as the information in the middle.</li></ul></p><p></p><p></p><p><strong><h4>Padding Input Images</h4></strong></p><p>Padding is simply a process of adding layers of zeros to our input images so as to avoid the problems mentioned above. </p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190721014439/Screenshot-2019-07-21-at-1.43.59-AM.png"><img src="images/146-2.png" alt="images/146-2.png" /></a><ul><li>This prevents shrinking as, if p = number of layers of zeros added to the border of the image, then our (n x n) image becomes <strong>(n + 2p) x (n + 2p)</strong> image after padding. So, applying convolution-operation (with (f x f) filter) <strong>outputs (n + 2p – f + 1) x (n + 2p – f + 1)</strong></li><li>mages. For example, adding one layer of padding to an (8 x 8) image and using a (3 x 3) filter we would get an (8 x 8) output after performing convolution operation.</p><p>◇ This increases the contribution of the pixels at the border of the original image by bringing them into the middle of the padded image. Thus, information on the borders is preserved as well as the information in the middle of the image.1. <strong>Valid Padding: </strong></li></ul>It implies no padding at all. The input image is left in its valid/unaltered shape. </p><p>So, </p><p></p><p></p><p> </p><p><em><strong>[(n x n) image] * [(f x f) filter] —&gt; [(n – f + 1) x (n – f + 1) image]</strong></em><ol><li> </li></ol></p><p>where * represents a convolution operation.<ol><li><strong>Same Padding: </strong></li></ol>In this case, we add ‘p’ padding layers such that the output image has the same dimensions as the input image. </p><p>So, </p><p> </p><p><em><strong>[(n + 2p) x (n + 2p) image] * [(f x f) filter] —&gt; [(n x n) image]</strong></em><ol><li> </li></ol></p><p>which gives <strong>p = (f – 1) / 2</strong> (because n + 2p – f + 1 = n). </p><p>So, if we use a (the 3 x 3) filter the 1 layer of zeros must be added to the borders for the same padding. Similarly, if (5 x 5) filter is used 2 layers of zeros must be appended to the border of the image.</p><p></p></div><div class='page'><h1 class='title level-3'>Introduction to Pooling layer</h1><br/><p><h2>CNN | Introduction to Pooling Layer</h2></p><p>The pooling operation involves sliding a two-dimensional filter over each channel of feature map and summarising the features lying within the region covered by the filter. </p><p>For a feature map having dimensions <strong>n</strong><strong><sub>h</sub></strong><strong> x n</strong><strong><sub>w</sub></strong><strong> x n</strong><strong><sub>c</sub></strong>, the dimensions of output obtained after a pooling layer is </p><p> </p><p><strong>(n</strong><strong><sub>h - f + 1) / s x (nw - f + 1)/s x nc</sub></strong>where, </p><p>-&gt; <strong>n</strong><strong><sub>h -</sub></strong> height of feature map</p><p>-&gt; <strong>n</strong><strong><sub>w -</sub></strong> width of feature map</p><p>-&gt; <strong>n</strong><strong><sub>c -</sub></strong> number of channels in the feature map</p><p>-&gt; <strong>f  -</strong> size of filter</p><p>-&gt; <strong>s  -</strong> stride lengthA common CNN model architecture is to have a number of convolution and pooling layers stacked one after the other. </p><p></p><p><strong><h4>Why to use Pooling Layers?</h4></strong><ul><li>Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network.</li><li>The pooling layer summarises the features present in a region of the feature map generated by a convolution layer. So, further operations are performed on summarised features instead of precisely positioned features generated by the convolution layer. This makes the model more robust to variations in the position of the features in the input image. </li></ul></p><p> </p><p></p><p></p><p><strong><h4>Types of Pooling Layers:</h4></strong><h4></h4></p><p><h4> </h4></p><p><h4></h4><strong><h4>Max Pooling</h4></strong><ol><li>Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map. </li></ol></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png"><img src="images/147-1.png" alt="images/147-1.png" /></a><ol><li>This can be achieved using MaxPooling2D layer in keras as follows:</li></ol></p><p><strong>Code #1 : Performing Max Pooling using keras</strong> </p><p></p><p><div class="codebox"><pre>import numpy as np<br />from keras.models import Sequential<br />from keras.layers import MaxPooling2D <br /> # define input image<br />image = np.array([[2, 2, 7, 3],<br />                  [9, 4, 6, 1],<br />                  [8, 5, 2, 4],<br />                  [3, 1, 2, 6]])<br />image = image.reshape(1, 4, 4, 1)  # define model containing just a single max pooling <br />layermodel = Sequential(    [MaxPooling2D(pool_size = 2, strides = 2)])<br />  # generate pooled outputoutput = model.predict(image)<br />  # print output image<br />output = np.squeeze(output)print(output)</pre></div><ol><li><strong>Output: </strong></li></ol></p><p>[[9. 7.]</p><p>[8. 6.]]</p><p><strong><h3>Average Pooling</h3></strong><ol><li>Average pooling computes the average of the elements present in the region of feature map covered by the filter. Thus, while max pooling gives the most prominent feature in a particular patch of the feature map, average pooling gives the average of features present in a patch. </li></ol></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190721030705/Screenshot-2019-07-21-at-3.05.56-AM.png"><img src="images/147-2.png" alt="images/147-2.png" /></a><ol><li><strong>Code #2 : Performing Average Pooling using keras</strong></li><li>◇ Python3</li></ol></p><p></p><p> </p><p> </p><p> </p><p></p><p></p><p></p><p></p><p><div class="codebox"><pre>import numpy as npfrom keras.models import Sequentialfrom keras.layers import AveragePooling2D  # define input imageimage = np.array([[2, 2, 7, 3],                  [9, 4, 6, 1],                  [8, 5, 2, 4],                  [3, 1, 2, 6]])image = image.reshape(1, 4, 4, 1)  # define model containing just a single average pooling layermodel = Sequential(    [AveragePooling2D(pool_size = 2, strides = 2)])  # generate pooled outputoutput = model.predict(image)  # print output imageoutput = np.squeeze(output)print(output)</pre></div><ol><li><strong>Output: </strong></li></ol></p><p> </p><p>[[4.25 4.25]</p><p>[4.25 3.5 ]]</p><p><strong><h3>Global Pooling</h3></strong><ol><li>Global pooling reduces each channel in the feature map to a single value. Thus, an <strong>n</strong><strong><sub>h</sub></strong><strong> x n</strong><strong><sub>w</sub></strong><strong> x n</strong><strong><sub>c</sub></strong> feature map is reduced to <strong>1 x 1 x n</strong><strong><sub>c</sub></strong> feature map. This is equivalent to using a filter of dimensions <strong>n</strong><strong><sub>h</sub></strong><strong> x n</strong><strong><sub>w</sub></strong></li></ol> i.e. the dimensions of the feature map. </p><p>Further, it can be either global max pooling or global average pooling.</p><p><strong>Code #3 : Performing Global Pooling using keras</strong> </p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">keras.models</span> <span style="color:#333333;font-weight:400">import</span> Sequential<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">keras.layers</span> <span style="color:#333333;font-weight:400">import</span> GlobalMaxPooling2D<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">keras.layers</span> <span style="color:#333333;font-weight:400">import</span> GlobalAveragePooling2D  <br /><span style="color:#0088ff;font-weight:400"># define input image</span><br />image = np.array([[<span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">7</span>, <span style="color:#ff0044;font-weight:400">3</span>],<br />                  [<span style="color:#ff0044;font-weight:400">9</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">6</span>, <span style="color:#ff0044;font-weight:400">1</span>],<br />                  [<span style="color:#ff0044;font-weight:400">8</span>, <span style="color:#ff0044;font-weight:400">5</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">4</span>],<br />                  [<span style="color:#ff0044;font-weight:400">3</span>, <span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">2</span>, <span style="color:#ff0044;font-weight:400">6</span>]])<br />image = image.reshape(<span style="color:#ff0044;font-weight:400">1</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">4</span>, <span style="color:#ff0044;font-weight:400">1</span>)  <br /><span style="color:#0088ff;font-weight:400"># define gm_model containing just a single global-max pooling layer</span><br />gm_model = Sequential(    [GlobalMaxPooling2D()])  <br /><span style="color:#0088ff;font-weight:400"># define ga_model containing just a single global-average pooling layer</span><br />ga_model = Sequential(    [GlobalAveragePooling2D()]) <br /> <span style="color:#0088ff;font-weight:400"># generate pooled output</span><br />gm_output = gm_model.predict(image)<br />ga_output = ga_model.predict(image)  <br /><span style="color:#0088ff;font-weight:400"># print output image</span><br />gm_output = np.squeeze(gm_output)<br />ga_output = np.squeeze(ga_output)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;gm_output: &quot;</span>, gm_output)<br /><span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;ga_output: &quot;</span>, ga_output)</pre></div><ol><li><strong>Output: </strong></li></ol></p><p> </p><p>gm_output:  9.0</p><p>ga_output:  4.0625 </p></div><div class='page'><h1 class='title level-2'>Multilayer Perceptron</h1><br/><p><small>Need for Multilayer Perceptron</small></p><p> Before starting with a multilayer perceptron, the architecture and working of a single perceptron often referred to as a neuron must be clear to you. A single perceptron model just takes the input(x) , applies the weight(w) and adds the bias(b) then this equation z = wx + b is given to the activation function in-order to produce an output. </p><p>Need of Multilayer Perceptron</p><p>Single layer perceptron is quite useful when we have linearly separable data example,</p><p><a href="https://lh4.googleusercontent.com/Vyz3tVUW7Tomshdz_0DClndddPBCSSAiz06smWmQ9gc6peai9Y-9lQM27YwD8HYngeIRy4mBjg23BTQAS8YFV0YQ4zF1Hvh4X7AKf1BU70r_8_OAMgAqs1YoL_Oep1wYCiYatjMZyfYxeML8H8Bq1nPQ6nKm3WcOAKiIjBrx8ZKInV8s5NW3eoNAKqifq4sdIb9dddSTDQ"><img src="images/148-1.png" alt="images/148-1.png" /></a></p><p>This data can be separated using the red line, </p><p>Let’s take another example of an AND table, The truth table for AND looks like this</p><p><a href="https://lh5.googleusercontent.com/AyLQHTjyIdJofuCPzbAM_Qvo3UoFEokAf4Vx5m_ERjb_eOzE2-rYhWCGJBA_w5xqqE429fZLe9qjEj-fk8P3N4eB0kyOsNSOD6AAtRmbQHRrIsaKB-hLo1cPkRV648M7Mn80wAzP58KJZzIb8fa-xb4erWazFnxiPGBSMy5H1qip75cvHrPdt_sxSopjQ6oR6FBl7eItRw"><img src="images/148-2.png" alt="images/148-2.png" /></a></p><p>Such type of data is simple and a linear hypothesis can be performed on such type of data so a single perceptron can easily do it</p><p><a href="https://lh4.googleusercontent.com/svdNHoWehxb8_qaa6u3fKxZfLYZYgzDjFTfF-iDZBhBO7XM7T8bZk_Zoxw5rlmtBXfjMcPxwtLe_noWZLhEwJoJ3hKT_qDWg-kv7Epe9D_ITLIFYrJ4uuBaBJXnyNiAA_gbKXQNJFUrTNQNtvG-RO-Hq4yd89B-P4WBaV9pSa7q5EUoO3CKmGCJO2ncPM5-kzwL3vmwBvQ"><img src="images/148-3.png" alt="images/148-3.png" /></a></p><p>Similarly, OR Table is linearly separable and can be resolved using a single perceptron.</p><p>But when it comes to complex functions like XOR these can’t be resolved using a simple single perceptron. Truth Table for XOR is: </p><p><a href="https://lh6.googleusercontent.com/8O3F5B7WGP18DmuuoTShXn9Zrp6YZlPU9lOi10_Xhp6Rp0Ww8vOX3iJBk87w5JXn-EJfPod7EnmMIdlabk4e3TIxVlhbHb8hJg1my6CMIDbv3sV9KoHS4kxQHaYanHu0J4ZngFaeeBKdfgo8uWsJ-UgtIfKLb6YShCJbqWD2nAJiBw7Ie4Rk3ah9mseNK5isf2HH-yUVWw"><img src="images/148-4.png" alt="images/148-4.png" /></a></p><p>A linear Hypothesis for such functions isn’t possible but if we do a combination of </p><p>[!AND] AND [OR] we will get a XOR</p><p><a href="https://lh6.googleusercontent.com/gCoDdUCGdswn3Qj6JTnH35SJK3XZSmGtb_zl1eJNYexxdwvT2jfHswk074IWlrzFkYHV9u69mv8-5L58e2Id_fvzxZBMW7jcjP4AnVpuUFe_bINr9uOksBTZUUSKd4wCjB3eJiLObsMoMp4Qnl5XL7Uj7hboYK_exJZ8YSOP3WK8buKA9AxxIEXRk5QIkBh0rTYh6OSlfg"><img src="images/148-5.png" alt="images/148-5.png" /></a></p><p></p><p> </p><p>Now you must be thinking what this has to do with Multilayer Perceptrons. All these simple operations can be performed using a single perceptron like [!AND] AND [OR]. When these values are combined in a single architecture, they form a multilayer perceptron model and can be used to perform complex functions like XOR</p><p><a href="https://lh5.googleusercontent.com/qjthajcsBC9yKvpK4hAZon-XQcq-Bb0UBdgsSMhZyumTmrO0kdIcbo2OPtZRkeVP2GxLgEuYMXVpPyJEZf2sbEYYWiC8QboWCXLk1dhXFwgeXWh4lYtRLEuesokgHT-5a53bYsXATWTEpy3ueJaKf-JAknq5ScV3eOQwMlv4xnkN9olYpsHw8PkQDF8sOtYxE8sQSRUN0g"><img src="images/148-6.png" alt="images/148-6.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Architecture of Multilayer Perceptron</h1><br/><p><small>Architecture of Multilayer Perceptron</small></p><p><h3>When studying about the architecture of a single perceptron or neuron we came to know that it consisted of Input the input was passed on to the perceptron and it would produce an output based on the activation function. </h3></p><p><h3>For Multilayer Perceptrons we’ve 3 main layers </h3><ul><li>Input Layer</li><li>Hidden Layer (More than 1 can be present)</li><li>Output Layer</li></ul></p><p></p><p><a href="https://lh4.googleusercontent.com/pvT9BlhHyQVd32E_Wznxlxk6lDex9I3gBGMI0VmYod_0HIz7yujRX-Bh40umoFbZW6R5dEfttilpfqOPCtvFeTNRpZz0fjeVXlIzYc_U9uf6GI1AKjgSt7cmCQvdgmQHg1FOkLYYqOmPgC1qFV-tMjuWEhzcnq3F0NtweIg6WLqrHdNoFWm0eqEmCm61CuJEdiEjBG1iDA"><img src="images/149-1.png" alt="images/149-1.png" /></a></p><p><h3>It is a 3-layer neural network, while defining the architecture of the neural network we don’t consider the input layer only hidden and the output layer is considered. Input Layer will take features e.g., x1 and output layer would produce output y_hat.</h3></p><p><h3>For better understanding let’s consider the input layer is taking input x1. This input x1 will be passed to all the neurons in the 1</h3><sup>st</sup><h3> hidden layer along with the suitable weight and the bias term. Then that neuron would produce some value with the help of the input, weight and the bias term using the activation function and the it would pass it to the neuron in the next hidden layer with some weight and bias, this would continue until the output is produced </h3></p><p><h3>In our data we will be dealing with 2 components</h3></p><p><h3>‘M’  denotes the number of instances in our data or we can say the number of rows present in our data.</h3></p><p><h3>‘N’ denotes the number of input features in our data or the number of columns present in our data.</h3></p><p><a href="https://lh6.googleusercontent.com/i1aRXYcRwxdp6DDcWiuxaycers7D-c5dAVQrQsErgBM6f9pBEaNzCLz_9dxgqdOBrTIu4yLbgc52vszNBqjg3dhkiuIBMnnuFGu8V7rTGIOZgN-Tb_nPdJ7LTh4W0r9-iu-maeMojWcLjZo_GFqkHs6JR59F-mgfU5wY-6cWb0BRInUZuxuCzaC7tbhtuZmVn3hdW0SkIA"><img src="images/149-2.png" alt="images/149-2.png" /></a></p><p><h3></h3></p><p><h3> </h3></p><p><h3>In this way data is represented X1a represents feature a of row 1 similarly feature a of row 2 and 3 and feature b of row 1 2 and 3 are represented in a more general way we can represent it as </h3></p><p><a href="https://lh5.googleusercontent.com/rMdSznV05AP2VCNY7Wu-AshCjBRJeLSDp43-8hNTnQ8GPtNZCZPIMbNTTnVyqpnJ55vxXRmalGAT-7ImgFJRByzAzFiB39Nrvlctg_8ERie93le62HxH5OgnGXQ6Mb_mxeqFLKslKWOx0LyPlOnCiuPt96MT9FWRCrOcKWCLAkfGT9Irxv3vG2Rhk7g1XzecMwp85qgsyQ"><img src="images/149-3.png" alt="images/149-3.png" /></a></p><p><h3>This is a MxN Matrix. But for the sake of calculations in the neural network we will transpose this matrix to a NxM Matrix.</h3></p><p><a href="https://lh6.googleusercontent.com/HyRx4rI_vAfTHG2z7jKTCKUWYu-0LpK_Zsa8jXRORsqHuNjnAU8KeAy6IbWU6hPhhmGpP8xsKJDP5v8un9AwigOs2AOr40wrnM9-8jYARxxJt-A3mTaDHjPiKgETOFzLXNyOsAUW8ldEIBfZEdM7LYqROZmePLt0Pz5uJKY6XCM1LO4tAeC5k09QNFHDZ4yGpLiD2u2QcQ"><img src="images/149-4.png" alt="images/149-4.png" /></a></p><p><h3></h3></p><p><h3> </h3></p><p><h3>Now that was all for how Input features and examples are represented in the form of Matrix but we also have weights and bias to be passed for computations in each Neuron. First let’s start with the weights. To understand this, we would take an example of a 2-Layer Neural Network having 2 input features X1 and X2 </h3></p><p><a href="https://lh4.googleusercontent.com/pIT8LU0F6ywmorzTXFb7_gjVe1x3Gwn4ZVfDM9bb2wM8nCRKp2oP60diD-oC0TJdPfquOBF0qrNBz0aMFrJkJRrrT-TPtIPtPm6cBiBpd_oc8ZITfUmfm3yWI2h0aQUlxskWYvJXlhiR8IRrkp6kRDOA0BJQIN9FN5_B6WlWyTEXxfJjDanVEw6KqJTk9cNVVH9x8kyNZw"><img src="images/149-5.png" alt="images/149-5.png" /></a></p><p><h3>Here we have 3 weights for each feature has 3 neurons are present in the hidden layer.</h3></p><p><h3>As the number of neurons present in the Hidden layer = 3 and input features = 2. We would end up with 2 weights for each neuron in the hidden layer leading us to a 3x2 Matrix of weights, it can be shown as </h3></p><p><a href="https://lh3.googleusercontent.com/kzRepLumvQt0JnyXw17yDglNNyyIDuIEsw3Xb-voQpb2hntx0DR2cTqgxC97bY3Zt6lQ6-xjCde0qxq0QwJlgxda16y3wtKYViqKl7EKDhoBtCoxt1LQTnlqdcavNQ6u_0-PtWlRIvQgGffI3UtrBhCxr6goK6Cy9sWj4_hZDqPp4_YDTNj0Dd10zPO8ghUiMt3naWlK3A"><img src="images/149-6.png" alt="images/149-6.png" /></a></p><p><h3>The first row i.e., W11 and W21 represents weights passed to 1</h3><sup>st</sup><h3> Neuron in the hidden layer, similarly W12 and W22 are weights passed on to the 2</h3><sup>nd</sup><h3> Neuron and so on it goes. </h3></p><p><h3>For a more general perspective we can write it in its Vectorized format</h3></p><p><a href="https://lh3.googleusercontent.com/thtCmIySl3cxLBOdo1Kis4-bPHEc4Y8KcOfFt41HbAomDEyAUan-NTWYFhWUsEKV1bRSbsYOmutWCSe-t6mg_uDsoUz9XDKMZSjtARzRWa2gMNXedwpvAaxsE9gtsZ9uwn1iPZ2WKpfYoGBp5_rzHrtXu7MxDptjurA6_u_5XzKc_m3HgPD7fnN2QULELaBYWLWNRBDzzA"><img src="images/149-7.png" alt="images/149-7.png" /></a></p><p><h3>Similarly Bias terms are passed in vectorized formats.</h3></p><p><h3></h3></p><p><h3></h3></p><p><h3> </h3></p><p><h3>Now the last thing is to note that there exists a specific notation which helps in distinguishing whether the weight is from the input layer to 1</h3><sup>st</sup><h3> hidden layer or 1</h3><sup>st</sup><h3> to 2</h3><sup>nd</sup><h3> hidden layer or hidden layer to output layer. To overcome this problem of similarity and to avoid confusion we define a notation as </h3></p><p><a href="https://lh4.googleusercontent.com/ayKrwADV_sMxqFMRZaLYFhJp0auR1MVXG_8GuwoTz2WFrI9Ti5pdo8NwGm7aU8q9suxGOavv77O0xii2B5vGE7oP4tuWuBAY-FJdc6-jHc3LCW1i7X3d2NR1UZ6Hj7wim2O3_eSN3dPghSCUL_WJMzpXc2KdlqpusdGP4FSTljEDnja95cSiTKHVMzG-gDZW16w3OJVCcA"><img src="images/149-8.png" alt="images/149-8.png" /></a></p><p><h3>[L]: represents the Layer</h3></p><p><h3>[i]: represents the node in that layer</h3></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Forward, Backward Propagation and Final Equation for MLP</h1><br/><p><small>Forward, Backward propagation and Final equation for MLP</small></p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">Forward propagation </span></strong></em></p><p>Forward Propagation: In forward propagation the flow of data is understood to be from left to right(input to hidden layers to output) </p><p><a href="https://lh5.googleusercontent.com/5PYVF_EElfEPKy1kNZ2xTB5YUA7CZswcCAByb-lDXjHiMSsT8YmhqPbDUDzwQrWKocV6w7XbBzxr83oZcbc2etvQ7lzcb2lsr7UkhCWYEELgwru6HYyTZjZoANr49RmSjbdMMSa4z6TbE1Q6hqnxCU2BTD0XPKyIXt07hyWPJ0BE2XY_w7XTjiSJq23EpSJTCpWgEj72IQ"><img src="images/150-1.png" alt="images/150-1.png" /></a></p><p><strong>h11 = (w11 x X ) + b11</strong></p><p><strong>h12 = (w12 x X) + b12</strong></p><p><strong>h13 = (w13 x X) + b13</strong></p><p></p><p> </p><p>Now for a neuron to compute the input we know that an activation function is applied to it, considering sigmoid activation here:</p><p><strong> a11 = sigmoid(h11)</strong></p><p><strong>a12 = sigmoid(h12)</strong></p><p><strong>a13 = sigmoid(h13)</strong></p><p></p><p> </p><p>If we take a bit more complex neural network with 2 input features, we would have h21 h22 h23 and a21, a22, a23 as well. For all these values we would be having corresponding weights and bias terms. </p><p>For output we’ll be having a matrix only having the dimension of </p><p>number of neurons in hidden layer x neurons in output layer.</p><p>In our case that would be (3,1) Matrix and the elements would be h11,h12 and h13. This would be our h1 it could be depicted as: </p><p><a href="https://lh6.googleusercontent.com/508rqT3a0vgjxiREEIlQ0vtpxja2jihvetbAqd5CKlNSG8cfjh2g4h1MATGSewELhyecbNgCCceZjb_n8Pfn9QUaCBmEc0D_7bqW7ghPBPlgrT_bsirT7CnXyjKQ8Y4D_RSS7R2Qsz6E8UivcE6iJzQM5pHzZ6EQVcHUZ8KCrTrKBOCiR2sn_v3Ics0_fBprLz9QAkq68Q"><img src="images/150-2.png" alt="images/150-2.png" /></a></p><p>This matrix is equal to (W[1] x X) + b[1] ) or matrix of weights multiply with features matrix plus matrix of bias terms</p><p><a href="https://lh4.googleusercontent.com/fooB3mbcN5wkIykIWj-Fr69zqPE4FWZYDBf6UaCRvhH_kDmfZ6Tw7AJQsnzrJibw7jZCrLPJ_UQBmy7NM7aegmdIPVL_2hhVgSfyaxUT1G8LreUDk6PapENk606XOATFwpJJQfYG-8tgNCzYuloHsWFYl-K-LhZH9WFDZC-CnnuXe9xrle-E6uhCUPObSbYRCHpD1tl1VA"><img src="images/150-3.png" alt="images/150-3.png" /></a></p><p>Further it can be written as</p><p><a href="https://lh3.googleusercontent.com/Ll1gz56Zfams0xYr-P8z2WjIOW93VKGLHTiJMly8na6Njm9E6Q-EqTTnANpw_QMbYQneyO0CLibCfQXrVS3Ydx1r9hTq0LUJJH9LTJ8Z71THS4lDRxC2jKjMazRGVwTvTCV9U9Y0P7L_HpxFvH3Al25Oa5yQMVTcj8xw4er6TCywPiZx7j0HIa2zm3KAy_Fkfh8aqZ8jBQ"><img src="images/150-4.png" alt="images/150-4.png" /></a></p><p>This will give rise to a 3x1 matrix.</p><p>Now the values passed by the input layer to the first hidden layer will be equal to</p><p><strong>a1 = sigmoid(h1)</strong></p><p>Now the values from hidden layer will be passed to the output layer so for this activation function would take a1 as input and weight w2 would be applied to produce an output. </p><p><strong>h2 = (w2 * a1) + b2</strong></p><p>Final y predicted or <strong>Y_hat = sigmoid(h2)</strong></p><p>In this way forward propagation works</p><p></p><p> </p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">Backward propagation</span></strong></em></p><p>When we start to learn about neural networks, we came to know about a concept known as <span style="text-decoration:underline;">cost, </span></p><p>Every time we design a model our goal is to minimize the cost. In back propagation what happens is that after we find an output using forward propagation, we get the cost after obtaining the result we try to minimize the cost by adjusting the weights that were allocated randomly in the first iteration. Thus, backward propagation basically means to re-adjust the randomly assigned weights so that the cost could be reduced and accuracy increased. </p><p>Backward propagation can be achieved using gradient descent. Gradient descent can be written as </p><p><a href="https://lh4.googleusercontent.com/pjR0zidCNEZCx8hMe0n_mHU7Os5ymiLWxSTB5J5RWtGWZkK-4yIxVQvrVdHXK1-ph2cb-_YXxSaV1oKHgYXDoPHdzQWUuNa8TFOm-ugUvOYAVVsuALRZnRXV-hIOzLqVEddug6Wp2mfuUJ3hR6mdkGdInqFNfN7TcP-qjzERbSd1OPhqjZcubvwdqcIa0j1BI75xcufEPQ"><img src="images/150-5.png" alt="images/150-5.png" /></a></p><p>w` is the updated cost and α is the learning rate and J(w) is basically the cost. </p><p></p><p> </p><p><em><span style="color:#4472c4;">  </span></em><em><strong><span style="color:#4472c4;text-decoration:underline;">Final Equation for Multilayer perceptron</span></strong></em></p><p><a href="https://lh6.googleusercontent.com/mtCqllGAzFnJSWGQZ8vSZ-0nX994WhvkMlofpgi82ByNzYK6weeLALpyN6XK7JSZTs3656Oy57mbSyQcQ5WP6wo0LN_KvQdWQBuz8II6BwZejUXayjJCO3mV6fxvzQRQerv-c27qzhlMpKNqBGZzJG19EKgOjGAangGjlZjs5-HDCjFZiqKTZLT5XyOd-enlO7oL5ybJRw"><img src="images/150-6.png" alt="images/150-6.png" /></a></p><p></p><p> </p><p><strong>Equation obtained in Forward Propagation</strong></p><p><a href="https://lh5.googleusercontent.com/TNgdsxF30v4XNznyo79Cl53WDfc_KhqtQksFJ8nHJDJI9q6j1Ku6hXUVuNuJbaDFcbD-9TkssC-DYjQ1iS-a4zA3NEa7E6V-fKQT51CC-DFqCUcjRC4Dl3gRbCGKxJuGDI_OFLrQ5mro9mWixF1kSbf2hNK45NHHnOh1M9ndgiZGMlIPggtM-Ou0dvpUhjY2Estc14GBKw"><img src="images/150-7.png" alt="images/150-7.png" /></a></p><p><a href="https://lh5.googleusercontent.com/DxCWSkaNVxNhRxpLFycRrPLsVkCL111RWEsJGcJ8fEpkCt_aO_E5huZLA_wx0rAP4pZMx_6ZPwnU3LsML88rgg9ZdTPIrXvQnt2k_MBA0SbGEJwe6E29p_1d72of0LW7MLfLC-1cmT7NZ6CFudlvck2qDqvov04AsdihKSnToFbr9Gh2E2UKqnqsWUoPOsvfaur34MM-XA"><img src="images/150-8.png" alt="images/150-8.png" /></a></p><p>Here g1 is any activation function sigmoid or ReLu or tanh.</p><p></p><p> </p><p>Data is taken as input, multiplied with some weight w and a bias term is added to it, then an activation function is used to generate an output that is done for all features. Hence all the features are passed through the 1<sup>st</sup> hidden layer and some output is produced.</p><p>Let the output produced = h2, this h2 is then passed to another layer of neurons or in our case to the output layer neuron.</p><p><a href="https://lh5.googleusercontent.com/sKIPI3dPAZsF9q9EdEaZMzlk2zj15zsF9nek4XrHWY7BYzuLeDVv7k1BQsFDbEy89NRPyYDYi79RWLjtEZImiLRTklGX2ygdNbuwYrLCrf29CW_HeFVy9ePOdPQj21URw3Nj7q-WDWP0Z903dgvT-zQ49hAIOlj2MpM3ucbSMbX6AFp_wAIMstWJi-WF7Q1oIU1WdP-olA"><img src="images/150-9.png" alt="images/150-9.png" /></a></p><p>Here A1 is the output from 1<sup>st</sup> layer new weight w2 and bias b2 is passed then the activation function is used to compute A2 that is the output here (Y_hat / y_predicted) </p><p></p><p> </p><p><strong>Equations obtained using Backward Propagation</strong></p><p>In backward propagation we move from right to left so the first term we consider is h2(Output)</p><p><strong>d(h2)  = [d(activation function) * A[2] – y] </strong>      <strong> (predicted – actual  this gives us cost)</strong></p><p>After this we would calculate derivative for our weights d(w2) can be written as:</p><p><a href="https://lh4.googleusercontent.com/IOVy2urMUYdBq1JI4fErV4t-AKBqEIQfBDDLUqKDN-Rv0XeMF5IkAGq7Jp4Pd6i7yx37qPNI7Y-pPoC3MYcKlBgQght0Kc9vIpML7Rs1VmXnzTASSwL6duxhTncFqHEbZGXyG4bXHuCvH5-5vsxFp33bRfwwHbl_IJY8p089rLELcBpFKguVvzhQ32vP2e7Ldb295Zf1sA"><img src="images/150-10.png" alt="images/150-10.png" /></a></p><p>Similarly, db2 i.e., the matrix of bias terms can be written as 1/m np.sum(db1).</p><p><strong>db2  = 1/m * np.sum(db1)</strong></p><p></p><p> </p><p>After this we would perform differentiation of dh1 which is nothing but basically</p><p><strong>dh1 =  (w2 dh2) * (differentiation of our activation function *h1)</strong></p><p></p></div><div class='page'><h1 class='title level-3'>Activation Functions</h1><br/><p><small>Activation Functions</small></p><p>It is recommended to understand <a href="https://www.geeksforgeeks.org/neural-networks-a-beginners-guide/">Neural Networks</a> before reading this article. </p><p>In the process of building a neural network, one of the choices you get to make is what <a href="https://www.geeksforgeeks.org/activation-functions-neural-networks/">Activation Function</a> to use in the hidden layer as well as at the output layer of the network. This article discusses some of the choices.</p><p></p><p><strong><h2>Elements of a Neural Network </h2></strong></p><p><strong>Input Layer:</strong><em><strong> </strong></em>This layer accepts input features. It provides information from the outside world to the network, no computation is performed at this layer, nodes here just pass on the information(features) to the hidden layer. </p><p><strong>Hidden Layer</strong><em><strong>: </strong></em>Nodes of this layer are not exposed to the outer world, they are part of the abstraction provided by any neural network. The hidden layer performs all sorts of computation on the features entered through the input layer and transfers the result to the output layer. </p><p><strong>Output Layer:</strong><em><strong> </strong></em>This layer bring up the information learned by the network to the outer world. </p><p></p><p><strong><h2>What is an activation function and why use them?</h2></strong><h2> </h2></p><p>The activation function decides whether a neuron should be activated or not by calculating the weighted sum and further adding bias to it. The purpose of the activation function is to introduce non-linearity into the output of a neuron. </p><p><strong>Explanation:</strong> We know, the neural network has neurons that work in correspondence with <em>weight, bias,</em> and their respective activation function. In a neural network, we would update the weights and biases of the neurons on the basis of the error at the output. This process is known as <em><strong><a href="https://www.geeksforgeeks.org/backpropagation-in-data-mining/">back-propagation</a></strong></em>. Activation functions make the back-propagation possible since the gradients are supplied along with the error to update the weights and biases. </p><p></p><p><strong><h2>Why do we need Non-linear activation function?</h2></strong></p><p>A neural network without an activation function is essentially just a linear regression model. The activation function does the non-linear transformation to the input making it capable to learn and perform more complex tasks. </p><p></p><p><strong><h3>Mathematical proof </h3></strong></p><p><em>Suppose we have a Neural net like this :-</em> </p><p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Network.png"><img src="images/151-1.png" alt="images/151-1.png" /></a></p><p>Elements of the diagram are as follows:<strong> </strong></p><p><strong>Hidden layer i.e. layer 1:</strong></p><p><em>z(1) = W(1)X + b(1) a(1)</em></p><p><em>Here,</em><ul><li><em>z(1) is the vectorized output of layer 1</em></li><li><em>W(1) be the vectorized weights assigned to neurons of hidden layer i.e. w1, w2, w3 and w4</em></li><li><em>X be the vectorized input features i.e. i1 and i2</em></li><li><em>b is the vectorized bias assigned to neurons in hidden layer i.e. b1 and b2</em></li><li><em>a(1) is the vectorized form of any linear function.</em></li></ul></p><p></p><p><em>(</em><em><strong>Note:</strong></em><em> We are not considering activation function here)</em></p><p><strong>Layer 2 i.e. output layer :-</strong></p><p><em><strong>Note :</strong></em><em> Input for layer 2 is output from layer 1</em></p><p><em>z(2) = W(2)a(1) + b(2)  </em></p><p><em>a(2) = z(2) </em></p><p></p><p><strong><h4>Calculation at Output layer</h4></strong></p><p><em>z(2) = (W(2) * [W(1)X + b(1)]) + b(2)</em></p><p><em>z(2) = [W(2) * W(1)] * X + [W(2)*b(1) + b(2)]</em></p><p><em>Let, </em></p><p><em>    [W(2) * W(1)] = W</em></p><p><em>    [W(2)*b(1) + b(2)] = b</em></p><p><em>Final output : z(2) = W*X + b</em></p><p><em>which is again a linear function</em></p><p>This observation results again in a linear function even after applying a hidden layer, hence we can conclude that, doesn’t matter how many hidden layer we attach in neural net, all layers will behave same way because <em><strong>the composition of two linear function is a linear function itself</strong></em>. Neuron can not learn with just a linear function attached to it. A non-linear activation function will let it learn as per the difference w.r.t error. <strong>Hence we need activation function.</strong> </p><p></p><p><strong><h2>Variants of Activation Function </h2></strong></p><p></p><p><strong><h3>Linear Function </h3></strong><ul><li><strong>Equation : </strong>Linear function has the equation similar to as of a straight line i.e. <strong>y = x</strong></li><li>No matter how many layers we have, if all are linear in nature, the final activation function of last layer is nothing but just a linear function of the input of first layer.</li><li><strong>Range :</strong></li><li>inf to +inf</p><p>◇ <strong>Uses : Linear activation function</strong></li><li>s used at just one place i.e. output layer.</p><p>◇ <strong>Issues : </strong>If we will differentiate linear function to bring non-linearity, result will no more depend on <em>input “x”</em></li></ul> and function will become constant, it won’t introduce any ground-breaking behavior to our algorithm.</p><p></p><p><strong>For example :</strong> Calculation of price of a house is a regression problem. House price may have any big/small value, so we can apply linear activation at output layer. Even in this case neural net must have any non-linear function at hidden layers. </p><p></p><p><strong><h3>Sigmoid Function </h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221013120722/1.png"><img src="images/151-2.png" alt="images/151-2.png" /></a> <ul><li>It is a function which is plotted as <strong>‘S’</strong></li><li>haped graph.</p><p>◇ <strong>Equation : </strong>A = 1/(1 + e<sup>-x</sup></li><li>◇ <strong>Nature :</strong></li><li>on-linear. Notice that X values lies between -2 to 2, Y values are very steep. This means, small changes in x would also bring about large changes in the value of Y.</p><p>◇ <strong>Value Range : </strong></li><li>to 1</p><p>◇ <strong>Uses : </strong>Usually used in output layer of a binary classification, where result is either 0 or 1, as value for sigmoid function lies between 0 and 1 only so, result can be predicted easily to be <em><strong>1</strong></em> if value is greater than <strong>0.5</strong> and <em><strong>0</strong></em></li></ul> otherwise.</p><p></p><p></p><p><strong><h3>Tanh Function </h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190408115639/tanh3.png"><img src="images/151-3.png" alt="images/151-3.png" /></a> <ul><li>The activation that works almost always better than sigmoid function is Tanh function also knows as <strong>Tangent Hyperbolic function</strong></li><li>It’s actually mathematically shifted version of the sigmoid function. Both are similar and can be derived from each other.</p><p>◇ <strong>Equation :-</strong></li></ul></p><p></p><p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2018-01-04-22-01-14-e1515083558457.png"><img src="images/151-4.png" alt="images/151-4.png" /></a> <ul><li><strong>Value Range :- </strong></li><li> to +1</p><p>◇ <strong>Nature :- </strong></li><li>n-linear</p><p>◇ <strong>Uses :- </strong>Usually used in hidden layers of a neural network as it’s values lies between <strong>-1 to 1 </strong>hence the mean for the hidden layer comes out be 0 or very close to it, hence helps in <em>centering the data</em></li></ul> by bringing mean close to 0. This makes learning for the next layer much easier.</p><p></p><p></p><p><strong><h3>RELU Function </h3></strong></p><p><a href="https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Screenshot-from-2018-01-04-22-45-49-e1515086199933.png"><img src="images/151-5.png" alt="images/151-5.png" /></a> <ul><li>It Stands for <em>Rectified linear unit</em>. It is the most widely used activation function. Chiefly implemented in <em>hidden layers</em></li><li>f Neural network.</p><p>◇ <strong>Equation :- </strong><em><strong>A(x) = max(0,x)</strong></em></li><li>It gives an output x if x is positive and 0 otherwise.</p><p>◇ <strong>Value Range :- </strong></li><li>, inf)</p><p>◇ <strong>Nature :- </strong></li><li>n-linear, which means we can easily backpropagate the errors and have multiple layers of neurons being activated by the ReLU function.</p><p>◇ <strong>Uses :- </strong></li></ul>ReLu is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations. At a time only a few neurons are activated making the network sparse making it efficient and easy for computation.</p><p></p><p>In simple words, RELU learns <em>much faster</em> than sigmoid and Tanh function.</p><p></p><p><strong><h3>Softmax Function</h3></strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20190322133046/softmxx.png"><img src="images/151-6.png" alt="images/151-6.png" /></a> <ul><li>e softmax function is also a type of sigmoid function but is handy when we are trying to handle mult- class classification problems.</p><p>◇ <strong>Nature :- </strong></li><li>n-linear</p><p>◇ <strong>Uses :- </strong></li><li>ually used when trying to handle multiple classes. the softmax function was commonly found in the output layer of image classification problems.The softmax function would squeeze the outputs for each class between 0 and 1 and would also divide by the sum of the outputs. </p><p>◇ <strong>Output:- </strong></li><li>e softmax function is ideally used in the output layer of the classifier where we are actually trying to attain the probabilities to define the class of each input.</p><p>◇ The basic rule of thumb is if you really don’t know what activation function to use, then simply use <em>RELU</em></li><li>s it is a general activation function in hidden layers and is used in most cases these days.</p><p>◇ If your output is for binary classification then, <em>sigmoid function</em></li><li>s very natural choice for output layer.</p><p>◇ If your output is for multi-class classification then, Softmax is very useful to predict the probabilities of each classes. </li></ul></p><p></p><p></p></div><div class='page'><h1 class='title level-2'>Perceptrons</h1><br/></div><div class='page'><h1 class='title level-3'>Intro to ANN</h1><br/><p><small>Introduction to Artificial Neutral Networks</small></p><p>ANN learning is robust to errors in the training data and has been successfully applied for learning real-valued, discrete-valued, and vector-valued functions containing problems such as interpreting visual scenes, speech recognition, and learning robot control strategies. The study of artificial neural networks (ANNs) has been inspired in part by the observation that biological learning systems are built of very complex webs of interconnected neurons in brains. The human brain contains a densely interconnected network of approximately 10^11-10^12 neurons, each connected neuron, on average connected, to l0^4-10^5 other neurons. So on average human brain takes approximately 10^-1 to make surprisingly complex decisions. ANN systems are motivated to capture this kind of highly parallel computation based on distributed representations. Generally, ANNs are built out of a densely interconnected set of simple units, where each unit takes a number of real-valued inputs and produces a single real-valued output.</p><p>But ANNs are less motivated by biological neural systems, there are many complexities to biological neural systems that are not modeled by ANNs. Some of them are shown in the figures.</p><p></p><p><h2>Difference between Biological Neurons and Artificial Neurons</h2></p><p><table class="table"><tr><th>Biological Neurons</th><th>Artificial Neurons</th></tr><tr><td>Major components: Axions, Dendrites, Synapse</td><td>Major Components: Nodes, Inputs, Outputs, Weights, Bias</td></tr><tr><td>Information from other neurons, in the form of electrical impulses, enters the dendrites at connection points called synapses. The information flows from the dendrites to the cell where it is processed. The output signal, a train of impulses, is then sent down the axon to the synapse of other neurons.</td><td>The arrangements and connections of the neurons made up the network and have three layers. The first layer is called the input layer and is the only layer exposed to external signals. The input layer transmits signals to the neurons in the next layer, which is called a hidden layer. The hidden layer extracts relevant features or patterns from the received signals. Those features or patterns that are considered important are then directed to the output layer, which is the final layer of the network.</td></tr><tr><td>A synapse is able to increase or decrease the strength of the connection. This is where information is stored.</td><td>The artificial signals can be changed by weights in a manner similar to the physical changes that occur in the synapses.</td></tr><tr><td>Approx 1011 neurons.</td><td>102– 104 neurons with current technology</td></tr></table></p><p></p><p><h2>Difference between the human brain and computers in terms of how information is processed.</h2></p><p><table class="table"><tr><th>Human Brain(Biological Neuron Network)</th><th>Computers(Artificial Neuron Network)</th></tr><tr><td>The human brain works asynchronously</td><td>Computers(ANN) work synchronously.</td></tr><tr><td>Biological Neurons compute slowly (several ms per computation)</td><td>Artificial Neurons compute fast (&lt;1 nanosecond per computation)</td></tr><tr><td>The brain represents information in a distributed way because neurons are unreliable and could die any time.</td><td>In computer programs every bit has to function as intended otherwise these programs would crash.</td></tr><tr><td>Our brain changes their connectivity over time to represents new information and requirements imposed on us.</td><td>The connectivity between the electronic components in a computer never change unless we replace its components.</td></tr><tr><td>Biological neural networks have complicated topologies.</td><td>ANNs are often in a tree structure.</td></tr><tr><td>Researchers are still to find out how the brain actually learns.</td><td>ANNs use Gradient Descent for learning.</td></tr></table></p><p><strong>Advantage of Using Artificial Neural Networks:</strong><ul><li>Problem in ANNs can have instances that are represented by many attribute-value pairs.</li><li>ANNs used for problems having the target function output may be discrete-valued, real-valued, or a vector of several real- or discrete-valued attributes.</li><li>ANN learning methods are quite robust to noise in the training data. The training examples may contain errors, which do not affect the final output.</li><li>It is used generally used where the fast evaluation of the learned target function may be required.</li><li>ANNs can bear long training times depending on factors such as the number of weights in the network, the number of training examples considered, and the settings of various learning algorithm parameters.</li></ul></p><p></p><p><strong>The McCulloch-Pitts Model of Neuron:</strong></p><p>The early model of an artificial neuron is introduced by <strong>Warren McCulloch</strong> and Walter Pitts in 1943. The McCulloch-Pitts neural model is also known as linear threshold gate. It is a neuron of a set of inputs I1, I2,…, Im and one output y. The linear threshold gate simply classifies the set of inputs into two different classes. Thus the output y is binary. Such a function can be described mathematically using these equations:</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a5ecd31bd166f1f27bd94c540cb38510_l3.svg"><img src="images/153-1.png" alt="images/153-1.png" /></a></p><p>W1,W2,W3….Wn are weight values normalized in the range of either (0,1)or (-1,1) and associated with each input line, Sum is the weighted sum, and is a threshold constant. The function f is a linear step function at the threshold</p><p><strong>Single-layer Neural Networks (Perceptrons)</strong></p><p>Input is multi-dimensional (i.e. input can be a vector):</p><p>input x = ( I1, I2, .., In)</p><p>Input nodes (or units) are connected (typically fully) to a node (or multiple nodes) in the next layer. A node in the next layer takes a weighted sum of all its inputs:</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-fc5fabd6aefd310dc13ed0c07e35c66f_l3.svg"><img src="images/153-2.png" alt="images/153-2.png" /></a></p><p><strong>The rule:</strong></p><p>The output node has a “threshold” t.</p><p>Rule: If summed input ? t, then it “fires” (output y = 1). Else (summed input &lt; t) it doesn&#39;t fire (output y = 0).</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-30ccf9a80c41c2b63b58204972ec14e6_l3.svg"><img src="images/153-3.png" alt="images/153-3.png" /></a>which</p><p></p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/booleanfunctions.jpg"><img src="images/153-4.png" alt="images/153-4.png" /></a></p><p><strong>Limitations of Perceptrons:</strong></p><p>(i) The output values of a perceptron can take on only one of two values (0 or 1) due to the hard-limit transfer function.</p><p>(ii) Perceptrons can only classify linearly separable sets of vectors. If a straight line or a plane can be drawn to separate the input vectors into their correct categories, the input vectors are linearly separable. If the vectors are not linearly separable, learning will never reach a point where all vectors are classified properly</p><p>The Boolean function XOR is not linearly separable (Its positive and negative instances cannot be separated by a line or hyperplane). Hence a single layer perceptron can never compute the XOR function. This is a big drawback that once resulted in the stagnation of the field of neural networks. But this has been solved by multi-layer.</p><p><strong>Multi-layer Neural Networks</strong></p><p>A Multi-Layer Perceptron (MLP) or Multi-Layer Neural Network contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi-layer perceptron can also learn non – linear functions.</p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/nodeNeural.jpg"><img src="images/153-5.png" alt="images/153-5.png" /></a></p><p>This neuron takes as input x1,x2,….,x3 (and a +1 bias term), and outputs f(summed inputs+bias), where f(.) called the activation function. The main function of Bias is to provide every node with a trainable constant value (in addition to the normal inputs that the node receives). Every activation function (or non-linearity) takes a single number and performs a certain fixed mathematical operation on it. There are several activation functions you may encounter in practice:</p><p><strong>Sigmoid:</strong>takes real-valued input and squashes it to range between 0 and 1.</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-eb7637f7978fcbae6fc3dd91cd23149d_l3.svg"><img src="images/153-6.png" alt="images/153-6.png" /></a></p><p><strong>tanh:</strong>takes real-valued input and squashes it to the range [-1, 1 ].</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-8b0fc0d6cbf00a386858d3535d576d81_l3.svg"><img src="images/153-7.png" alt="images/153-7.png" /></a></p><p><strong>ReLu:</strong>ReLu stands for Rectified Linear Units. It takes real-valued input and thresholds it to 0 (replaces negative values to 0 ).</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-2426683592c5bde4bd22e639dc600c3f_l3.svg"><img src="images/153-8.png" alt="images/153-8.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Architecture and Learning Process in ANN</h1><br/><p><small>Architecture and Learning process in neural network</small></p><p>In order to learn about Backpropagation<strong>, </strong>we first have to understand the architecture of the neural network and then the learning process in ANN. So, let’s start about knowing the various architectures of the ANN:</p><p></p><p><strong><h4>Architectures of Neural Network: </h4></strong></p><p>ANN is a computational system consisting of many interconnected units called <strong>artificial neurons</strong>. The connection between artificial neurons can transmit a signal from one neuron to another. So, there are multiple possibilities for connecting the neurons based on which the <strong>architecture</strong><ul><li>e are going to adopt for a specific solution. Some permutations and combinations are as follows: </p><p>• There may be just two layers of neuron in the network – the input and output layer.</li><li>There can be one or more intermediate <strong>‘hidden’</strong></li><li>ayers of a neuron.</p><p>• The neurons may be connected with all neurons in the next layer and so on …..</li></ul></p><p></p><p>So let’s start talking about the various possible architectures:</p><p><strong>A. Single-layer Feed Forward Network:</strong></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104105301/first.PNG"><img src="images/154-1.png" alt="images/154-1.png" /></a></p><p></p><p> </p><p>It is the simplest and most basic architecture of ANN’s. It consists of only two layers- the input layer and the output layer. <strong>The input layer</strong> consists of ‘m’ input neurons connected to each of the ‘n’ output neurons. The connections carry weights w<sub>11</sub> and so on. The input layer of the neurons doesn’t conduct any processing – they pass the i/p signals to the o/p neurons. The computations are performed in the output layer. So, though it has 2 layers of neurons, only one layer is performing the computation. This is the reason why <strong>the network is known as SINGLE</strong> layer. Also, the signals always flow from the input layer to the output layer. Hence, the <strong>network is known as FEED FORWARD. </strong></p><p>The net signal input to the output neurons is given by:</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-24479a7e671492f27607a3a1b6ea7639_l3.svg"><img src="images/154-2.png" alt="images/154-2.png" /></a></p><p>The signal output from each output neuron will depend on the activation function used.</p><p><strong>B. Multi-layer Feed Forward Network:</strong></p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104135201/second.jpg"><img src="images/154-3.png" alt="images/154-3.png" /></a><em><strong>Multi-Layer Feed Forward Network</strong></em></p><p></p><p>The multi-layer feed-forward network is quite similar to the single-layer feed-forward network, except for the fact that there are one or more intermediate layers of neurons between the input and output layer. Hence, the <strong>network is termed as multi-layer. </strong>Each of the layers may have a varying number of neurons. For example, the one shown in the above diagram has ‘m’ neurons in the input layer and ‘r’ neurons in the output layer and there is only one hidden layer with ‘n’ neurons. </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-14543a7fd7a9d2e9e4c944ac9364b33a_l3.svg"><img src="images/154-4.png" alt="images/154-4.png" /></a></p><p> </p><p>for the kth hidden layer neuron. The net signal input to the neuron in the output layer is given by:</p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-744a74cb59d4f530e20f97cc85c39649_l3.svg"><img src="images/154-5.png" alt="images/154-5.png" /></a></p><p><strong>C. Competitive Network:</strong></p><p>It is as same as the single-layer feed-forward network in structure. The only difference is that<strong> the output neurons are connected with each other (either partially or fully)</strong>. Below is the diagram for this type of network.</p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104111515/third.PNG"><img src="images/154-6.png" alt="images/154-6.png" /></a><em><strong>Competitive Network</strong></em></p><p></p><p>According to the diagram, it is clear that few of the output neurons are interconnected to each other. For a given input, the output neurons compete against themselves to represent the input. It represents a form of an unsupervised learning algorithm in ANN that is suitable to find the clusters in a data set.</p><p><strong>D. Recurrent Network:</strong></p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104111902/fourth.PNG"><img src="images/154-7.png" alt="images/154-7.png" /></a><em><strong>Recurrent Network</strong></em></p><p></p><p>In feed-forward networks, the signal always flows from the input layer towards the output layer (in one direction only). In the case of recurrent neural networks, there is <strong>a feedback loop</strong> (from the neurons in the output layer to the input layer neurons). There can be self-loops too.</p><p></p><p><strong><h4>Learning Process In ANN:</h4></strong><ol><li>rning process in ANN mainly depends on four factors, they are:</p><p>1. <strong>The number of layers in the network (Single-layered or multi-layered)</strong></li><li><strong>Direction of signal flow (Feedforward or recurrent)</strong></li><li><strong>Number of nodes in layers: </strong></li><li> number of node in the input layer is equal to the number of features of the input data set. The number of output nodes will depend on possible outcomes i.e. the number of classes in case of supervised learning. But the number of layers in the hidden layer is to be chosen by the user. A larger number of nodes in the hidden layer, higher the performance but too many nodes may result in overfitting as well as increased computational expense.</p><p>4. <strong>Weight of Interconnected Nodes: </strong>Deciding the value of weights attached with each interconnection between each neuron so that a specific learning problem can be solved correctly is quite a difficult problem by itself. Take an example to understand the problem. Take the example of a<strong> Multi-layered Feed-Forward Network, </strong>we have to train an ANN model using some data, so that it can classify a new data set, say<strong> </strong>p_5(3,-2). Say we have deduced that p_1=(5,2)   and  p_2 = (-1,12)   belonging to class C1 while p_3=(3,-5)   and p_4 = (-2,-1)  belonging to class C2. We assume the values of synaptic weights w_0,w_1,w_2 as -2, 1/2 and 1/4 respectively. But we will NOT get these weight values for every learning problem. For solving a learning problem with ANN, we can start with a set of values for synaptic weights and keep changing those in multiple iterations. The stopping criterion may be the <strong>rate of misclassification &lt; 1% or the maximum numbers of iterations should be less than 25(a threshold value).</strong></li></ol> There may be another problem that, the rate of misclassification may not reduce progressively.</p><p>So, we can summarize the learning process in ANN as the combination of – <strong>deciding the number of hidden layers, </strong>the <strong>number of nodes in each of the hidden layers, </strong>the <strong>direction of signal flow, deciding the connection weight.</strong></p><p><strong>Multi-layer feed network </strong>is a commonly used architecture. It has been observed that a neural network with even one hidden layer can be used to reasonably approximate any continuous function. The learning methodology adopted to train a multi-layer feed-forward network is <strong>Backpropagation</strong>. </p><p></p><p><strong><h4>Backpropagation:</h4></strong></p><p>In the above section, we get to know that the most critical activities of training an ANN are to assign the inter-neuron connection weights. In 1986, an efficient way of training an ANN was introduced. In this method, the <strong>difference in output values of the output layer and the expected values, are </strong>propagated<strong> back from the output layer to the </strong>preceding<strong> layers.</strong> Hence, the algorithm implementing this method is known as BACK PROPAGATION<strong> i.e. propagating the errors back to the </strong>preceding<strong> layers.</strong></p><p>The backpropagation algorithm is applicable for multi-layer feed-forward network. It is a supervised learning algorithm which continues adjusting the weights of the connected neurons with an objective to reduce the deviation of the output signal from the target output. This algorithm consists of multiple iterations, <strong>known as epochs.</strong><ul><li>ach epoch consists of two phases:</p><p>◇ <strong>Forward Phase: </strong></li><li>gnal flow from neurons in the input layer to the neurons in the output layer through the hidden layers. The weights of the interconnections and activation functions are used during the flow. In the output layer, the output signals are generated.</p><p>◇ <strong>Backward Phase: </strong></li></ul>Signal is compared with the expected value. The computed errors are propagated backwards from the output to the preceding layer. The error propagated back are used to adjust the interconnection weights between the layers.</p><p></p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104134400/back1.jpg"><img src="images/154-8.png" alt="images/154-8.png" /></a><em><strong>BACKPROPAGATION</strong></em></p><p></p><p>The above diagram depicts a reasonably simplified version of the back propagation algorithm. </p><p>One main part of the algorithm is adjusting the interconnection weights. This is done using a technique termed as <strong>Gradient Descent</strong>. In simple words, the algorithm calculates the partial derivative of the activation function by each interconnection weight to identify the ‘gradient’ or extent of change of the weight required to minimize the cost function. </p><p>In order to understand the back propagation algorithm in detail, let us consider the <strong>Multi-layer Feed Forward Network.</strong> </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104135201/second.jpg"><img src="images/154-9.png" alt="images/154-9.png" /></a></p><p> </p><p><strong>The net signal input to the hidden layer neurons is given by:</strong></p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-845af7f9c8f2c59a2c97503e4aab43a8_l3.svg"><img src="images/154-10.png" alt="images/154-10.png" /></a></p><p>If<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-c60956ced7973c630263bbf2143a0083_l3.svg"><img src="images/154-11.png" alt="images/154-11.png" /></a>is the activation function of the hidden layer, then<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-eed47ca4b879a055fad73abf4434cf66_l3.svg"><img src="images/154-12.png" alt="images/154-12.png" /></a></p><p><strong>The net signal input to the output layer neurons is given by:</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-3cb1ee6b4935cfaaf27ff5d2602ed02b_l3.svg"><img src="images/154-13.png" alt="images/154-13.png" /></a></p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210104141017/back2.jpg"><img src="images/154-14.png" alt="images/154-14.png" /></a><em><strong>BACKPROPAGATION NET</strong></em></p><p></p><p>Note that the signals<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f4e6a8384ba28c9f1ce986fa10f3c037_l3.svg"><img src="images/154-15.png" alt="images/154-15.png" /></a>and<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9b71e2b8700445857fd4cfd08fdad7d1_l3.svg"><img src="images/154-16.png" alt="images/154-16.png" /></a>are assumed to be 1. If<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a7aefe2bc41141f18fef1cf683972284_l3.svg"><img src="images/154-17.png" alt="images/154-17.png" /></a>is the activation function of the hidden layer, then<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-3d4853ae12e1476bbac403b6d4e0bccc_l3.svg"><img src="images/154-18.png" alt="images/154-18.png" /></a></p><p><strong>If is the target of the k-th output neuron, then the cost function defined as the squared error of the output layer is given by:</strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-d5cbd5bca23a3f82108bd073d89c1762_l3.svg"><img src="images/154-19.png" alt="images/154-19.png" /></a></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6a83d2f41f949adefed1bc84f1cd372d_l3.svg"><img src="images/154-20.png" alt="images/154-20.png" /></a></p><p><strong>According to the descent algorithm</strong>, partial derivative of cost function E has to be taken with respect to interconnection weights. Mathematically it can be represented as:</p><p> </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-db033e935850fed747ca80e9150172af_l3.svg"><img src="images/154-21.png" alt="images/154-21.png" /></a></p><p>{Above expression is for the interconnection weights between the <strong>j-th neuron in the hidden layer and the k-th neuron in the output layer</strong>.} <strong>This expression can be reduced to </strong></p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-56518df6b80ab79b48a6937c668d5b04_l3.svg"><img src="images/154-22.png" alt="images/154-22.png" /></a></p><p><strong>where,</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-9be1b18780b03f43f3c3406815c83e13_l3.svg"><img src="images/154-23.png" alt="images/154-23.png" /></a> or  <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-eaa19af7a4f4b20d2ceab8f7fa183a39_l3.svg"><img src="images/154-24.png" alt="images/154-24.png" /></a></p><p><strong>If we assume</strong><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-24ff4d5e2c1339779e8c58a99221f446_l3.svg"><img src="images/154-25.png" alt="images/154-25.png" /></a>as a component of the weight adjustment needed for weight  <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-05d89d9d7e92f63707a37b202f387544_l3.svg"><img src="images/154-26.png" alt="images/154-26.png" /></a>corresponding to the k-th output neuron, then : </p><p><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-5bcb9b302ab25977efd99354a49cdcfe_l3.svg"><img src="images/154-27.png" alt="images/154-27.png" /></a><ul><li> the basis of this, the weights and bias need to be updated as follows: </p><p>◇ <strong>For weights:</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1bc3c047ea8c17c1a4e787738078dd9d_l3.svg"><img src="images/154-28.png" alt="images/154-28.png" /></a><ul><li><strong>Hence,</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-581003387cd4e2637536c2b9b1e3701f_l3.svg"><img src="images/154-29.png" alt="images/154-29.png" /></a><ul><li><strong>For bias:</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-54e1b271335eb99b0d2f88a46abdae56_l3.svg"><img src="images/154-30.png" alt="images/154-30.png" /></a><ul><li><strong>Hence,</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-42b129a298d38c2cd9d8b051339dbb85_l3.svg"><img src="images/154-31.png" alt="images/154-31.png" /></a></p><p></p><p>In the above expressions, alpha is the learning rate of the neural network.<strong> </strong><ul><li>arning rate is a user parameter which decreases or increases the speed with which the interconnection weights of a neural network is to be adjusted. If the learning rate is too high, the adjustment done as a part of the gradient descent process may diverge the data set rather than converging it. On the other hand, if the learning rate is too low, the optimization may consume more time because of the small steps towards the minima. </p><p>{All the above calculations are for the interconnection weight between neurons in the hidden layer and neurons in the output layer}</p><p>Like the above expressions, we can deduce the expressions for “Interconnection weights between the input and hidden layers:</p><p>◇ <strong>For weights:</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-ab0757f66bd2ec96a809e5ae8694ab79_l3.svg"><img src="images/154-32.png" alt="images/154-32.png" /></a><ul><li><strong>Hence,</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-0060b0c40eb21692e5cd6e83303db3fd_l3.svg"><img src="images/154-33.png" alt="images/154-33.png" /></a><ul><li><strong>For bias:</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-1c4ffb3326cfafba69265e65bb1d4f13_l3.svg"><img src="images/154-34.png" alt="images/154-34.png" /></a><ul><li><strong>Hence,</strong></li></ul><a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-7c38abef9476ee3566f8114ea8e955bd_l3.svg"><img src="images/154-35.png" alt="images/154-35.png" /></a></p><p></p><p>So, in this way, we can use the Backpropagation algorithm to solve various Artificial Neural Networks.</p><p></p></div><div class='page'><h1 class='title level-3'>Cross Entropy Classification Functions</h1><br/><p><small>Cross-Entropy Cost Functions used in Classification</small></p><p></p><p><h3>A Brief Idea of Cost Functions</h3></p><p>How does your teacher assess whether you have studied throughout the academic year or not? She takes a test at the end and grades your performance by cross-checking your answers against the desired answers. If you have managed to maintain your accuracy and have shot your scores over a certain benchmark, you have passed. If you haven’t(as unlikely as it is), you need to improve your accuracy and attempt again.  So in crude words, tests are used to analyze how well you have performed in class.</p><p>In machine learning lingo, a ‘<strong>cost function</strong>‘ is used to evaluate the performance of a model. An important question that might arise is, <em><strong>how can I assess how well my model is performing</strong></em>? Just like the teacher assesses your accuracy by verifying your answers against the desired answers, you assess the model’s accuracy by comparing the values predicted by the model with the actual values. The cost function quantifies the difference between the actual value and the predicted value and stores it as a single-valued real number.  The cost function can analogously be called the ‘<strong>loss function</strong>‘ if the error in a single training example only is considered. Note that these are applicable only in supervised machine learning algorithms that leverage optimization techniques. Since the cost function is the measure of how much our predicted values are deviating from the correct labelled values, it can be considered to be an inadequacy metric. Hence, all optimization techniques tend to strive to minimize it. </p><p>In this article, we shall be covering the cost functions predominantly used in classification models only.</p><p></p><p><h2>The Cross-Entropy Cost Function</h2></p><p></p><p><h3>The Idea behind Shannon Entropies</h3></p><p>The Entropy of a random variable<em> X</em> can be measured as the uncertainty in the variables’ possible outcomes. This means the more the certainty/probability, the lesser is the entropy. </p><p>The formula to calculate the entropy can be represented as:</p><p>(1)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-94174d9160750a4c0886ae6a8877f18e_l3.svg"><img src="images/155-1.png" alt="images/155-1.png" /></a></p><p>(2)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-f9dd587dea6aceeffe4e32956d6b645c_l3.svg"><img src="images/155-2.png" alt="images/155-2.png" /></a></p><p>Let us take a simple example.</p><p>You have <strong>3 hampers</strong> and each of them contains <strong>10 candies. </strong></p><p><em><strong>The first hamper has 3 Eclairs and 7 Alpenliebes. </strong></em></p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922170611/Untitleddesign5-300x300.png"><img src="images/155-3.png" alt="images/155-3.png" /></a><em>Red=Eclairs, yellow=Alpenliebe</em></p><p></p><p><em><strong>The second hamper has 5 Eclairs and 5 Alpenliebes.</strong></em></p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922170758/Untitleddesign6-300x300.png"><img src="images/155-4.png" alt="images/155-4.png" /></a></p><p><em><strong>The third hamper has 10 Eclairs and 0 Alpenliebes. </strong></em></p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922171100/hamper3-300x300.png"><img src="images/155-5.png" alt="images/155-5.png" /></a></p><p>Using the above equation, we can calculate the values of the entropies in each of the above cases.</p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922172854/Tablehamper.png"><img src="images/155-6.png" alt="images/155-6.png" /></a></p><p>You can now see that since hamper 2 has the highest degree of uncertainty, its entropy is the highest possible value, i.e 1. Also, since hamper 3 only has one kind of candies, there is 100% certainty that the candy drawn would be an Eclair. Therefore, there is no uncertainty and the entropy is 0. </p><p></p><p><h3>The Cost Function of Cross-Entropy</h3><ul><li>w that you are familiar with entropy, let us delve further into the cost function of cross-entropy.</p><p>Let us take an example of a 3-class classification problem.  The model shall accept an image and distinguish whether the image can be classified as that of an apple’s, an orange’s or a mango’s. After processing, the model would provide an output in the form of a probability distribution. The predicted class would have the highest probability. </p><p>• <strong>Apple = [1,0,0]</strong></li><li><strong>Orange = [0,1,0]</strong></li><li><strong>Mango = [0,0,1]</strong></li></ul></p><p></p><p>This means that if the class correctly predicted by the model is, let’s say, apple. Then the predicted probability distribution of apple should tend towards the maximum probability distribution value, i.e, 1. If that is not the case, the weight of the model needs adjustment. </p><p>Let’s just say that the following logits were the predicted values:</p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922183612/42-300x300.png"><img src="images/155-7.png" alt="images/155-7.png" /></a><em>Logits for apple, orange and mango respectively</em></p><p></p><p>These are the respective logit values for the input image being an apple, an orange and a mango. We can deploy a <strong>Softmax function</strong> to convert these logits into probabilities. The reason why we use softmax is that it is a continuously differentiable function. This makes it possible to calculate the derivative of the cost function for every weight in the neural network. </p><p></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922191109/421-300x300.png"><img src="images/155-8.png" alt="images/155-8.png" /></a><em>Difference between the expected value and predicted value, ie 1 and 0.723= 0.277</em></p><p></p><p>Even though the probability for apple is not exactly 1, it is closer to 1 than all the other options are. </p><p></p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210922193218/mappingfinal-300x300.png"><img src="images/155-9.png" alt="images/155-9.png" /></a></p><p> After subsequent, successive iterative training, the model might improve its output probability considerably and reduce the loss. This is how cross-entropy can reduce the cost function and make the model more accurate. The formula used to predict the cost function is:</p><p>(3)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-190eb1aaaf797ccf4a163fae819561ed_l3.svg"><img src="images/155-10.png" alt="images/155-10.png" /></a></p><p></p><p><h2>Multi-class Classification Cost Functions</h2></p><p>Just like the aforementioned example, multi-class classification is the scenario wherein there are multiple classes, but the input fits in only 1 class. Fruit cannot practically be a mango and an orange both, right? </p><p>  Let the model’s output highlight the probability distribution for ‘<em>c’</em> classes for a fixed input <em>‘d</em>‘.</p><p>(4)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-14258a7573aa9c738fcd59b5aefdc155_l3.svg"><img src="images/155-11.png" alt="images/155-11.png" /></a></p><p>Also, let the actual probability distribution be </p><p>(5)<a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-6a19199d75210cc6f3af531cb2261a11_l3.svg"><img src="images/155-12.png" alt="images/155-12.png" /></a></p><p>Thus, the cross-entropy cost function can be represented as : </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20210923021113/mixedmatrix-300x159.jpg"><img src="images/155-13.png" alt="images/155-13.png" /></a><em>Note that y3=yc for all ‘c’ terms</em></p><p></p><p> <a href="https://www.geeksforgeeks.org/wp-content/ql-cache/quicklatex.com-a6b04b57173f5faa3ffdce419bc1f60d_l3.svg"><img src="images/155-14.png" alt="images/155-14.png" /></a><ul><li>w, if we take the example of the probability distribution from the example on apples, oranges and mangoes and substitute the values in the formula, we get:</p><p>◇ <strong>p(Apple)=[0.723, 0.240, 0.036]</strong></li><li><strong>y(Apple)=[1,0,0]</strong></li></ul></p><p></p><p>Cross-Entropy(y,P) loss = <strong>– (1*log(0.723) + 0*log(0.240)+0*log(0.036)) = 0.14</strong></p><p> </p><p>This is the value of the cross-entropy loss.</p><p></p><p><h2>Categorical Cross-Entropy</h2></p><p>The error in classification for the complete model is given by the mean of cross-entropy for the complete training dataset. This is the categorical cross-entropy. Categorical cross-entropy is used when the actual-value labels are one-hot encoded. This means that only one ‘bit’ of data is true at a time, like [1,0,0], [0,1,0] or [0,0,1]. The categorical cross-entropy can be mathematically represented as:</p><p>                                                    <strong> Categorical Cross-Entropy = (Sum of Cross-Entropy for N data)/N</strong></p><p></p><p><h2>Binary Cross-Entropy Cost Function</h2></p><p>In Binary cross-entropy also, there is only one possible output. This output can have discrete values, either 0 or 1. For example, let an input of a particular fruit’s image be either that of an apple or that of an orange. Now, let us rewrite this sentence: A fruit is either an apple, or it is not an apple. There are only <em><strong>binary, true-false outputs</strong></em><ul><li>ossible. </p><p>Let us assume that the actual output is represented as a variable y</p><p>now, cross-entropy for a particular data ‘d’ can be simplified as </p><p>◇ <em><strong>Cross-entropy(d) = – y*log(p) when y = 1</strong></em></li><li><em><strong>Cross-entropy(d) = – (1-y)*log(1-p) when y = 0</strong></em></li></ul></p><p></p><p>Problem implementation for this method is the same as those of multi-class cost functions. The difference is that only binary classes can be accepted. </p><p></p><p><h2>Sparse Categorical Cross-Entropy</h2></p><p>In sparse categorical cross-entropy, truth labels are labelled with integral values. For example, if a 3-class problem is taken into consideration, the labels would be encoded as [1], [2], [3]. </p><p>Note that binary cross-entropy cost-functions, categorical cross-entropy and sparse categorical cross-entropy are provided with the Keras API. </p><p></p></div><div class='page'><h1 class='title level-3'>Implementation and Visualisation of single perceptron</h1><br/><p><small>Implementation and Visualization of a single perceptron</small></p><p>Neural Networks, a word that fantasizes most of the Machine Learning/ Deep Learning enthusiasts, this field is having many applications in today’s world and isn’t limited to computer science only. Neural Networks are used for image classifications, speech recognitions, object detection and segmentations etc. Neural Networks are having a huge impact in the medical field, automobile etc. </p><p>A neural network is formed of perceptrons. Data is inputted to these perceptrons and they provide an output. This output acts as input to the perceptrons in the next layer until we reach the final layer which provides an output. There can be more than 1 neuron present in the output layer.  To understand a neural network, we must understand how a single perceptron works and how it provides output.</p><p><strong>Implementation of a single perceptron.</strong></p><p><div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400">##Importing Libraries</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><span style="color:#333333;font-weight:400">import</span> matplotlib.pyplot <span style="color:#333333;font-weight:400">as</span> plt<br /><span style="color:#333333;font-weight:400">from</span> <span style="color:#333333;font-weight:400">sklearn.datasets</span> <span style="color:#333333;font-weight:400">import</span> make_blobs       <span style="color:#0088ff;font-weight:400">#make_blobs dataset used</span><br /><span style="color:#333333;font-weight:400">import</span> seaborn <span style="color:#333333;font-weight:400">as</span> sns<br /><span style="color:#0088ff;font-weight:400">##Initialising our X,Y variable</span><br />X,Y = make_blobs(n_samples = <span style="color:#ff0044;font-weight:400">500</span>,centers = <span style="color:#ff0044;font-weight:400">2</span>, n_features = <span style="color:#ff0044;font-weight:400">2</span>,random_state=<span style="color:#ff0044;font-weight:400">10</span>)<br /><span style="color:#0088ff;font-weight:400">## Printing shape of X and Y</span><br /><span style="color:#ff9d00;font-weight:700">print</span>(X.shape,Y.shape)<br />output = (<span style="color:#ff0044;font-weight:400">500</span>,<span style="color:#ff0044;font-weight:400">2</span>) (<span style="color:#ff0044;font-weight:400">500</span>, )<br /><span style="color:#0088ff;font-weight:400">##Visualizing the dataset</span><br />sns.scatterplot(X[:,<span style="color:#ff0044;font-weight:400">0</span>],X[:,<span style="color:#ff0044;font-weight:400">1</span>],c=Y,cmap = plt.cm.Accent)<br /></pre></div><code></code></p><p><code></code> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221103102602/1.jpg"><img src="images/156-1.png" alt="images/156-1.png" /></a></p><p>Scatter Plot of the Dataset </p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">##Defining the sigmoid function</span><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">sigmoid</span>(z):<br />	<span style="color:#ff9d00;font-weight:700">return</span> (<span style="color:#ff0044;font-weight:400">1.0</span>)/(<span style="color:#ff0044;font-weight:400">1</span> + np.exp(-z))<br /><span style="color:#0088ff;font-weight:400">##Defining the predict, loss, update and train functions</span><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">predict</span>(X,weights):<br />    <span style="color:#0088ff;font-weight:400"># X -&gt; m x (n+1) matrix and Weights -&gt; n x 1 vector</span><br />    z=np.dot(X,weights)<br />    predictions = sigmoid(z)<br />    <span style="color:#ff9d00;font-weight:700">return</span> predictions<br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">loss</span>(X,Y,weights):<br />    <span style="color:#0088ff;font-weight:400">#Binary Cross Entropy/Log Loss</span><br />    Y_hat = predict(X,weights)<br />    cost  = np.mean(-Y*np.log(Y_hat) - (<span style="color:#ff0044;font-weight:400">1</span>-Y)*np.log(<span style="color:#ff0044;font-weight:400">1</span>-Y_hat))<br />    <span style="color:#ff9d00;font-weight:700">return</span> cost<br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">update</span>(X,Y,weights,learning_rate):<br />    Y_hat = predict(X,weights)<br />    dw    = np.dot(X.T,Y_hat-Y)<br />    m     = X.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    weights = weights - learning_rate*dw/(<span style="color:#ff9d00;font-weight:700">float</span>(m))<br />    <span style="color:#ff9d00;font-weight:700">return</span> weights<br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">train</span>(X,Y,learning_rate,maxEpochs=<span style="color:#ff0044;font-weight:400">100</span>):<br />    ones  = np.ones((X.shape[<span style="color:#ff0044;font-weight:400">0</span>],<span style="color:#ff0044;font-weight:400">1</span>))<br />    X  = np.hstack((ones,X))<br />    weights = np.zeros(X.shape[<span style="color:#ff0044;font-weight:400">1</span>])<br />    <span style="color:#ff9d00;font-weight:700">for</span> epochs <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(maxEpochs):<br />        weights = update(X,Y,weights,learning_rate)<br />        <span style="color:#ff9d00;font-weight:700">if</span> epochs % <span style="color:#ff0044;font-weight:400">10</span> == <span style="color:#ff0044;font-weight:400">0</span>:<br />            l = loss(X,Y,weights)<br />            <span style="color:#ff9d00;font-weight:700">print</span>(<span style="color:#3ad900;font-weight:400">&quot;Epochs Number %d Loss %.4f&quot;</span>%(epochs,l))<br />    <span style="color:#ff9d00;font-weight:700">return</span> weights<br /><br /><span style="color:#0088ff;font-weight:400">##Running the train function </span><br />weight = train(X,Y,learning_rate=<span style="color:#ff0044;font-weight:400">0.1</span>,maxEpochs=<span style="color:#ff0044;font-weight:400">100</span>)<br /><span style="color:#0088ff;font-weight:400">##Visualisation</span><br />x1 = np.linspace(-<span style="color:#ff0044;font-weight:400">2</span>,<span style="color:#ff0044;font-weight:400">10</span>,<span style="color:#ff0044;font-weight:400">10</span>)<br />x2 = -(weight[<span style="color:#ff0044;font-weight:400">0</span>] + weight[<span style="color:#ff0044;font-weight:400">1</span>]*x1)/weight[<span style="color:#ff0044;font-weight:400">2</span>]<br />plt.plot(x1,x2,color = <span style="color:#3ad900;font-weight:400">&#39;red&#39;</span>)<br />sns.scatterplot(X[:,<span style="color:#ff0044;font-weight:400">0</span>],X[:,<span style="color:#ff0044;font-weight:400">1</span>],c=Y,cmap = plt.cm.Accent)<br /></pre></div></p><p> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/20221103103215/2.jpg"><img src="images/156-2.png" alt="images/156-2.png" /></a>Scatter Plot with the best fit line</p></div><div class='page'><h1 class='title level-1'>Image Processing</h1><br/></div><div class='page'><h1 class='title level-2'>Fundamentals of Image Formation</h1><br/><p><h2>Matrix vs Image and DIY High Res Grayscale</h2></p><p>We all know that a computer only understands numbers. Then a question that pops in our mind is if a computer can’t understand anything beyond numbers, then how it is able to display images.</p><p>How images are represented in a computer:</p><p>In computers images are represented using matrices. Now in python we can define a matrix using arrays. For a 2x2 matrix 2 arrays containing 2 elements can be used similarly any matrix can be formed each array used in the matrix can be considered as a pixel of image.</p><p>Example: </p><p>  </p><p><a href="https://lh3.googleusercontent.com/SgC7h2_AguR8rfg0HNscauD1dOkoLDL2GBpQcRs4is0SeXJKbuvtm1ec-ePZmnov_mjxewVZE1cQZ0SbsiF5DMBxX2VCVL4TUIsH1sl7yIFVQsuHwyLKZkCTYWoz1ZfxDUscA7tpdeoldVzqjFXpZI5yxAm0QnyqCdAS3KkYIIh55kbZqp7DoTJzl6nEjHSKmJfLQKc3xw"><img src="images/158-1.png" alt="images/158-1.png" /></a><h3>  </h3></p><p></p><p></p><p> </p><p><a href="https://lh5.googleusercontent.com/TtqYiM5bN3DXdkpy5dX8t3HPcaQEKpANNnZrgRuhFEkvcL-d-vNUmjJruXgOe3Th7FaArJ11wBZE_GpKvU6rAiWIZtIlB-nXwrzavwCwjq9oEJ8zJ_b-3-1SPt4M0uoelt2FBMZ6braI3a69ZXW0nOLLNZvIpGsBG3faGXQsmk3dgzxx6r6hyJRyDBn9DcgU2gGnPCf2Kw"><img src="images/158-2.png" alt="images/158-2.png" /></a></p><p>The first example shows an array containing only 1 value i.e., 0 hence an image containing only 1 pixel is formed and the colour of the image will be black (Purple here as it’s visualized using matplotlib).</p><p>In the second example 2 arrays are created 1 contains 0 and the other contains 1. Hence 2 pixels can be seen 0 producing black colour and 1 producing white colour.</p><p></p><p> </p><p>We can save this image by using imwrite(). </p><p>After saving the image if we view it in any photo viewer, you’ll notice that it needs to be zoomed in a lot as it is a very small image containing 1 2 pixels only. </p><p> </p><p><strong><span style="text-decoration:underline;">Program to create 8x8 chess board</span></strong></p><p><div class="codebox"><pre>zeros = np.zeros((<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">8</span>), dtype = <span style="color:#ff9d00;font-weight:700">int</span>)<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff9d00;font-weight:700">len</span>(zeros)):    <br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff9d00;font-weight:700">len</span>(zeros[i])):<br />        <span style="color:#ff9d00;font-weight:700">if</span> ((i+j)%<span style="color:#ff0044;font-weight:400">2</span> ==<span style="color:#ff0044;font-weight:400">0</span>): <br />            zeros[i][j] = <span style="color:#ff0044;font-weight:400">1</span>           <br />plt.imshow(zeros)<br />              cv.imwrite(“chess_board.png”,zeros)</pre></div></p><p></p><p> </p><p>To create a high pixel density image</p><p>Images that we usually see have a resolution written with them example 1920x1080, 1280x720 etc what it basically means that this image is having a width of 1920 pixels and a height of 1080 pixels. Now when we create an image manually using NumPy arrays we create each array and the colour it would produce. Doing so for 1920x1080 times is a hectic process so we use nested for loops in-order to make the process easy. </p><p><div class="codebox"><pre>img = []<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1080</span>):<br />    temp = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1920</span>):<br />        temp.append(<span style="color:#ff0044;font-weight:400">0</span>)<br />    img.append(temp)<br />    <br />img = np.array(img) <br /> </pre></div></p><p>In the above code you’ll see that we are appending 0 to temp meaning in the first iteration when i = 0 we’ll produce black colour 1920 times(horizontally) then with the iterations of ‘i&#39; we’ll produce a complete black image having a resolution of 1920x1080</p><p> </p><p>We can save these images using</p><p>cv2.imwrite(“image_name.png”,list) {if you imported cv2 as cv use cv.imwrite)</p><p> </p><p>Creating Shades of Black Colour</p><p>A pixel can take a value between 0-255 0 being the black and 255 being white as we</p><p>Increase the value of 0 by 1 it changes the shade to a lighter version of black. Though it may not be completely visible but it changes and on a significant change we can see it. Hence moving from 0 to255 we tend to move from black to its lighter colours until we reach complete white at 255</p><p> </p><p><strong><span style="text-decoration:underline;">Code</span></strong></p><p><div class="codebox"><pre>lst = []<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>):<br />    temp = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>):<br />        temp.append(i)<br />    lst.append(temp)<br />lst = np.array(lst)<br />cv.imwrite(<span style="color:#3ad900;font-weight:400">&#39;Shades.png&#39;</span>,lst)<br /><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>RGB</h1><br/><p><small>RGB</small></p><p><em><strong><span style="color:#4472c4;">RGB Colour Space</span></strong></em></p><p>So far, we have covered how a computer represents an image, how to create a black and white image(formed on a grey palette) and how to export it. We also learned how to create specific resolution images and how we can create patterns like chess board patterns.</p><p>Now if we can move forward on how to create a coloured image. Colours are created using RGB colour space. RGB stands for Red Green Blue. Using these three colours we can create any colour as most of the colours are formed using composition of these colours. </p><p>To create a RGB pixel we use 3 values instead of 1 value for a pixel </p><p><a href="https://lh4.googleusercontent.com/_dIbjgxe4idIUn_bIuNO_BT1lqa0xWdSADaXsILDatlERTeCi7LBbtFwP3OBnl2841xqQpqdda5xPZwz94-HjxxQ9peF5-jnz3jBN1sWNtG5XngdeZAQKxHjEktSCMOYHdRNAZOEWsoPoY-rroWwIMScM7uMgHDebQOJPdbt-3IgqZllsxxcJoJsxlsTmSHpKrID2UNH3A"><img src="images/159-1.png" alt="images/159-1.png" /></a></p><p>In the above image we create an array which depicts a RGB pixel that is to be shown in the image. The first value can be taken from 0-255 and is for red colour, second for Green and third for Blue.</p><p>We already studied that if pixel is 0 then its black and for 255 it’s white (Grayscale palette) </p><p>Now a common question that will arise in your mind is how to produce white and black colour in the RGB way. To create a completely white image we have to keep each element of array as 255 </p><p><div class="codebox"><pre>plt.imshow([[<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">255</span>]]) //<span style="color:#ff9d00;font-weight:700">for</span> white <br />plt.imshow([[<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>]]) //<span style="color:#ff9d00;font-weight:700">for</span> Black pixel</pre></div></p><p> </p><p>This was all how a RGB pixel is to be represented now we can move towards how to create colours. Like Red, Blue and Green.</p><p>Starting with some basics if we want to create Red colour, we know that a pixel is to be represented using RGB array (R , G , B ) for Red colour we can vary R’s value from 0 to 255 and keep G and B as 0</p><p>Similarly for Green, Red and Blue are to be kept as 0 and same is true for Blue as well</p><p> </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating a complete Red Image</span><br />arr = np.array([[[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]]])<br />plt.imshow(arr)</pre></div></p><p><a href="https://lh3.googleusercontent.com/cBOkC0en7FR0FivdzTwD38zVa_KwsTKbVenoYUz3HGdxr55YwZNSmaaBA4xw-_1HpwvwPpsjVZ1dxQowOVZbC83eNNziBp0-f5MmC1EB3e3LNXS4NXrAkEm68PGzzK2j__XuclPduE-sMlUvYrKkGdQQ0NilPfQnzJV9YTvoNKpUw8TWuZHzAkNFHoIwNbbuK5XgGSBW-Q"><img src="images/159-2.png" alt="images/159-2.png" /></a></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating a Green Image</span><br />arr = np.array([[[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span>  ] , [ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span>  ] , [ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span>  ] , [ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ]]])<br />plt.imshow(arr)</pre></div></p><p><a href="https://lh6.googleusercontent.com/kWR_S9lVD7qh8nnRCgRtHVE2nbbC2kjPSNACTezCK2Tz2cMAQo0zWOIVCyBXD38UejdGJ-i-h-77vXIxAIVM2ofSm1ggN9K8frokvMr3Tec_soQb6YRUXYMvH6_pDkE9bvq6zuo6YAZEDjM4vvhmoxVfIc6wCkgfn_Cgm3ObCG5Euxi1mkp2Ri0rBpZzPVvYlmZt5-sc4w"><img src="images/159-3.png" alt="images/159-3.png" /></a></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating a Blue Image</span><br />arr = np.array([[[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>, <span style="color:#ff0044;font-weight:400">255</span> ]]])<br />plt.imshow(arr)</pre></div></p><p><a href="https://lh3.googleusercontent.com/GrhxQlTHwKxJoQeXgFOP9k3eu-3UVP4RPCXwcfIZLLya7LxOiq4UU8FsqCxeVIGtPdVg2WxXP9fORrfxcqAjXxdETlq9knd6nvMu0plY_lB0_UJdelOQ1dlMoDbFLZ03irlMHM3PlMaVk6P0QRQ94PnNrh2Oz5-goJWGQTToBT2CpyOqSaA0Fr3dJAmI7MYNKa2lS34LZA"><img src="images/159-4.png" alt="images/159-4.png" /></a></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating a REE GREEN BLUE Pattern</span><br />arr = np.array([[[ <span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">0</span> ]],<br />                [[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">255</span> ]]])<br />plt.imshow(arr)</pre></div></p><p><a href="https://lh5.googleusercontent.com/XTqRzBt9QDFXl-8yB6Ltdo4cCHMiA8-izf-DWWzeJuRoKbSH8zsXBKj2_cYu2kmlSkl5TXRfrpGvCpqWLZCZEB8-EJb4looNcDwL5Qz4l7FM9Z67mQ0zDN4yj7IhQ0HjAPyfEGs7ddlryTrthMrHf93ZhAY8IZ_paFS_W4jZUQmWIM0Dmx9UuaAjl-IwM4-ZWQISsxX3Ww"><img src="images/159-5.png" alt="images/159-5.png" /></a></p><p></p></div><div class='page'><h1 class='title level-3'>Transition and Custom Colours</h1><br/><p><small>Transition and Custom Colours</small></p><p>Till now we’ve learned how to create images using grayscale palette and RGB palette. We created complete red, blue and green images and also learned on how to create a pattern of these 3 colours. In this article you’ll learn different shades of colours and how to add transitions of these colours. </p><p>We know that when we want to represent a colour like Red, we have to keep green and blue as 0 and we can change the intensity of Red from 0 to 255. In the first case if we keep Red as 0 it’ll create a black image as all three components will be 0 as we keep on increasing the value of red from 0 to 255, we can see different shades of red, 255 being the brightest.</p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Different Shades of Red</span><br />plt.imshow(np.array([[[ <span style="color:#ff0044;font-weight:400">30</span>  , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">60</span>  , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">90</span>  , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                       [[ <span style="color:#ff0044;font-weight:400">120</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">150</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">180</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                           [[ <span style="color:#ff0044;font-weight:400">210</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] , [ <span style="color:#ff0044;font-weight:400">240</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]]]))</pre></div></p><p><a href="https://lh6.googleusercontent.com/Bbwl7p21zW8m7yKGHOPQjpNPf_4DD_oQeEl4bIPDZ2HVesedu9hnSFNsww38zv3sGSgRmUzn8lD5FI_E4pnWyO0vz0KfYrEyL-TPnak6rwX41QUHVI_wBcCu3a_-X8C1Qb5MAMHcH7i-jjCa4H1IpAGFNRkHj9LM_iDY0afXcwMIzs1vTPxxgYX6s0AsqqxeVuAus0VMZg"><img src="images/160-1.png" alt="images/160-1.png" /></a></p><p>Similarly, we can create images of shades of green and blue simply by just keeping the rest of the two values as zero and changing the value of the required colour. </p><p> </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Merging all the images</span><br />plt.imshow(np.array([[[ <span style="color:#ff0044;font-weight:400">0</span>   , <span style="color:#ff0044;font-weight:400">70</span> , <span style="color:#ff0044;font-weight:400">0</span>  ] , [ <span style="color:#ff0044;font-weight:400">0</span>   ,<span style="color:#ff0044;font-weight:400">150</span>, <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">0</span>   ,<span style="color:#ff0044;font-weight:400">255</span>,  <span style="color:#ff0044;font-weight:400">0</span> ]],<br />          [[ <span style="color:#ff0044;font-weight:400">70</span>  , <span style="color:#ff0044;font-weight:400">0</span>  , <span style="color:#ff0044;font-weight:400">0</span>  ] , [ <span style="color:#ff0044;font-weight:400">150</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> ,  <span style="color:#ff0044;font-weight:400">0</span> ]],<br />          [[ <span style="color:#ff0044;font-weight:400">0</span>   , <span style="color:#ff0044;font-weight:400">0</span>  , <span style="color:#ff0044;font-weight:400">70</span> ] , [ <span style="color:#ff0044;font-weight:400">0</span>   , <span style="color:#ff0044;font-weight:400">0</span> ,<span style="color:#ff0044;font-weight:400">150</span>] ,[ <span style="color:#ff0044;font-weight:400">0</span>   , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">255</span>]]]))</pre></div></p><p><a href="https://lh4.googleusercontent.com/DZCk5l9cghwWSwmuwwl_KQOkDqxgChBXDfINQ5txWNWHkAxhti_f2PjDTarLbww141CuRK8eC5Hi2my0F7FpmHJWJUM5drlEaT-ChuI2Fs8RsfhZ3ppJZJSTPYNTLT0jQJ-RH3ubocSf2Py5Sx1_HUyjrckohI2PqSWJhK1LprXXcO-O6e7IiJFlbqVlKYJXcPIVJlYPuQ"><img src="images/160-2.png" alt="images/160-2.png" /></a></p><p></p><p></p><p> <div class="codebox"><pre><br /><span style="color:#0088ff;font-weight:400"># Creating a transition of the shades of RGB Colours</span><br />img = []<br /><span style="color:#0088ff;font-weight:400"># Red</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>):             <span style="color:#0088ff;font-weight:400"># from Black to Red</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1920</span>):<br />        t.append([i,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>])<br />    img.append(t)<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>,<span style="color:#ff0044;font-weight:400">0</span>,-<span style="color:#ff0044;font-weight:400">1</span>):        <span style="color:#0088ff;font-weight:400"># from Red to Black using range in the opposite direction from 256 it’ll                decrement till it reaches 0</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1920</span>):<br />        t.append([i,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>])<br />    img.append(t)<br />    <br /><span style="color:#0088ff;font-weight:400"># Green</span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>):             <span style="color:#0088ff;font-weight:400"># from Black to Green</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1920</span>):<br />        t.append([<span style="color:#ff0044;font-weight:400">0</span>,i,<span style="color:#ff0044;font-weight:400">0</span>])<br />    img.append(t)<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>,<span style="color:#ff0044;font-weight:400">0</span>,-<span style="color:#ff0044;font-weight:400">1</span>):        <span style="color:#0088ff;font-weight:400"># from Green to Black</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1536</span>):<br />        t.append([<span style="color:#ff0044;font-weight:400">0</span>,i,<span style="color:#ff0044;font-weight:400">0</span>])<br />    img.append(t)<br /><br /> <br /><span style="color:#0088ff;font-weight:400">#Blue    </span><br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>):             <span style="color:#0088ff;font-weight:400"># from Black to Blue</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1536</span>):<br />        t.append([<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,i])<br />    img.append(t)<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">256</span>,<span style="color:#ff0044;font-weight:400">0</span>,-<span style="color:#ff0044;font-weight:400">1</span>):        <span style="color:#0088ff;font-weight:400"># from Blue to Black</span><br />    t = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1536</span>):<br />        t.append([<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,i])<br />    img.append(t)<br />img = np.array(img)<br />plt.imshow(img)</pre></div></p><p><a href="https://lh3.googleusercontent.com/pBSd9lIySj0e2mndJ99Azz0C8-wyBBqWA76Yw_nmtIzuIqMI8byE9Zf_A-MhYo4LhlUZXyaxRqMZF7J-Crtz0ycJaGPTokbi8c4TKyuTG2_hpapmHrxuUaFQn1Xi5VvAl2sx6yyLYkgIIhY5Nc7bmywPSpAhOqt5mExgNrmZ61W8pZRky5IJgateluh68tPOewiPlxzpuA"><img src="images/160-3.png" alt="images/160-3.png" /></a></p><p> </p><p>Now we can come to our last topic that is how can we create custom colours. This can be achieved by simply changing the RGB values different combinations of these values produce different colours.</p><p>We can use a colour RGB selector to check the value of RGB for different colours.</p><p> </p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating Custom Colours</span><br />plt.imshow(np.array([[[ <span style="color:#ff0044;font-weight:400">249</span>  , <span style="color:#ff0044;font-weight:400">220</span> , <span style="color:#ff0044;font-weight:400">104</span> ] , [ <span style="color:#ff0044;font-weight:400">55</span>  , <span style="color:#ff0044;font-weight:400">126</span> , <span style="color:#ff0044;font-weight:400">34</span> ] ,[ <span style="color:#ff0044;font-weight:400">90</span>  , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                                       [[ <span style="color:#ff0044;font-weight:400">139</span>  , <span style="color:#ff0044;font-weight:400">206</span> , <span style="color:#ff0044;font-weight:400">247</span> ] , [ <span style="color:#ff0044;font-weight:400">239</span> , <span style="color:#ff0044;font-weight:400">134</span> , <span style="color:#ff0044;font-weight:400">59</span> ] ,[ <span style="color:#ff0044;font-weight:400">180</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]],<br />                                       [[ <span style="color:#ff0044;font-weight:400">113</span>  , <span style="color:#ff0044;font-weight:400">178</span> , <span style="color:#ff0044;font-weight:400">229</span> ] , [ <span style="color:#ff0044;font-weight:400">240</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ] ,[ <span style="color:#ff0044;font-weight:400">255</span> , <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ]]]))</pre></div></p><p><a href="https://lh5.googleusercontent.com/2MTjFtQVbYJCeEAeGH2I5fqkhqyqPNhyW1X6LzYq12g0IasmWtACkckqAp08EVQgSJNr0cx5KEivCT6LUqF_eb86mAyN5tMfFtGheAqmBFZhtoMUPBnQ-rAs3SbqumJjl2vPogJhravZ5ex9dBS_OSP9VH1GhzZeDguPbSsJVr1ZPLtuXS51FXuqhcK5lZ5Pa1tMGEzlGQ"><img src="images/160-4.png" alt="images/160-4.png" /></a></p><p>We can create dense colour images by choosing the RGB values for that particular colour.</p><p>For Orange RGB = [239 , 134 , 59]</p><p></p><p> </p><p></p></div><div class='page'><h1 class='title level-2'>Image Processing Techniques</h1><br/><p><small>RGB vs BGR</small></p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">RGB vs BGR</span></strong></em></p><p>Till now we know about 2 colour spaces one being RGB and the other being grey space. In this article we will be studying about another colour space known as BGR. We’ve also covered how we can create and save images but we don’t know how to load images that are in our PC. Let’s first start with how to load an image in our jupyter notebook. </p><p>#Load an Image in Jupyter Notebook</p><p>Let’s assume the name of the image that we want to load is transition.jpg, in order to load an image from our PC we’ve to use a function known as imread() which is a part of cv2 library.</p><p></p><p><div class="codebox"><pre>img = cv2.imread(<span style="color:#3ad900;font-weight:400">&#39;Transition.jpg&#39;</span>)<br />plt.imshow(img)<br /></pre></div></p><p></p><p>This code can be used to load an image named Transition.jpg</p><p>If you check the properties of the image saved on your PC you’ll notice that the colour space of the photo is RGB but when you load the photo in the jupyter notebook you’ll notice that the image in your PC isn’t the same as the one that you loaded. </p><p><a href="https://lh6.googleusercontent.com/yUiheuGIRznszM0ChKhXWkwadSRu5mWYdnTZp_WEP4a7-RTbYQrLfMfFJZiByU6Q6WsYQOEqonnVfSRluZFNg_cQWBwBDO69N4UTjQijO7KOzYrMnTV56ha5ghvb4uplYpZqmFQtIYq5htOnzCzPUMw-jALjZR55FEulrA7e9PFkVQBuLXtjCBQXxtaR38OAbfczedgAuQ"><img src="images/161-1.png" alt="images/161-1.png" /></a></p><p>The image RGB is saved in our PC and BGR is loaded in our jupyter notebook. The main difference between these 2 images is the position of colours shown in the images. In the BGR format position of Red and Blue is switched when compared to the RGB format</p><p>We can convert BGR image to RGB image by using</p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># BGR to RGB</span><br />img = cv.cvtColor(img, cv.COLOR_RGB2BGR)<br />plt.imshow(img)<br /><span style="color:#0088ff;font-weight:400"># RGB To BGR</span><br />img = cv.cvtColor(img, cv.COLOR_BGR2RGB)<br />plt.imshow(img)<br /><br /></pre></div></p><p></p><p><small>Frame Extraction and Displaying Images in New Window</small></p><p><em><span style="color:#4472c4;">Frame Extraction</span></em></p><p>Before starting Frame Extraction, we should learn how to crop images. For the same transition image if we check its shape it would be something like this:</p><p><a href="https://lh6.googleusercontent.com/nkQGQ_gk_NDbhuZh5L4-RIhfTFNk_XB-4aeFNLxW-N86jlH9uLXKgxhzb14qss1mpWdoXoAYz21bkKo72fveEBNEYqWTkt-tbJh7glbsF3eeM8NfDfQPxn1Yy5GW7vzS21_oAVH7VgsRPpmU6bhiaAe8TbeSO-srTvJKMrcbTRHcF6l7rG-IQIferTk_4SuUlwv5C3VA2g"><img src="images/161-2.png" alt="images/161-2.png" /></a></p><p>1536 is the number of rows , 1024 the number of columns and three is the channel of colours.</p><p>We can crop an image just by using basic slicing img[ : , : , : ]  this can be used to print the full image. In order to crop the image lets say we only want to print first 500 rows and 700 columns we can slice the image as img[ :500, : 1000 , : ] to plot this cropped image we can use </p><p><strong>plt.imshow(img[ :500, : 1000 , : ])</strong></p><p><a href="https://lh4.googleusercontent.com/LnaWemoxVzPr1VGUIzZCXugLpxDQhf0EANXDlErpoCk02oiH8o33PWaa-gaeLk8iZ8MzvUfISOE7IpDxMClsFSDMmeXfit4hmiUoaPxgQpgI4jajxw5JpjmC62UDaxco3L9UMPRljcjrtGXwxf8Vi9fzE6vQN2Fqp-c81CWFVKqwEryIvgNN42NwSXy85qEocyfPvMtw6g"><img src="images/161-3.png" alt="images/161-3.png" /></a></p><p> </p><p>Now let’s start with frame extraction for frame extraction let’s take the Transition.jpg image</p><p><a href="https://lh6.googleusercontent.com/zw61W__1UcrMO4Q9fQx5uohT2HbcqoT2DBeDEb3mdVXU_W5sRWeaw8EFvxvefiDi9aPXPBB3qnqD7pazdW3Pxsld9NrZ8u0w05qKhFEMD9kL4TOq6Y57-0XcZLYogEvfq0ZM64qYCGtLzVbns6fKpcTJrgUmhBxX-RodW2pfjrzVEMUy6XD1_rTHnoxnmkO7uOniwS76Ew"><img src="images/161-4.png" alt="images/161-4.png" /></a></p><p>Let’s extract the red frame</p><p><strong>Red = img[ : , : , :0]  #0 from the colour channel to extract Red</strong></p><p><strong>Green = img[ : , : , :1] #1 from the colour channel to extract Green</strong></p><p><strong>Blue = img[ : , : , :2] #2 from the colour channel to extract Blue</strong></p><p>plt.imshow can be used to visualize these extracted frames.</p><p></p><p></p><p> </p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">Display Images in new window</span></strong></em></p><p>We have extracted three frames Red, Green and Blue now</p><p><strong>Code to display the frame in a new window:</strong></p><p><strong>cv2.imshow(“Frame1_Red”,Red)</strong></p><p><strong>cv2.waitKey(0) #This can also be used to add delay as well</strong></p><p><strong>cv2.imshow(&quot;Frame2_Green&quot;,Green)</strong></p><p><strong>cv2.waitKey(0)</strong></p><p><strong>cv2.imshow(&quot;Frame3_Blue&quot;,Blue)</strong></p><p><strong>cv2.waitKey(0)</strong></p><p></p><p> </p><p><a href="https://lh6.googleusercontent.com/qT9fns0IN7DV_5rXegzN5euigwI_lR3mHQZ3iPTphGV7SExgmwm-613pD_ZKAQKtF9gtv_BQokfQcI-IT4i2jdik4v7qd7SKDwSp_w5VFhhTJSdHspjchIt8I32PqM--2T6uoNcaAI5fZx4hYrrQ3fySOpbiNHbAnthyHMaHImNoPf175N8l-2pcLbYeax7Mhg0EMvEmvA"><img src="images/161-5.png" alt="images/161-5.png" /></a></p><p>3 frames loaded </p><p></p></div><div class='page'><h1 class='title level-2'>Image Processing On live webcam</h1><br/><p><h2>Working with the Webcam</h2></p><p></p><p><h3>We will use the function VideoCapture() which is a part of cv2 library and is used to capture frames inside the function we will pass the value 0 if we are using inbuilt camera or 1 2 3 depending in which port did you connected your external camera in most cases 1 will work. </h3></p><p><h3>Let’s get started with displaying frames using web cams.</h3></p><p><h3>#Code</h3></p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>) <span style="color:#0088ff;font-weight:400">#0 because I’m using internal camera of my laptop</span><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>: <span style="color:#0088ff;font-weight:400">#We used an infinite loop so that I can display video instead of images in the window</span><br />  _, img = cam.read() <span style="color:#0088ff;font-weight:400">#_ is a boolean variable that returns true if the frame is available and img is an image array vector captured based on the default frames per second defined explicitly or implicitly</span><br />  cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span>,img)<br />  key = cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) <span style="color:#0088ff;font-weight:400">#delay of 1ms</span><br />  <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">27</span>):   <span style="color:#0088ff;font-weight:400">#27 is ASCII for esc</span><br />    cam.release()<br />    <span style="color:#ff9d00;font-weight:700">break</span></pre></div></p><p></p><p><small>Crop and Flip</small></p><p>Cropping a video window is similar to cropping a plotted image, like we used slicing to crop a plotted image we can similarly use slicing to crop a video window. </p><p>crop = img [ : , : , : ]                 #[horizontal, vertical, channel]</p><p>To flip an image what we mean is to flip the image that is shown in the window. To flip an image, we will use a function known as flip() flip takes 2 arguments: 1 the image and second whether to flip the image horizontally or vertically. </p><p>img = cv2.flip(img , 0) # 0 means horizontal flip </p><p>img = cv2.flip(img , 1)      # 1 means vertical flip</p><p> #Code</p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br /><br />    _, img = cam.read()<br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>) <br /><br />    frame = img[ <span style="color:#ff0044;font-weight:400">100</span>:<span style="color:#ff0044;font-weight:400">500</span> , <span style="color:#ff0044;font-weight:400">400</span>:<span style="color:#ff0044;font-weight:400">800</span> , : ]<br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span>,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Cropped&quot;</span>,frame)<br />    <br />    key = cv.waitKey(<span style="color:#ff0044;font-weight:400">20</span>)<br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">27</span>):<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /><br /><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Frame Extraction and HSV</h1><br/><p><small>Frame Extraction and HSV</small></p><p>HSV stands for Hue, Saturation and Value. </p><p>#Code for Frame Extraction</p><p></p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br /><br />    _, img = cam.read()<br />    <br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>) <br />    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)<br />    <br />    <span style="color:#0088ff;font-weight:400">#RGB Extraction</span><br />    r = img[:,:,<span style="color:#ff0044;font-weight:400">0</span>]<br />    g = img[:,:,<span style="color:#ff0044;font-weight:400">1</span>]<br />    b = img[:,:,<span style="color:#ff0044;font-weight:400">2</span>]<br />    <br />    <span style="color:#0088ff;font-weight:400">#HSV Extraction</span><br />    h = hsv[:,:,<span style="color:#ff0044;font-weight:400">0</span>]<br />    s = hsv[:,:,<span style="color:#ff0044;font-weight:400">1</span>]<br />    v = hsv[:,:,<span style="color:#ff0044;font-weight:400">2</span>]<br /><br />    <span style="color:#0088ff;font-weight:400">#RGB Frame Display</span><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span>,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Red&quot;</span>  ,r)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Green&quot;</span>,g)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Blue&quot;</span> ,b)<br />  <br />    <span style="color:#0088ff;font-weight:400">#HSV Frame Display    </span><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;HSV&quot;</span>  ,hsv)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Hue&quot;</span>  ,h)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Saturation&quot;</span>,s)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Value&quot;</span>,v)<br />    <br />    key = cv.waitKey(<span style="color:#ff0044;font-weight:400">20</span>)<br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">27</span>):<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-2'>OpenCV Selfie</h1><br/><p><h2>Selfie with OpenCV</h2></p><p>Before learning how to click a selfie and save it, remember that the ASCII of enter is 13. It is important as we are going to use the enter key to click our photo.</p><p>We can take a selfie using basic if condition:</p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">13</span>):<br />cv.imwrite(“Selfie.png”,img)<br />cam.release()<br />       <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p><p>This piece of code can be used to take a selfie. The image will be saved in your current working directory.</p><p>We can also take a Black and White and HSV image by using:</p><p></p><p><div class="codebox"><pre>gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)<br />hsv   = cv.cvtColor(img, cv.COLOR_RGB2HSV)<br /></pre></div></p><p></p><p>and then cv.write for both gray and hsv.</p><p><strong>Complete Code:</strong></p><p></p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br /><br />    _, img = cam.read()<br />    <br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>) <br />    <br />    gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)<br />    hsv  = cv.cvtColor(img, cv.COLOR_RGB2HSV)<br />   <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span>,img)<br />    <br />    key = cv.waitKey(<span style="color:#ff0044;font-weight:400">20</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">13</span>):<br />        <br />        cv.imwrite(<span style="color:#3ad900;font-weight:400">&#39;Selfie.png&#39;</span>, img)<br />        cv.imwrite(<span style="color:#3ad900;font-weight:400">&#39;Selfie_Gray.png&#39;</span>, gray)<br />        cv.imwrite(<span style="color:#3ad900;font-weight:400">&#39;Selfie_HSV.png&#39;</span>, hsv)<br />        cam.release()<br />        <br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p><p></p><p></p><p><h2>Multiple Selfies with OpenCV</h2></p><p><h3>By multiple selfies we mean that each time we press enter we could click a selfie and won’t release the camera seems pretty easy right, But the main problem here is the name of selfie as each time we press enter we would end up with only one image taken at last as it would overwrite the previous image every time enter is pressed due to naming conflict. So, we have to click a selfie in such a way that whenever we press enter a selfie is clicked and a name is dynamically given to it. So, the next time we press enter another selfie is clicked and saved with a different name.</h3></p><p><h3>To achieve this dynamic naming, we use a variable ‘c’ every time enter is pressed the value of c gets incremented by 1. Therefore, each image will have a different name</h3></p><p><h3>#Code</h3></p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />c = <span style="color:#ff0044;font-weight:400">1</span><br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br /><br />    _, img = cam.read()<br />    <br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>) <br />   <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span>,img)<br />    <br />    key = cv.waitKey(<span style="color:#ff0044;font-weight:400">30</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">13</span>):     <span style="color:#0088ff;font-weight:400"># Click selfie if Enter is pressed</span><br />        cv.imwrite(<span style="color:#3ad900;font-weight:400">&#39;Selfie/Selfie_&#39;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(c) + <span style="color:#3ad900;font-weight:400">&#39;.png&#39;</span>, img) <span style="color:#0088ff;font-weight:400">#Dynaic Name given to Each new selfie</span><br />        c += <span style="color:#ff0044;font-weight:400">1</span><br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (key == <span style="color:#ff0044;font-weight:400">27</span>):  <span style="color:#0088ff;font-weight:400"># Terminate the program if Escape is Pressed</span><br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Image Manipulation</h1><br/></div><div class='page'><h1 class='title level-3'>Shapes</h1><br/><p><small>Drawing Shapes with OpenCV</small></p><p><a href="https://www.geeksforgeeks.org/set-opencv-anaconda-environment/">OpenCV </a>provides many drawing functions to draw geometric shapes and write text on images. Let’s see some of the drawing functions and draw geometric shapes on images using OpenCV.</p><p>Some of the drawing functions are :</p><p><em><strong>cv2.line() :</strong></em><em> Used to draw line on an image. </em></p><p><em><strong>cv2.rectangle() :</strong></em><em> Used to draw rectangle on an image. </em></p><p><em><strong>cv2.circle() :</strong></em><em> Used to draw circle on an image. </em></p><p><em><strong>cv2.putText() :</strong></em><em> Used to write text on image.</em></p><p>To demonstrate the uses of the above-mentioned functions we need an image of size 400 X 400 filled with a solid color (black in this case). Inorder to do this, We can utilize <em><strong>numpy.zeroes</strong></em> function to create the required image. </p><p></p><p><div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># Python3 program to draw solid-colored# image using numpy.zeroes() function</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> npimport cv2  <span style="color:#0088ff;font-weight:400"># Creating a black image with 3 channels# RGB and unsigned int datatype</span><br />img = np.zeros((<span style="color:#ff0044;font-weight:400">400</span>, <span style="color:#ff0044;font-weight:400">400</span>, <span style="color:#ff0044;font-weight:400">3</span>), dtype = <span style="color:#3ad900;font-weight:400">&quot;uint8&quot;</span>)<br />cv2.imshow(<span style="color:#3ad900;font-weight:400">&#39;dark&#39;</span>, img) <br /> <span style="color:#0088ff;font-weight:400"># Allows us to see image# until closed forcefull</span><br />cv2.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)cv2.destroyAllWindows()</pre></div></p><p></p><p></p><p><strong>Output :</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/darkimage400.jpg"><img src="images/170-1.png" alt="images/170-1.png" /></a></p><p>Now, let’s draw some geometric shapes on this solid black image. </p><p></p><p><h4>Draw a line : </h4></p><p><em>cv2.line(imageObjectName, (‘start_coordinates’), (‘end_coordinates’), (‘color_in_bgr’), ‘line_thickness’)</em><ul><li>Python3</li></ul></p><p></p><p> </p><p> </p><p> </p><p></p><p></p><p></p><p></p><p><div class="codebox"><pre># Python3 program to draw line# shape on solid image<br />import numpy as npimport cv2  # Creating a black image with 3 channels# RGB and unsigned int datatype<br />img = np.zeros((400, 400, 3), dtype = &quot;uint8&quot;)  # Creating linecv2.line(img, (20, 160), (100, 160), (0, 0, 255), 10)  <br />cv2.imshow(&#39;dark&#39;, img)  # Allows us to see image# until closed forcefully<br />cv2.waitKey(0)<br />cv2.destroyAllWindows()</pre></div></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>Output :</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/line-2.jpg"><img src="images/170-2.png" alt="images/170-2.png" /></a></p><p></p><p><h4>Draw a rectangle :</h4></p><p><em>cv2.rectangle(imageObjectName, (‘top_left_vertex_coordinates’), (‘lower_right_vertex_coordinates’), (‘stroke_color_in_bgr’), ‘stroke_thickness’)</em><ul><li>Python3</li></ul></p><p></p><p> </p><p> </p><p> </p><p></p><p></p><p></p><p></p><p><div class="codebox"><pre># Python3 program to draw rectangle# shape on solid imageimport numpy as npimport cv2  # Creating a black image with 3# channels RGB and unsigned int datatypeimg = np.zeros((400, 400, 3), dtype = &quot;uint8&quot;)  # Creating rectanglecv2.rectangle(img, (30, 30), (300, 200), (0, 255, 0), 5)  cv2.imshow(&#39;dark&#39;, img)  # Allows us to see image# until closed forcefullycv2.waitKey(0)cv2.destroyAllWindows()</pre></div></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>Output :</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/rectangle-2.jpg"><img src="images/170-3.png" alt="images/170-3.png" /></a></p><p></p><p><h4>Draw a Circle :</h4></p><p><em>cv2.circle(imageObjectName, (‘center_coordinates’), (‘circle_radius’), (‘color_in_bgr’), ‘stroke_thickness’)</em><ul><li>Python3</li></ul></p><p></p><p> </p><p> </p><p> </p><p></p><p></p><p></p><p></p><p><div class="codebox"><pre># Python3 program to draw circle# shape on solid imageimport numpy as npimport cv2  # Creating a black image with 3# channels RGB and unsigned int datatypeimg = np.zeros((400, 400, 3), dtype = &quot;uint8&quot;)  # Creating circlecv2.circle(img, (200, 200), 80, (255, 0, 0), 3)  cv2.imshow(&#39;dark&#39;, img)  # Allows us to see image# until closed forcefullycv2.waitKey(0)cv2.destroyAllWindows()</pre></div></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>Output :</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/circle-7.jpg"><img src="images/170-4.png" alt="images/170-4.png" /></a></p><p></p><p><h4>Writing text :</h4></p><p><em>cv2.putText(imageObjectName, ‘TextContent’, (‘text_starting_point_coordinates’), ‘fontToBeUsed’, ‘font_size’, (‘text_color’, ‘text_thickness’, ‘line_type’)</em><ul><li>Python</li></ul></p><p></p><p> </p><p> </p><p> </p><p></p><p></p><p></p><p></p><p><div class="codebox"><pre># Python3 program to write # text on solid imageimport numpy as npimport cv2  # Creating a black image with 3# channels RGB and unsigned int datatypeimg = np.zeros((400, 400, 3), dtype = &quot;uint8&quot;)  # writing textfont = cv2.FONT_HERSHEY_SIMPLEXcv2.putText(img, &#39;GeeksForGeeks&#39;, (50, 50),            font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)  cv2.imshow(&#39;dark&#39;, img)  # Allows us to see image# until closed forcefullycv2.waitKey(0)cv2.destroyAllWindows()</pre></div></p><p></p><p></p><p></p><p></p><p></p><p></p><p><strong>Output :</strong> </p><p><a href="https://media.geeksforgeeks.org/wp-content/uploads/text.jpg"><img src="images/170-5.png" alt="images/170-5.png" /></a></p><p><strong>Applications of drawing shapes on images : </strong><ul><li>◇ Drawing geometrical shapes can help us highlight the particular portions of an image.</li><li>Geometrical shapes like line can help us point or identify particular regions in image.</li><li>Writing text on certain regions of images can add description to that region.</li></ul></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Edge Detection</h1><br/><p><small>Edge Detection</small></p><p>The objective of the program given is to perform edge detection of images in real-time. In this article, the popular canny edge detection algorithm is used to detect a wide range of edges in images. OpenCV has in-built function cv2.Canny() which takes our input image as first argument and its aperture size(min value and max value) as last two arguments. This is a simple example of how to detect edges in Python. </p><p><strong>Implementation </strong><ul><li>Python</li></ul></p><p></p><p> <div class="codebox"><pre><span style="color:#0088ff;font-weight:400"># OpenCV program to perform Edge detection in real time</span><br /><span style="color:#0088ff;font-weight:400"># import libraries of python OpenCV</span><br /><span style="color:#0088ff;font-weight:400"># where its functionality resides</span><br /><span style="color:#333333;font-weight:400">import</span> cv2<br /> <br /><span style="color:#0088ff;font-weight:400"># np is an alias pointing to numpy library</span><br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br /> <br /><span style="color:#0088ff;font-weight:400"># capture frames from a camera</span><br />cap = cv2.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /> <br /> <br /><span style="color:#0088ff;font-weight:400"># loop runs if capturing has been initialized</span><br /><span style="color:#ff9d00;font-weight:700">while</span>(<span style="color:#ff0044;font-weight:400">1</span>):<br /> <br />    <span style="color:#0088ff;font-weight:400"># reads frames from a camera</span><br />    ret, frame = cap.read()<br /> <br />    <span style="color:#0088ff;font-weight:400"># converting BGR to HSV</span><br />    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)<br />     <br />    <span style="color:#0088ff;font-weight:400"># define range of red color in HSV</span><br />    lower_red = np.array([<span style="color:#ff0044;font-weight:400">30</span>,<span style="color:#ff0044;font-weight:400">150</span>,<span style="color:#ff0044;font-weight:400">50</span>])<br />    upper_red = np.array([<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">255</span>,<span style="color:#ff0044;font-weight:400">180</span>])<br />     <br />    <span style="color:#0088ff;font-weight:400"># create a red HSV colour boundary and</span><br />    <span style="color:#0088ff;font-weight:400"># threshold HSV image</span><br />    mask = cv2.inRange(hsv, lower_red, upper_red)<br /> <br />    <span style="color:#0088ff;font-weight:400"># Bitwise-AND mask and original image</span><br />    res = cv2.bitwise_and(frame,frame, mask= mask)<br /> <br />    <span style="color:#0088ff;font-weight:400"># Display an original image</span><br />    cv2.imshow(<span style="color:#3ad900;font-weight:400">&#39;Original&#39;</span>,frame)<br /> <br />    <span style="color:#0088ff;font-weight:400"># finds edges in the input image and</span><br />    <span style="color:#0088ff;font-weight:400"># marks them in the output map edges</span><br />    edges = cv2.Canny(frame,<span style="color:#ff0044;font-weight:400">100</span>,<span style="color:#ff0044;font-weight:400">200</span>)<br /> <br />    <span style="color:#0088ff;font-weight:400"># Display edges in a frame</span><br />    cv2.imshow(<span style="color:#3ad900;font-weight:400">&#39;Edges&#39;</span>,edges)<br /> <br />    <span style="color:#0088ff;font-weight:400"># Wait for Esc key to stop</span><br />    k = cv2.waitKey(<span style="color:#ff0044;font-weight:400">5</span>) &amp; <span style="color:#ff0044;font-weight:400">0xFF</span><br />    <span style="color:#ff9d00;font-weight:700">if</span> k == <span style="color:#ff0044;font-weight:400">27</span>:<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /> <br /> <br /><span style="color:#0088ff;font-weight:400"># Close the window</span><br />cap.release()<br /> <br /><span style="color:#0088ff;font-weight:400"># De-allocate any associated memory usage</span><br />cv2.destroyAllWindows()</pre></div></p><p> </p><p> </p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>Output:</p><p></p></div><div class='page'><h1 class='title level-3'>Image Blur</h1><br/><p> <div class="codebox"><pre>Image Blur<br /><br />OpenCV-Python <span style="color:#ff9d00;font-weight:700">is</span> a library of Python bindings designed to solve computer vision problems. cv2.blur() method <span style="color:#ff9d00;font-weight:700">is</span> used to blur an image using the normalized box <span style="color:#ff9d00;font-weight:700">filter</span>. The function smooths an image using the kernel which <span style="color:#ff9d00;font-weight:700">is</span> represented <span style="color:#333333;font-weight:400">as</span>:<br /><br /><br />Syntax: cv2.blur(src, ksize[, dst[, anchor[, borderType]]])<br />Parameters:<br />src: It <span style="color:#ff9d00;font-weight:700">is</span> the image whose <span style="color:#ff9d00;font-weight:700">is</span> to be blurred.<br />ksize: A <span style="color:#ff9d00;font-weight:700">tuple</span> representing the blurring kernel size.<br />dst: It <span style="color:#ff9d00;font-weight:700">is</span> the output image of the same size <span style="color:#ff9d00;font-weight:700">and</span> <span style="color:#ff9d00;font-weight:700">type</span> <span style="color:#333333;font-weight:400">as</span> src.<br />anchor: It <span style="color:#ff9d00;font-weight:700">is</span> a variable of <span style="color:#ff9d00;font-weight:700">type</span> integer representing anchor point <span style="color:#ff9d00;font-weight:700">and</span> it’s default value Point <span style="color:#ff9d00;font-weight:700">is</span> (-<span style="color:#ff0044;font-weight:400">1</span>, -<span style="color:#ff0044;font-weight:400">1</span>) which means that the anchor <span style="color:#ff9d00;font-weight:700">is</span> at the kernel center.<br />borderType: It depicts what kind of border to be added. It <span style="color:#ff9d00;font-weight:700">is</span> defined by flags like cv2.BORDER_CONSTANT, cv2.BORDER_REFLECT, etc<br />Return Value: It returns an image.<br /><br />Image used <span style="color:#ff9d00;font-weight:700">for</span> <span style="color:#ff9d00;font-weight:700">all</span> the below examples:<br /><br />Example <span style="color:#0088ff;font-weight:400">#1:</span><br /><br /> <br /><br /> <br /><br /> <br /><br /><span style="color:#0088ff;font-weight:400"># Python program to explain cv2.blur() method </span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing cv2 </span><br /><span style="color:#333333;font-weight:400">import</span> cv2 <br />  <br /><span style="color:#0088ff;font-weight:400"># path </span><br />path = <span style="color:#3ad900;font-weight:400">r&#39;C:\Users\Rajnish\Desktop\geeksforgeeks\geeks.png&#39;</span><br />  <br /><span style="color:#0088ff;font-weight:400"># Reading an image in default mode </span><br />image = cv2.imread(path) <br />  <br /><span style="color:#0088ff;font-weight:400"># Window name in which image is displayed </span><br />window_name = <span style="color:#3ad900;font-weight:400">&#39;Image&#39;</span><br />  <br /><span style="color:#0088ff;font-weight:400"># ksize</span><br />ksize = (<span style="color:#ff0044;font-weight:400">10</span>, <span style="color:#ff0044;font-weight:400">10</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># Using cv2.blur() method </span><br />image = cv2.blur(image, ksize) <br />  <br /><span style="color:#0088ff;font-weight:400"># Displaying the image </span><br />cv2.imshow(window_name, image) <br />Output:<br /><br /><br />Example <span style="color:#0088ff;font-weight:400">#2:</span><br /><br /> <br /><br /> <br /><br /> <br /><br /><span style="color:#0088ff;font-weight:400"># Python program to explain cv2.blur() method </span><br />  <br /><span style="color:#0088ff;font-weight:400"># importing cv2 </span><br /><span style="color:#333333;font-weight:400">import</span> cv2 <br />  <br /><span style="color:#0088ff;font-weight:400"># path </span><br />path = <span style="color:#3ad900;font-weight:400">r&#39;C:\Users\Rajnish\Desktop\geeksforgeeks\geeks.png&#39;</span><br />  <br /><span style="color:#0088ff;font-weight:400"># Reading an image in default mode </span><br />image = cv2.imread(path) <br />  <br /><span style="color:#0088ff;font-weight:400"># Window name in which image is displayed </span><br />window_name = <span style="color:#3ad900;font-weight:400">&#39;Image&#39;</span><br />  <br /><span style="color:#0088ff;font-weight:400"># ksize</span><br />ksize = (<span style="color:#ff0044;font-weight:400">30</span>, <span style="color:#ff0044;font-weight:400">30</span>)<br />  <br /><span style="color:#0088ff;font-weight:400"># Using cv2.blur() method </span><br />image = cv2.blur(image, ksize, cv2.BORDER_DEFAULT) <br />  <br /><span style="color:#0088ff;font-weight:400"># Displaying the image </span><br />cv2.imshow(window_name, image) <br />Output:<br /></pre></div></p><p> </p><p> </p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>Output:</p><p></p></div><div class='page'><h1 class='title level-3'>Edge Detection with Blur</h1><br/><p><em><strong><span style="color:#4472c4;">Edge Detection and Image Blur</span></strong></em></p><p>Till now you have learned about drawing shapes, Edge detection and Image blur. In this article we’re going to combine two of the previously learned techniques i.e., Edge detection and Blur. You would be knowing how to add blur to an image, what is kernel and stuff like that and how do we detect edges how and how we reduce noise using threshold values. Now the main question is why do we perform edge detection and image blur simultaneously. The main reason that we perform a blur before edge detection is that it helps in smoothing the edges. What we mean by saying smoothening is that the image that has been blurred before edge detection gives a better result as the edges are a lot smoother.</p><p><a href="https://lh3.googleusercontent.com/0eBhmR54hvSvKHvEqwAgQJgX1vHZc4UVJdR1KG2lowpIm264aZcHIdGMpe8LkxMrN9qPle2xi7if9MyEM9kIrGs46Qx1KGhbxZ-LtK5VGqRu0ErhcqvnccHN5rUcXYVfeWGVNh1JCwiMEd8JQnsFNxzydUOcaOfibSv4Qlbz2NXpvjg9d6gJesr0h2VJc-JIQp_g-eIlzg"><img src="images/168-1.png" alt="images/168-1.png" /></a></p><p>Blur used before Edge Detection</p><p><a href="https://lh6.googleusercontent.com/yPN90m2bknScX29nzjgL-khCgSrigD2TaCAPTaiymMf-E8fm3taCRSvnbcDzj1Is7FlJcscWusK8lBlyPML3VfE0UfL8s0HD7kXUEuVmcQSXt4mkn9ypTtotidcbFYx5LqIUD2r_3lyQcLCftH47Pg7LGMqVxZajlsIIdA3WAUq_pwRAhNHpNCipQMap2i-vQH7ygRRhqw"><img src="images/168-2.png" alt="images/168-2.png" /></a></p><p>No Blur used before Edge detection</p><p>Now it must be clear to you why we use blur before edge detection. Now let’s code it.</p><p>#Code for blur and edge detection</p><p>This code is very simple if you know how to blur an image and how to perform edge detection. In this code you simply pass the blurred image as input and perform edge detection</p><p><div class="codebox"><pre>Python3<br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br /><br />    _, img = cam.read()<br />    <br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)                <span style="color:#0088ff;font-weight:400"># Original Frame</span><br />    blr = cv.blur(img,(<span style="color:#ff0044;font-weight:400">5</span>,<span style="color:#ff0044;font-weight:400">5</span>))            <span style="color:#0088ff;font-weight:400"># Blur on Original Frame</span><br />    edg = cv.Canny(img, <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">50</span>)        <span style="color:#0088ff;font-weight:400"># Edge Detection on Original Frame</span><br />    fin = cv.Canny(blr, <span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">50</span>)        <span style="color:#0088ff;font-weight:400"># Edge Detection on Blur Frame</span><br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Original&quot;</span>, img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Blur&quot;</span>    , blr)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Edges&quot;</span>   , edg)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Final&quot;</span>   , fin)<br /><br />    <span style="color:#ff9d00;font-weight:700">if</span> (cv.waitKey(<span style="color:#ff0044;font-weight:400">10</span>) == <span style="color:#ff0044;font-weight:400">27</span>):<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Image Scaling</h1><br/><p><small>Image Scaling</small></p><p>Image Scaling basically means changing the size of an image; it includes both Up-Scaling  an image and Down-Scaling  an image. Image scaling has various applications even in data science. It helps in reducing the computation needed while training a CNN model. </p><p></p><p>Up-Scaling  and Down-Scaling  are two basic resizing methods. Up-Scaling  basically means to increase the size of the image. How we can do it is very simple and will cover it shortly.</p><p></p><p>Down-Scaling  on the other hand is the opposite of Up-Scaling  and means reducing the size of an image.</p><p></p><p>We know an image consists of pixels and each image has a size associated with it which basically tells us how many pixels are there in the rows and columns of the image. Example shape of an image is (720,1080) which means there are 720 rows(height) and 1080 columns(width). If we want to reduce an image&#39;s height we have to reduce the number of rows and if we want to reduce the height of an image we have to reduce the number columns. Similarly, we can increase the size of image by increasing the rows and columns of the image .This can be done by indexing img.shape</p><p></p><p>img.shape[0] will give us the rows(height) and img.shape[1] will give us the columns(width).</p><p></p><p>Now in the CV2 library we have a function known as resize which can be used for resizing an image.</p><p></p><p>resize takes 2 arguments 1<sup>st</sup> is the image 2<sup>nd</sup> argument consists of 2 arguments which tell how much we want to resize the image if we divide the rows and columns it means down-scaling and if we multiply it means up-scaling</p><p>#Code for Up-scaling and Down-Scaling </p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />  <br />    _, img = cam.read()<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)                <br />    resized_1 = cv.resize(img , (<span style="color:#ff9d00;font-weight:700">int</span>(img.shape[<span style="color:#ff0044;font-weight:400">1</span>]/<span style="color:#ff0044;font-weight:400">4</span>) ,<span style="color:#ff9d00;font-weight:700">int</span>(img.shape[<span style="color:#ff0044;font-weight:400">0</span>]/<span style="color:#ff0044;font-weight:400">4</span>)))<br />    resized_2 = cv.resize(resized_1, (<span style="color:#ff9d00;font-weight:700">int</span>(resized_1.shape[<span style="color:#ff0044;font-weight:400">1</span>]*<span style="color:#ff0044;font-weight:400">4</span>) ,<span style="color:#ff9d00;font-weight:700">int</span>(resized_1.shape[<span style="color:#ff0044;font-weight:400">0</span>]*<span style="color:#ff0044;font-weight:400">4</span>)))<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Original&quot;</span>, img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Resized-1&quot;</span>, resized_1)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Upscaled&quot;</span>, resized_2)<br /><br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">10</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p><p></p></div><div class='page'><h1 class='title level-2'>DIY Insta Filters</h1><br/></div><div class='page'><h1 class='title level-3'>Brightness Controru</h1><br/><p><small>Brightness Control</small></p><p>Changing the Brightness level is the most basic thing everyone does. In-order to increase the brightness we change the value of each and every pixel, it can be done by either multiplying or adding a value to the pixel&#39;s value. In this article, we will see how we can implement this using OpenCV Python.</p><p></p><p> Before starting with the code let’s discuss some important things. As already discussed we can increase the brightness by multiplying or adding a value to each pixel. But this can lead to a formation of an unnatural tint of blue on the image like the one below:</p><p><a href="https://lh3.googleusercontent.com/LWJNj1D9ed_mzdx7DDEW5kZkFjxPOIju7sU9vXuNEmDb6Q4jWiGR5pJnZYUt1w_Kt4eSxUIpQYrTkyn90FQrYMffDaHqRhJtVIgSgcFxUooTCi6oSJqh8pKgpzOTOLUEitPoN1sy-06dxTHv4SKQcvnKuQkTm8ZWwpe7-1bZ_h7gxp6tFkQVtv3HfGkqH1lmhNtodPnQjw"><img src="images/172-1.png" alt="images/172-1.png" /></a></p><p>This blue tint appears on an image because the pixel values for some colours exceed the 0-255 range and when this happens the computer doesn’t know how to represent these particular out of range values leading to the formation of this blue tint. </p><p>How to avoid it?</p><p>We can avoid it by using simple coding in which any pixel having value less than 0 will be changed to 0 and any value greater than 255 will be changed to 255 therefore every pixel will be in range of 0-255.</p><p></p><p><strong>#Code to increase brightness</strong></p><p></p><p></p><p><div class="codebox"><pre>pixels = <span style="color:#ff9d00;font-weight:700">float</span>(<span style="color:#ff0044;font-weight:400">10</span>)<br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    img_1 = img + pixels<br />    img_1[img_1 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span>     <span style="color:#0088ff;font-weight:400">#For negative values</span><br />    img_1[img_1 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span>   <span style="color:#0088ff;font-weight:400"># For values &gt; 255</span><br />    img_1 = img_1.astype(np.uint8)	<span style="color:#0088ff;font-weight:400">#Keeping the type of image same as og</span><br />    <br />    img_2 = img + (<span style="color:#ff0044;font-weight:400">2</span>*pixels) 	<span style="color:#0088ff;font-weight:400">#2x brighter than img_1</span><br />    img_2[img_2 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span><br />    img_2[img_2 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span><br />    img_2 = img_2.astype(np.uint8)<br />    <br />    img_3 = img + (<span style="color:#ff0044;font-weight:400">3</span>*pixels) 	<span style="color:#0088ff;font-weight:400">#3x than img_1</span><br />    img_3[img_3 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span><br />    img_3[img_3 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span><br />    img_3 = img_3.astype(np.uint8)<br />    <br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Original&quot;</span>,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Filter-1&quot;</span>,img_1)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Filter-2&quot;</span>,img_2)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Filter-3&quot;</span>,img_3)<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br />                <br /></pre></div></p><p></p><p><strong>#Code to reduce brightness</strong></p><p><div class="codebox"><pre><br />Python3pixels = <span style="color:#ff9d00;font-weight:700">float</span>(<span style="color:#ff0044;font-weight:400">10</span>)<br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    img_1 = img - pixels<br />    img_1[img_1 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span><br />    img_1[img_1 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span><br />    img_1 = img_1.astype(np.uint8)<br />    <br />    img_2 = img - (<span style="color:#ff0044;font-weight:400">2</span>*pixels)<br />    img_2[img_2 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span><br />    img_2[img_2 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span><br />    img_2 = img_2.astype(np.uint8)<br />    <br />    img_3 = img - (<span style="color:#ff0044;font-weight:400">3</span>*pixels)<br />    img_3[img_3 &lt;  <span style="color:#ff0044;font-weight:400">0</span> ] = <span style="color:#ff0044;font-weight:400">0</span><br />    img_3[img_3 &gt; <span style="color:#ff0044;font-weight:400">255</span>] = <span style="color:#ff0044;font-weight:400">255</span><br />    img_3 = img_3.astype(np.uint8)<br />    <br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Original&quot;</span>,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Filter-1&quot;</span>,img_1)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Filter-2&quot;</span>,i</pre></div></p></div><div class='page'><h1 class='title level-3'>Warm and Cool</h1><br/><p><small>Warm and Cool(Video)</small></p><p>In this article we’ll cover how we can add warm and cool shades of colour to our video frames. Let’s start with cool shade. A cool shade is basically a tint of blue colour applied to our original frame. Whereas a warm shade is basically a tint of yellow colour applied to our original frame. </p><p>This would have made it clear what it means by warm and cool colours. Now how we can apply them to our frames. We basically create a background of blue colour and then merge it with our original image which will add an effect to our image. Similarly for a warm effect we have to create a yellow background and then merge it.</p><p>You might think how to merge the images now, CV2 got you covered. CV2 library contains a function known as addWeighted() which is used to merge 2 images. This function calculates the weighted sum of two arrays.</p><p></p><p></p><p><strong>dst = src1*alpha + src2*beta + gamma</strong></p><p><strong>gamma is a scalar added to each sum</strong></p><p>cv2.addWeighted takes 5 parameters as input </p><p><strong>cv2.addWeighted(src1,alpha,src2,beta,gamma)</strong></p><p>The values of alpha and beta tells us about which image will be more reflective in the merged image is alpha is greater than beta image from source 1 will be dominant </p><p>Note alpha + beta = 1</p><p><strong>#Code for adding blue and yellow background or warmer and cooler tone to th</strong></p><p><strong></strong><div class="codebox"><pre><span style="color:#0088ff;font-weight:400">#Creating a yellow background</span><br />yellow = [<span style="color:#ff0044;font-weight:400">108</span>,<span style="color:#ff0044;font-weight:400">222</span>,<span style="color:#ff0044;font-weight:400">249</span>] <span style="color:#0088ff;font-weight:400">#Colour shade for Yellow</span><br /><br />yellow_background = []<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">720</span>):<br />    temp = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1280</span>):<br />        temp.append(yellow)<br />    yellow_background.append(temp)<br />    <br />yellow_background = np.array(background).astype(np.uint8)<br /><br /><br /><span style="color:#0088ff;font-weight:400">#Creating a blue background</span><br />blue = [<span style="color:#ff0044;font-weight:400">247</span>,<span style="color:#ff0044;font-weight:400">206</span>,<span style="color:#ff0044;font-weight:400">139</span>] <span style="color:#0088ff;font-weight:400">#Colour shade for blue</span><br /><br />blue_background = []<br /><span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">720</span>):<br />    temp = []<br />    <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(<span style="color:#ff0044;font-weight:400">1280</span>):<br />        temp.append(blue)<br />    blue_background.append(temp)<br />    <br />blue_background = np.array(blue_background).astype(np.uint8)<br /><br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img, <span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    img = np.array(img).astype(np.uint8)<br />    <br /><br />    <span style="color:#0088ff;font-weight:400">#Merged yellow and blue background using addWeighted function with alpha = .90 and beta = .10 and gamma = 0</span><br />    merged_yellow = cv.addWeighted(img, <span style="color:#ff0044;font-weight:400">.90</span>, yellow_background, <span style="color:#ff0044;font-weight:400">.10</span>, <span style="color:#ff0044;font-weight:400">0</span>)<br />    merged_blue = cv.addWeighted(img, <span style="color:#ff0044;font-weight:400">.90</span>, blue_background, <span style="color:#ff0044;font-weight:400">.10</span>, <span style="color:#ff0044;font-weight:400">0</span>)<br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Original&quot;</span>,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Yellow&quot;</span>  ,merged_yellow)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Blue&quot;</span>    ,merged_blue)<br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p><p></p><p><h2>Warm and Cool(image)</h2></p><p> Application of shades of images to different images there is a difference in videos and images. </p><p> It is because the video frames are captured by our web cam or external cam and the resolution remains the same as written in our code. </p><p> But when it comes to images there can be a difference in the resolution, size and other aspects of different images as they can be captured using different devices. Example let’s say an image is of 1280x720 pixels and we want to add a cool tone to the image so we have to add a background of blue having size of 1280x720 for another image having 3120x1280 resolution we have to add a background image of 3120x1280. Hence for different images we have to add backgrounds of different sizes.</p><p> </p><p>To overcome this problem, we will define a function that will create a background of the same size as of the image.</p><p></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">add_tone</span>(img_path, color, a, b):<br />    background = []<br />    img = cv.imread(img_path)<br />    cols = img.shape[<span style="color:#ff0044;font-weight:400">1</span>]<br />    rows = img.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(rows):<br />        temp = []<br />        <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(cols):<br />            temp.append(color)<br />        background.append(temp)</pre></div></p><p></p><p>In the above code a function add_tone <strong><span style="color:#ff9d00;">is</span></strong> created which dynamically sets the size of image as size of the background</p><p></p><p><strong>#Code</strong></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">add_tone</span>(img_path, color, a, b):<br />    background = []<br />    img = cv.imread(img_path)<br />    cols = img.shape[<span style="color:#ff0044;font-weight:400">1</span>]<br />    rows = img.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    <span style="color:#ff9d00;font-weight:700">for</span> i <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(rows):<br />        temp = []<br />        <span style="color:#ff9d00;font-weight:700">for</span> j <span style="color:#ff9d00;font-weight:700">in</span> <span style="color:#ff9d00;font-weight:700">range</span>(cols):<br />            temp.append(color)<br />        background.append(temp)<br />    background = np.array(background).astype(np.uint8)<br />    final = cv.addWeighted(img, a , background, b , <span style="color:#ff0044;font-weight:400">0</span>)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Original&#39;</span>,img)<br />    cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Processed&#39;</span>,final)<br />    cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)<br /></pre></div></p><p><strong>#Example on how to add filters to an image [80,20,200] denotes the color of background/filter</strong></p><p><strong>add_tone(&#39;img_3.png&#39;, [80,20,200], .5, .5)</strong></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p></div><div class='page'><h1 class='title level-3'>Merging two Images</h1><br/><p><small>Merging two Images</small></p><p>Merging two images is a similar concept like adding a filter to an image. When we add a filter and that filter is just a background of colors that we make. Now merging two images is a concept in which we merge two images, for example a filter of transition of colors and a photo on which this transition is applied. We will merge them by defining a merge function in which sources of both images will be passed along with the alpha and beta value.</p><p></p><p><strong>#Code</strong></p><p><div class="codebox"><pre><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">merge</span>(foreground_path, background_path, a, b):<br />    <br />    background = []<br /><br />    img        = cv.imread(foreground_path)<br />    background = cv.imread(background_path)<br />        <br />    background = cv.resize(background, (img.shape[<span style="color:#ff0044;font-weight:400">1</span>], img.shape[<span style="color:#ff0044;font-weight:400">0</span>]))<br /><br />    final = cv.addWeighted(img, a, background, b , <span style="color:#ff0044;font-weight:400">0</span>)<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Original&#39;</span>,img)<br />    cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Processed&#39;</span>,final)<br />    cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />	merge(<span style="color:#3ad900;font-weight:400">&#39;img_4.png&#39;</span>,<span style="color:#3ad900;font-weight:400">&#39;b4.jpeg&#39;</span>, <span style="color:#ff0044;font-weight:400">.5</span>,<span style="color:#ff0044;font-weight:400">.6</span>)</pre></div><code></code></p><p><code></code><a href="https://lh4.googleusercontent.com/xm0CkNXvzZvIaJ5fnGslk2dbtTxGGR9pAlKduF8m41tRbwWGAjEPfeYjAr3eoRSsmW3hteoKHFyy6AqHUpH3rSvpD5n0DO-cb3aasHI7TiojYHAKbR9r-J3lXKzFYGthROi_GlXX3GFZxOU-DFM1Ftm41ydpXkOiqrOAlBpAFmPkqOoXavi2QEQWnHDPqNfJ52fhdeKdfg"><img src="images/174-1.png" alt="images/174-1.png" /></a></p><p><strong>b4.jpeg</strong></p><p><a href="https://lh4.googleusercontent.com/jsTSOV48hJddRmCjq6YrDZy0fRvqgjyoWgqD8sdiOVNTdIJfsGr_1mYvXNCHgcQcZYM4iG4XmuMWHrVhpJltHyh-ED1wmPMd_vc-vjfV5yQ1cMKJdrR22Ltph0jjsxmiqjrfpMxnROMj8vHvGmn1uVrtRDLRDLEEx7zGn4ghyVic-HNXKQRV6l8AmHMCkhQPpnMhqfAS_A"><img src="images/174-2.png" alt="images/174-2.png" /></a></p><p><strong>img4.jpeg</strong></p><p> </p><p> </p><p><strong>After Merging</strong></p><p><a href="https://lh5.googleusercontent.com/-QRQ4x1Q8iAWHvWvhdrXx6vHCYYzBmOrUxyKnX6I-SvzR9_8zxlcv1GKE0MQVSxGLgtBVuCIjbMdW5dUtO2CjizG3X8NZE53Iom3FKQ8SMPoafQzOJOT0F_wuWivXr23GTONKw3Fb1o4zU62LBUft9x9EFLkgRpwQQsAk7LI-3Z1GZLeWrqVHnJ9tGIXvR1Q2X-egIibsg"><img src="images/174-3.png" alt="images/174-3.png" /></a></p><p></p><p> </p><p><strong>Difference between 2 images:</strong></p><p><a href="https://lh6.googleusercontent.com/6AIoxlRWkrf492byi8VX3KzUVReXb1wjZJW0MpOfV4crx-wEKqCa63VCs3iUEnhpQzv-OHm6XZVdGThPZCluh9eiu9QS-lzK2t9jp5B_Uv8qlRM2KTpQpNzpI5cACrqklLy-vf1OdI9bmWIu22eInuP4txvK_QZa5FcxxoKN9q5PMJEsfhLmAjG1zhMxS4BVm33Bp9NiHg"><img src="images/174-4.png" alt="images/174-4.png" /></a></p><p></p></div><div class='page'><h1 class='title level-2'>Masking</h1><br/><p><small>Thresholding on Grayscale</small></p><p><h3>Thresholding is a technique in OpenCV, which is the assignment of pixel values in relation to the threshold value provided. In thresholding, each pixel value is compared with the threshold value. If the pixel value is smaller than the threshold, it is set to 0, otherwise, it is set to a maximum value (generally 255). Thresholding is a very popular segmentation technique, used for separating an object considered as a foreground from its background. A threshold is a value which has two regions on its either side i.e. below the threshold or above the threshold.</h3></p><p><h3>Initially we’ll start thresholding on a grayscale frame. To convert our BGR frame to a grayscale frame we use: </h3></p><p></p><p><strong><h3>cv2.cvtColor(img,cv2.COLOR_BGR2Gray)</h3></strong></p><p></p><p></p><p><h3>In-order to see the changes in the frame we will display all the frames simultaneously and to do that we will keep the frame size as 640,360 this will help us in observing multiple frames together. As we have to make changes to multiple frames we will copy the attributes of our original frame and manipulate it and display it in the other frames. To copy we will use .copy() function. If we don’t use the .copy() function the changes made in the 2</h3><sup><span style="color:#a5a5a5;">nd</span></sup><h3> frame will also be depicted in the original frame and we won’t be able to observe the changes. How we use .copy() function</h3></p><p><strong><h3>new_frame = original_frame.copy()  </h3></strong></p><p><h3>Using this code attributes of the original frame will be copied to the new frame and any change made in the new_frame will be limited and shown in it only.</h3></p><p><h3>#Code for thresholding on Grayscale</h3></p><p><div class="codebox"><pre>cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    _ , img = cam.read()<br />    img = cv.resize(img , (<span style="color:#ff9d00;font-weight:700">int</span>(<span style="color:#ff0044;font-weight:400">1280</span>/<span style="color:#ff0044;font-weight:400">2</span>), <span style="color:#ff9d00;font-weight:700">int</span>(<span style="color:#ff0044;font-weight:400">720</span>/<span style="color:#ff0044;font-weight:400">2</span>)))<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br /><br />    gray = cv.cvtColor(img , cv.COLOR_BGR2GRAY)<br /><br />    gray_thr_1 = gray.copy()<br />    gray_thr_1[gray_thr_1 &gt; <span style="color:#ff0044;font-weight:400">200</span>] = <span style="color:#ff0044;font-weight:400">30</span>        <span style="color:#0088ff;font-weight:400"># Black Background Threshold</span><br />    gray_thr_2 = gray.copy()<br />    gray_thr_2[gray_thr_2 &gt; <span style="color:#ff0044;font-weight:400">200</span>] = <span style="color:#ff0044;font-weight:400">100</span>       <span style="color:#0088ff;font-weight:400"># White Background Threshold</span><br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Original&#39;</span>  ,img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Gray&#39;</span>      ,gray)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Gray_Thr1&#39;</span> ,gray_thr_1)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Gray_Thr2&#39;</span> ,gray_thr_2)  <br />	<span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />    	cam.release()<br />		<span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div>		</p><p>		<strong><h3>Sample Output displaying 4 frames:</h3></strong></p><p><a href="https://lh4.googleusercontent.com/iAwnNouTVpB8FsxHFvBCXi7_ok0gwbLQhHH4ThrFaTQo2mS6mYV0deFYjuMQtB-VBTkc48WwprkdpqaKEylHk6dTT58mUZ4I2fo5Y9Yciz67gpiROsBI7IQw_5SyTMz1xSX0AQ9Cg7bNaEnBsKEbI4E8FBnz4Asrd3JaRyGm-_KM79rk1FDZygjqutje50fGWHvyjRhMLQ"><img src="images/175-1.png" alt="images/175-1.png" /></a></p><p></p><p></p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">Colour Masking a Video</span></strong></em></p><p>Masking is a common technique to extract a particular region or particular colors from a frame. In order to perform color masking we provide a range of RGB values, this range specifies the range of pixel values which will be masked.  Before masking a frame, we use <strong>cv2.blur</strong>, this function is used to smoothen the image. Smoothing the image helps in creating a better quality of picture as it helps in reducing the noise. Till now we know how to manually use thresholding on a frame, in that type of thresholding all the pixels are checked according to the thresholding condition and the value of the pixel is changed. In this article we will do thresholding using cv2.inRange() function.</p><p></p><p></p><p></p><p><strong>inRange(mask,lower,upper)</strong><ul><li>unction takes 3 parameters as input. </p><p>• mask: It is basically providing the source of frame/video we didn’t directly use img because mask is a smoothened form of video frame.</li><li>lower: this provides the lower bound of pixel values that is to be masked.</li><li>upper: this provides the upper bound of pixel values that is to be masked.</li></ul></p><p></p><p>#Code for masking a video</p><p><div class="codebox"><pre>camera = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br />lower = np.array([<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">0</span>]) <br />upper = np.array([<span style="color:#ff0044;font-weight:400">60</span>,<span style="color:#ff0044;font-weight:400">60</span>,<span style="color:#ff0044;font-weight:400">60</span>])<br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:    <br />    _ , img = camera.read()<br />    mask = cv.blur(img, (<span style="color:#ff0044;font-weight:400">4</span>,<span style="color:#ff0044;font-weight:400">4</span>)) <span style="color:#0088ff;font-weight:400">#smoothened image kernel size =4x4</span><br />    mask = cv.inRange(mask, lower, upper)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame&quot;</span> , img)<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Mask&quot;</span>  , mask)<br />    <span style="color:#ff9d00;font-weight:700">if</span> (cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>):<br />        camera.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div><code></code></p><p><code></code></p><p><code></code> </p><p></p><p> </p><p><strong>input:</strong></p><p><a href="https://lh6.googleusercontent.com/fyyuBbzecQMnGrjLNcv7Z9MzTEpPv6iw0G3aRLmwCKg_BVGaCvfvttzQMG1RSrMWVIu6nNw9GUfDuvBnFrVqYPn68cYyt6tZlX5JHQ7pp2pGdLwDsHyTQeCr-sMJhVEi8emwZw322L0KRajsefaTeoZvH08mNTSA2wBeIwbD2BNhIJVhUR8fo6_0NkoGhjIMrdyletcFkA"><img src="images/175-2.png" alt="images/175-2.png" /></a></p><p><strong>Output: </strong></p><p><a href="https://lh6.googleusercontent.com/MSnQcwl35icXPMhh7kNHLfJu8PpOuk_WT56T9Q1G0R_skNO3b91IjoK4e58sf7npTbwjy-R3CWfNp54uq-EBJJ61ymZd7eqejEyjQoPtovLvm4y2bFirSkPH1iN7YClPIvv_xbWB9BGTzXmSNZfz6AoBIT0ZIUha25X-HPEuBcO9GPqWdOwgSddJZH7fSotOryNiVW-Nrw"><img src="images/175-3.png" alt="images/175-3.png" /></a></p><p>In this code we masked the black color giving the range from 0,0,0 to 60,60,60. All the colors that are having pixel value in this range are turned white hence masked and outside this range are turned black. Hence the black color of the video is masked.</p><p></p><p></p><p></p><p> </p><p><em><strong><span style="color:#4472c4;text-decoration:underline;">Colour Masking an Image</span></strong></em></p><p>The concept of masking remains the same in this case we just provide an image as input and get a masked image as output. We use cv2.imread(source) to provide the image</p><p>#Code for masking an image</p><p></p><p><div class="codebox"><pre>lower = np.array([<span style="color:#ff0044;font-weight:400">0</span>,  <span style="color:#ff0044;font-weight:400">0</span> , <span style="color:#ff0044;font-weight:400">0</span> ])<br />upper = np.array([<span style="color:#ff0044;font-weight:400">50</span> ,  <span style="color:#ff0044;font-weight:400">50</span> , <span style="color:#ff0044;font-weight:400">50</span>])<br />img = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;img_5.png&#39;</span>)<br /><br />mask = cv.blur(img, (<span style="color:#ff0044;font-weight:400">8</span>,<span style="color:#ff0044;font-weight:400">8</span>))<br />mask = cv.inRange(mask, lower, upper)<br /><br />cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Frame-1&quot;</span> , img)<br />cv.imshow(<span style="color:#3ad900;font-weight:400">&quot;Mask-1&quot;</span>  , mask)<br /><br />cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Adding Logo on live video</h1><br/><p><h2>Adding Logo on Live Video</h2></p><p></p><p>In this article, we are going to see how to add a logo on images using OpenCV in Python.</p><p>Logos are generally used by artists to protect the copyright of the image. Using logos, we can ensure that the owner of the image is the person who imprinted the logo on the image.  </p><p>Let’s understand this with the help of an example, what do we mean by adding a logo on an image:</p><p><a href="https://lh5.googleusercontent.com/FB80LoxH2odOMtpqeacQOfpg6l6RMRc2gRNXzFBmVD0UPU0Wiz62KNnnN0-tuOtILqKcYnYgcWytM9AISQ5eUq2vdsRJh51S1qAPoa2E_Mpy9qYSgxsyf6zBL-07SU0dz-Mhfpd74aa6Yz6q0lYKHQXqrv1p6n54G0kCrI5JICxeaU84P8qoTgW8762iPmtgB_9oJrbHrQ"><img src="images/176-1.png" alt="images/176-1.png" /></a>	</p><p>Adding a logo at top right of image.</p><p>Before adding a logo at any position, we need to know the position coordinates where we want to add the logo. Let’s start with adding the logo at top right of the frame. </p><p><em><strong><span style="text-decoration:underline;">Finding the position where the logo should be placed.</span></strong></em></p><p>The first thing that we need to do is know about the shape of the logo that we want to add. Let’s assume that the shape of the image is (720,1280,3) and that of the logo is (200,200,3). To add the logo at top right of the frame we need to crop that particular area and then add the logo there to crop the area we can use slicing. Can be done in code as follows:</p><p><strong>img[ : , :] = logo</strong></p><p>We’ve to slice the top right portion of the frame where we need to add the logo. For top right corner we need to slice 200 pixels (width) and 200 pixels (height). </p><p>Now height wise we need to slice 200 pixels it can be done as img[0:200,:] or img[50:250, : ]</p><p>Similarly, width wise we need to slice 200 pixels and it can also be done as img[ : , 1080:1280] or </p><p><strong>img[ : , 1000:1200]</strong></p><p>Combining both height and width gives us img[50:250 , 1000:1200] = logo </p><p>Using this small code will add logo at the cropped area in the live video feed.</p><p>To add a more perfect fit for the logo we can reduce the size of the logo and add it to the frame this can be done by using<strong> logo = cv.resize(logo , (50,50))</strong></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;logo.png&#39;</span>)<br />logo = cv.resize(logo, (<span style="color:#ff0044;font-weight:400">50</span>,<span style="color:#ff0044;font-weight:400">50</span>))<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br /><br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    img[ <span style="color:#ff0044;font-weight:400">5</span> : <span style="color:#ff0044;font-weight:400">55</span> , <span style="color:#ff0044;font-weight:400">1225</span> : <span style="color:#ff0044;font-weight:400">1275</span> ] = logo <span style="color:#0088ff;font-weight:400">#for logo.shape = (50,50,3)</span><br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img)<br />     <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Analysing Aspect Ratio and Fiting a Logo</h1><br/><p><small>Analysing Aspect Ratio and Fitting a Logo</small></p><p>Aspect Ratio is a term that everyone has heard and is so common when buying TVs, monitors etc. But what does this term actually mean?  Aspect Ratio uses a proportional relationship between an image’s width and height, it basically describes/tells us about the image’s shape. We know a square has same/equal width and height or we can say a square is having an aspect ratio of 1:1</p><p>Now the question is why we need to learn about Aspect Ratio when we know how to add a logo using basic indexing though it requires some calculations but indexing is an easy method which we can use to add logo to an image. Let’s assume that we are using the same indexing method for many video frames. If these video frames are having different shapes then the logo will never be at the exact top right position as we had calculated it for different shapes. </p><p>To overcome this problem and to place the logo at a certain position irrespective of the video frames shape , we will calculate 4 points that will help us in locating the position of the logo.</p><p>Calculation of 4 points:</p><p><strong>ht = img.shape[0] #height of image</strong></p><p><strong>wt = img.shape[1] # width of image</strong></p><p>To place the logo at top right:</p><p></p><p><strong>  margin_top  = int(ht/100)             </strong><em><strong># 1% from the top of the frame</strong></em></p><p><strong>    logo_height = int((ht/100)*7)         </strong><em><strong># 7% logos height</strong></em></p><p><strong>    margin_left = int((wt/100)*95.5)      </strong><em><strong># 95.5% from logos left side to frames left side</strong></em></p><p><strong>    logo_width  = int((wt/100)*4)         </strong><em><strong># 4% logos width</strong></em></p><p></p><p> </p><p>To place the logo at Top Left</p><p><strong>    margin_top  = int(ht/100)             </strong><em><strong># 1%</strong></em></p><p><strong>    logo_height = int((ht/100)*7)         </strong><em><strong># 7%</strong></em></p><p><strong>    margin_left = int((wt/100)*.5)        </strong><em><strong># .5%</strong></em></p><p><strong>    logo_width  = int((wt/100)*4)         </strong><em><strong># 4%</strong></em></p><p> </p><p>To place the logo at Bottom Left</p><p><strong>    margin_top  = int((ht/100)*92)        </strong><em><strong># 92%</strong></em></p><p><strong>    logo_height = int((ht/100)*7)         </strong><em><strong># 7%</strong></em></p><p><strong>    margin_left = int((wt/100)*.5)        </strong><em><strong># .5%</strong></em></p><p><strong>    logo_width  = int((wt/100)*4)         </strong><em><strong># 4%</strong></em></p><p> </p><p>To place the logo at Bottom right</p><p><strong>    margin_top  = int((ht/100)*92)        </strong><em><strong># 92%</strong></em></p><p><strong>    logo_height = int((ht/100)*7)         </strong><em><strong># 7%</strong></em></p><p><strong>    margin_left = int((wt/100)*.5)        </strong><em><strong># .5%</strong></em></p><p><strong>    logo_width  = int((wt/100)*4)         </strong><em><strong># 4%</strong></em></p><p>All of these codes can be used to locate the position but to crop the frame and place our logo there we will slice the frame but this time will provide these margins and logos height and width:</p><p><strong>img[ margin_top : logo_width + margin_top , margin_left : margin_left + logo_width ] = logo</strong></p><p><span style="text-decoration:underline;">#Final Merge of 4 logos Code</span></p><p> </p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;download.png&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br /><br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    ht = img.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    wt = img.shape[<span style="color:#ff0044;font-weight:400">1</span>]<br />    <br /><span style="color:#0088ff;font-weight:400">#    Top Right</span><br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>(ht/<span style="color:#ff0044;font-weight:400">100</span>)             <span style="color:#0088ff;font-weight:400"># 1%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">95.5</span>)      <span style="color:#0088ff;font-weight:400"># 95.5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    logo = cv.resize(logo, (logo_width, logo_width))<br />    img[ margin_top : logo_width + margin_top , margin_left : margin_left + logo_width ] = logo<br />    <br /><span style="color:#0088ff;font-weight:400">#   Top Left</span><br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>(ht/<span style="color:#ff0044;font-weight:400">100</span>)             <span style="color:#0088ff;font-weight:400"># 1%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">.5</span>)        <span style="color:#0088ff;font-weight:400"># .5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    logo = cv.resize(logo, (logo_width, logo_width))<br />    img[ margin_top : logo_width + margin_top , margin_left : margin_left + logo_width ] = logo<br />    <br /><span style="color:#0088ff;font-weight:400">#   Bottom Left</span><br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">92</span>)        <span style="color:#0088ff;font-weight:400"># 92%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">.5</span>)        <span style="color:#0088ff;font-weight:400"># .5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    logo = cv.resize(logo, (logo_width, logo_width))<br />    img[ margin_top : logo_width + margin_top , margin_left : margin_left + logo_width ] = logo<br /><br /><span style="color:#0088ff;font-weight:400">#   Bottom Right</span><br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">92</span>)        <span style="color:#0088ff;font-weight:400"># 92%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">.5</span>)        <span style="color:#0088ff;font-weight:400"># .5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    logo = cv.resize(logo, (logo_width, logo_width))<br />    img[ margin_top : logo_width + margin_top , margin_left : margin_left + logo_width ] = logo<br />    <br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img)<br />     <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Final Fit of Logo</h1><br/><p><small>Final Fit of a Logo</small></p><p>Till now we know how to add a Logo at any position despite the shape of the frame. </p><p>In this article we’ll learn what will happen to the logo if we change the size of the same frame.</p><p>By changing the size of the frame what we mean is that after pressing a certain key the size of the frame will increase or decrease.</p><p></p><p>If the width of the frame is decreased the logo adjusts itself automatically as the logos position is adjusted according to the shape of the frame of the video. But as we go on decreasing the size of the frame the quality of the logo gets adjusted according to the size of the logo as more and more size is reduced it starts to get blurry after a certain point. Now when we start to increase the size of the frame again the logo gets back to its normal shape but the quality of the logo remains the same i.e., blurry. </p><p><a href="https://lh5.googleusercontent.com/rUwt_6z-dA2iBwXg1HT5EISwpVcUMUd__v4j785WQEvqmrIvjFHw6mBLpOGYLqWP9O-mRv85jWy1NM1zayXlEtwgcJWOIQVgxk4LOuA493IhybpcKERJYGuFNgqbN0p3cQ34u5rdO-A1m5V4UwyLOSx5h9wUmA3uLF2jX5cN9JU5kttTsaz95D3i861_7I8Z7_UFCJnw2Q"><img src="images/178-1.png" alt="images/178-1.png" /></a></p><p>Original Frame</p><p><a href="https://lh6.googleusercontent.com/WWqVsuhE9DfvHhkPt9vfuoX_ClySRA7hRpIdWDQj1fxWvp__migc_ldG70kBYSsaA2rbe-IQwwfYOseh9c_0-VsgNnB7H9TSgGLzVTx1hd9vWm3MqO_IxdMb3EHlR1tva5HU4Hmt_N6J5ZRMIDR4eXEX8cFDAC-H_kyADlHt-EUPGhPyoR7SebQlkRRJZPU74LIX2NSjGw"><img src="images/178-2.png" alt="images/178-2.png" /></a></p><p>Reduced Frame</p><p><a href="https://lh3.googleusercontent.com/6Kc7G2huYwk4Gir99WkU8vJQd7NOXxBN3Eai2ngoMthbRADLXQ6sd9T89NkPaxiHnhzZ6QSW6idLiUZQVP-gqHoI-dQl5ntLpARp9UbvACtTWQvcRggyPenUveGuxiFBqec6OKl31NCeWVRw3WX_jTz_pvupvpAvMEwNZg6c6I4yyofuZv5caVP7GHkXTCygdjrTuraGQg"><img src="images/178-3.png" alt="images/178-3.png" /></a></p><p>Frame back to normal shape(720,1080)</p><p>These images would give you the idea of the problem. See the quality of the logo gets deteriorated after we decrease and increase the frame again. </p><p>To avoid this problem we use a scaling_factor this scaling factor is used to increase and decrease the size of the frame. This can be done by using a value of scaling factor and then using <strong><span style="text-decoration:underline;">cv2.resize(img,(wt*scaling_factor,ht*scaling_factor)</span></strong></p><p>#Code</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;download.png&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;download.png&#39;</span>)<br />    _, img = cam.read()<br /><br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />        <br />    img = cv.resize(img, (<span style="color:#ff9d00;font-weight:700">int</span>(img.shape[<span style="color:#ff0044;font-weight:400">1</span>] * scaling_factor), <span style="color:#ff9d00;font-weight:700">int</span>(img.shape[<span style="color:#ff0044;font-weight:400">0</span>] * scaling_factor)))<br />    <br />    <br />    ht = img.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    wt = img.shape[<span style="color:#ff0044;font-weight:400">1</span>]<br />    <br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>(ht/<span style="color:#ff0044;font-weight:400">100</span>)             <span style="color:#0088ff;font-weight:400"># 1%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    <br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">95.5</span>)      <span style="color:#0088ff;font-weight:400"># 95.5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    <br />    side = <span style="color:#ff9d00;font-weight:700">min</span>(logo_width,logo_height)<br />    <br />    logo = cv.resize(logo, (side, side))<br />    <br />    img[ margin_top : side + margin_top , margin_left : margin_left + side] = logo<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img)<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> (cv.waitkey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">115</span>):<br />	r -= <span style="color:#ff0044;font-weight:400">10</span><br />    <span style="color:#ff9d00;font-weight:700">elif</span> (cv.waitkey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">119</span>):<br />	r += <span style="color:#ff0044;font-weight:400">10</span><br /><br />     <span style="color:#ff9d00;font-weight:700">elif</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Transparency</h1><br/><p><small>Transparency</small></p><p>Transparency / Transparent Logo is Logo that doesn’t hide the background behind it. We can add transparency to our logo by simply passing it through the addWeighted function changing the values of alpha and beta will help us mix the logo more with the background.</p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /> <br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br />logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;download.png&#39;</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    logo = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;download.png&#39;</span>)<br />    _, img = cam.read()<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    <br />    ht = img.shape[<span style="color:#ff0044;font-weight:400">0</span>]<br />    wt = img.shape[<span style="color:#ff0044;font-weight:400">1</span>]<br />    <br />    margin_top  = <span style="color:#ff9d00;font-weight:700">int</span>(ht/<span style="color:#ff0044;font-weight:400">100</span>)             <span style="color:#0088ff;font-weight:400"># 1%</span><br />    logo_height = <span style="color:#ff9d00;font-weight:700">int</span>((ht/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">7</span>)         <span style="color:#0088ff;font-weight:400"># 7%</span><br />    <br />    margin_left = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">95.5</span>)      <span style="color:#0088ff;font-weight:400"># 95.5%</span><br />    logo_width  = <span style="color:#ff9d00;font-weight:700">int</span>((wt/<span style="color:#ff0044;font-weight:400">100</span>)*<span style="color:#ff0044;font-weight:400">4</span>)         <span style="color:#0088ff;font-weight:400"># 4%</span><br />    <br />    side = <span style="color:#ff9d00;font-weight:700">min</span>(logo_width,logo_height)<br />    <br />    bg   = img[ margin_top : side + margin_top , margin_left : margin_left + side ].copy()<br />    logo = cv.resize(logo, (side, side))<br />    <br />    final_logo = cv.addWeighted(bg, <span style="color:#ff0044;font-weight:400">.3</span>, logo, <span style="color:#ff0044;font-weight:400">.7</span>, <span style="color:#ff0044;font-weight:400">0</span>) <span style="color:#0088ff;font-weight:400">#Transparency </span><br />    <br />    img[ margin_top : side + margin_top , margin_left : margin_left + side ] = final_logo<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img )<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;BG&#39;</span>     , bg  )<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-2'>Face Detection and Manipulation</h1><br/><p><h2>Face Detection on Live Webcam</h2></p><p>Object Detection is a computer technology related to computer vision, image processing and deep learning that deals with detecting instances of objects in images and videos. We will do object detection in this article using something known as Haar cascades.</p><p></p><p><strong>What are Haar Cascades? </strong><ul><li>ar Cascade classifiers are an effective way for object detection. This method was proposed by Paul Viola and Michael Jones in their paper Rapid Object Detection using a Boosted Cascade of Simple Features .Haar Cascade is a machine learning-based approach where a lot of positive and negative images are used to train the classifier. </p><p></p><p>• Positive images – These images contain the images which we want our classifier to identify.</li><li>Negative Images – Images of everything else, which do not contain the object we want to detect.</li></ul></p><p></p><p>The HaarCascade file should be downloaded so that it can be used in our code.</p><p>#Code</p><p></p><p><div class="codebox"><pre>classifier = cv.CascadeClassifier(<span style="color:#3ad900;font-weight:400">&#39;haarcascade_frontalface_default.xml&#39;</span>)<br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">try</span>:<br />        faces = classifier.detectMultiScale(img, <span style="color:#ff0044;font-weight:400">1.1</span>, <span style="color:#ff0044;font-weight:400">5</span>) <span style="color:#0088ff;font-weight:400">#(source,scaling_factor,min_neighbours)</span><br />        <span style="color:#ff9d00;font-weight:700">for</span> (x,y,w,h) <span style="color:#ff9d00;font-weight:700">in</span> faces:<br />            cv.rectangle(img, (x,y),(x+w,y+h) , (<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">180</span>,<span style="color:#ff0044;font-weight:400">0</span>), <span style="color:#ff0044;font-weight:400">2</span>) <span style="color:#0088ff;font-weight:400">#(source,coordinates,colour,thickness) rectangle</span><br />    <span style="color:#ff9d00;font-weight:700">except</span>:<br />        <span style="color:#ff9d00;font-weight:700">pass</span><br />    <br />    <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img )<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p><p></p><p>Output:</p><p><a href="https://lh6.googleusercontent.com/Mom58FeZR4XM5zRlT72gI-4hdczfdkHa6-2lHUjGSO9bLD-6sKboYCdlac10XsQux76ThqsAQgaLmXZvEjYgPcV8DRdDJeQcbStaBGuqfHroZv_Y1WIRptOBtLmGL3xSx4n6WRvchng2bAp-E72IMuzkIGD2mPoAzXWRpWN-1JpLs9HV1skEiyqgfbM3GHy2yfuImfQC1Q"><img src="images/180-1.png" alt="images/180-1.png" /></a></p><p></p><p>(Sample image)</p></div><div class='page'><h1 class='title level-3'>Face Crop and Blur</h1><br/><p>	<em><strong><span style="color:#4472c4;text-decoration:underline;">Cropping a Face</span></strong></em></p><p>When a face gets detected we draw a rectangle around it now when more than 1 faces are present in the frame there arises a problem that which frame is to be cropped and which isn’t to be cropped to avoid this problem we choose a face that is having the maximum coordinate values. To find the face having maximum coordinate values we use:</p><p><div class="codebox"><pre><br />    <span style="color:#ff9d00;font-weight:700">for</span> f <span style="color:#ff9d00;font-weight:700">in</span> faces:                             <span style="color:#0088ff;font-weight:400"># Going through Each Face Detected</span><br />        <span style="color:#ff9d00;font-weight:700">if</span> f[-<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#ff9d00;font-weight:700">max</span>(faces[:,-<span style="color:#ff0044;font-weight:400">1</span>]):           <span style="color:#0088ff;font-weight:400"># Finding the Face with Maximum Area</span><br />            <span style="color:#ff9d00;font-weight:700">break</span><br />            <br /></pre></div></p><p>            </p><p>             coming to the final code which we use to detect a face and crop the face on a video frame:</p><p><div class="codebox"><pre><br />classifier = cv.CascadeClassifier(<span style="color:#3ad900;font-weight:400">&#39;haarcascade_frontalface_default.xml&#39;</span>)<br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    faces = classifier.detectMultiScale(img, <span style="color:#ff0044;font-weight:400">1.1</span>, <span style="color:#ff0044;font-weight:400">5</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">for</span> f <span style="color:#ff9d00;font-weight:700">in</span> faces:                             <span style="color:#0088ff;font-weight:400"># Going through Each Face Detected</span><br />        <span style="color:#ff9d00;font-weight:700">if</span> f[-<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#ff9d00;font-weight:700">max</span>(faces[:,-<span style="color:#ff0044;font-weight:400">1</span>]):           <span style="color:#0088ff;font-weight:400"># Finding the Face with Maximum Area</span><br />            <span style="color:#ff9d00;font-weight:700">break</span> <br /><br />    <span style="color:#ff9d00;font-weight:700">if</span> (<span style="color:#ff9d00;font-weight:700">len</span>(faces) &gt;= <span style="color:#ff0044;font-weight:400">1</span>):                       <span style="color:#0088ff;font-weight:400"># Drawing Rectange on the Face</span><br />        x = f[<span style="color:#ff0044;font-weight:400">0</span>] <br />        y = f[<span style="color:#ff0044;font-weight:400">1</span>] <br />        w = f[<span style="color:#ff0044;font-weight:400">2</span>]<br />        h = f[<span style="color:#ff0044;font-weight:400">3</span>]<br /><br />        cv.rectangle(img, (x,y),(x+w,y+h) , (<span style="color:#ff0044;font-weight:400">0</span>,<span style="color:#ff0044;font-weight:400">180</span>,<span style="color:#ff0044;font-weight:400">0</span>), <span style="color:#ff0044;font-weight:400">2</span>)   <br />        face = img[y:y+h, x:x+w]<br />        <br />        face = cv.resize(face, (<span style="color:#ff0044;font-weight:400">256</span>,<span style="color:#ff0044;font-weight:400">256</span>))<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img )<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Face&#39;</span>   , face)<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /> </pre></div></p><p><em><strong><span style="color:#4472c4;">Face Blur</span></strong></em></p><p>Face Blur or Blurring a Face requires face detection first and after detection of face we should also be able to find the right face from the frame that needs to be blurred (Method used in Face cropping).</p><p>After we have worked on both of these concepts face blur is an easy job. We just have to use cv2.blur on the face extracted from the video frame</p><p>#Code for face Blur</p><p></p><p><div class="codebox"><pre>classifier = cv.CascadeClassifier(<span style="color:#3ad900;font-weight:400">&#39;haarcascade_frontalface_default.xml&#39;</span>)<br /><br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    faces = classifier.detectMultiScale(img, <span style="color:#ff0044;font-weight:400">1.1</span>, <span style="color:#ff0044;font-weight:400">5</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">for</span> f <span style="color:#ff9d00;font-weight:700">in</span> faces:<br />        <span style="color:#ff9d00;font-weight:700">if</span> f[-<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#ff9d00;font-weight:700">max</span>(faces[:,-<span style="color:#ff0044;font-weight:400">1</span>]):<br />            <span style="color:#ff9d00;font-weight:700">break</span><br /><br />    <span style="color:#ff9d00;font-weight:700">if</span> (<span style="color:#ff9d00;font-weight:700">len</span>(faces) &gt;= <span style="color:#ff0044;font-weight:400">1</span>):<br />        x = f[<span style="color:#ff0044;font-weight:400">0</span>] <br />        y = f[<span style="color:#ff0044;font-weight:400">1</span>] <br />        w = f[<span style="color:#ff0044;font-weight:400">2</span>]<br />        h = f[<span style="color:#ff0044;font-weight:400">3</span>]<br /><br />        face = img[y:y+h, x:x+w]    <span style="color:#0088ff;font-weight:400">#Getting the Face Area from Video Feed</span><br />        face = cv.blur(face, (<span style="color:#ff0044;font-weight:400">32</span>,<span style="color:#ff0044;font-weight:400">32</span>))    <span style="color:#0088ff;font-weight:400"># Applying Blur on the Face</span><br />        img[y:y+h, x:x+w] = face         <span style="color:#0088ff;font-weight:400"># Apply Blured Face on Video Feed</span><br />        <br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img )<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Face&#39;</span>   , face)<br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div></p></div><div class='page'><h1 class='title level-3'>Circle and Face Extraction</h1><br/><p><small>Circle and Face Extraction</small></p><p><h3>Just like we create a rectangle around the face of a person we can create a circle around a person’s face. To achieve this, we have to just define 2 coordinate points for the circle:</h3></p><p><strong><h3>circle_x = x + int(w/2)</h3></strong></p><p><strong><h3>circle_y = y + int(h/2)</h3></strong></p><p><h3>These 2 coordinates will be used to draw a circle and now we just have to use cv2.circle inorder to draw a circle</h3></p><p><h3>#Code</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br />classifier = cv.CascadeClassifier(<span style="color:#3ad900;font-weight:400">&#39;haarcascade_frontalface_default.xml&#39;</span>)<br />cam = cv.VideoCapture(<span style="color:#ff0044;font-weight:400">0</span>)<br /><br /><span style="color:#ff9d00;font-weight:700">while</span> <span style="color:#ff0044;font-weight:400">True</span>:<br />    <br />    _, img = cam.read()	<br />    img = cv.flip(img,<span style="color:#ff0044;font-weight:400">1</span>)<br />    <br />    faces = classifier.detectMultiScale(img, <span style="color:#ff0044;font-weight:400">1.1</span>, <span style="color:#ff0044;font-weight:400">5</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">for</span> f <span style="color:#ff9d00;font-weight:700">in</span> faces:<br />        <span style="color:#ff9d00;font-weight:700">if</span> f[-<span style="color:#ff0044;font-weight:400">1</span>] == <span style="color:#ff9d00;font-weight:700">max</span>(faces[:,-<span style="color:#ff0044;font-weight:400">1</span>]):<br />            <span style="color:#ff9d00;font-weight:700">break</span><br /><br />    x = f[<span style="color:#ff0044;font-weight:400">0</span>] <br />    y = f[<span style="color:#ff0044;font-weight:400">1</span>] <br />    w = f[<span style="color:#ff0044;font-weight:400">2</span>]<br />    h = f[<span style="color:#ff0044;font-weight:400">3</span>]<br />    <br />    circle_x = x + <span style="color:#ff9d00;font-weight:700">int</span>(w/<span style="color:#ff0044;font-weight:400">2</span>)<br />    circle_y = y + <span style="color:#ff9d00;font-weight:700">int</span>(h/<span style="color:#ff0044;font-weight:400">2</span>)<br />    <br />    cv.circle(img, (circle_x, circle_y), <span style="color:#ff9d00;font-weight:700">int</span>(w/<span style="color:#ff0044;font-weight:400">1.7</span>), (<span style="color:#ff0044;font-weight:400">110</span>,<span style="color:#ff0044;font-weight:400">180</span>,<span style="color:#ff0044;font-weight:400">68</span>),<span style="color:#ff0044;font-weight:400">1</span>)<br /><br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Frame&#39;</span>  , img )<br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">1</span>) == <span style="color:#ff0044;font-weight:400">27</span>:<br />        cam.release()<br />        <span style="color:#ff9d00;font-weight:700">break</span><br /></pre></div> <h3></h3></p><p><h3></h3><strong><h3>cv.circle(img, (circle_x, circle_y), int(w/1.7), (110,180,68),-1) </h3></strong></p><p><strong><h3>If we use -1 as thickness the circle will fill itself with the colour.</h3></strong></p><p><em><strong><h3>Extracting Faces from an Image</h3></strong></em></p><p><h3>We can extract multiple faces from an image and save them in a separate folder all of this can be done using OpenCV. We know that multiple faces can get detected from an image and some of them might not be right so we also have to create a mechanism in which only when we press enter an image will get saved. We also need to provide dynamic naming so that images won’t get overridden.</h3></p><p><h3>#Code</h3></p><p></p><p><div class="codebox"><pre><span style="color:#333333;font-weight:400">import</span> os<br /><span style="color:#333333;font-weight:400">import</span> cv2 <span style="color:#333333;font-weight:400">as</span> cv<br /><span style="color:#333333;font-weight:400">import</span> numpy <span style="color:#333333;font-weight:400">as</span> np<br /><br /><br />img = cv.imread(<span style="color:#3ad900;font-weight:400">&#39;group.png&#39;</span>)<br /><br />classifier = cv.CascadeClassifier(<span style="color:#3ad900;font-weight:400">&#39;haarcascade_frontalface_default.xml&#39;</span>)<br />faces = classifier.detectMultiScale(img, <span style="color:#ff0044;font-weight:400">1.1</span>, <span style="color:#ff0044;font-weight:400">5</span>)<br /><br /><br /><span style="color:#ff9d00;font-weight:700">def</span> <span style="color:#333333;font-weight:400">save</span>(frame, folder_name): <br />    name_img = <span style="color:#ff9d00;font-weight:700">len</span>(os.listdir(folder_name)) + <span style="color:#ff0044;font-weight:400">1</span><br />    name_img = folder_name + <span style="color:#3ad900;font-weight:400">&quot;/IMG_&quot;</span> + <span style="color:#ff9d00;font-weight:700">str</span>(name_img)+<span style="color:#3ad900;font-weight:400">&#39;.png&#39;</span><span style="color:#0088ff;font-weight:400">#Dynamic Naming</span><br />    cv.imwrite(name_img, frame) <span style="color:#0088ff;font-weight:400">#Saving</span><br />    <span style="color:#ff9d00;font-weight:700">print</span>(name_img ,<span style="color:#3ad900;font-weight:400">&#39;is exported&#39;</span>)<br /><br /><br /><span style="color:#ff9d00;font-weight:700">for</span> (x,y,w,h) <span style="color:#ff9d00;font-weight:700">in</span> faces:<br /><br />    face = img[y:y+h, x:x+w]<br />    cv.imshow(<span style="color:#3ad900;font-weight:400">&#39;Face&#39;</span>   , face)<br />    <br />    <br />    <span style="color:#ff9d00;font-weight:700">if</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>) == <span style="color:#ff0044;font-weight:400">13</span>:         <span style="color:#0088ff;font-weight:400"># Save the Image | 13  = Enter Key</span><br />        save(face, <span style="color:#3ad900;font-weight:400">&#39;People&#39;</span>)<br />    <br />    <span style="color:#ff9d00;font-weight:700">elif</span> cv.waitKey(<span style="color:#ff0044;font-weight:400">0</span>) == <span style="color:#ff0044;font-weight:400">127</span>:      <span style="color:#0088ff;font-weight:400"># Skip the Image | 127 = Delete Key</span><br />        <span style="color:#ff9d00;font-weight:700">pass</span><br /><br /></pre></div></p></div>
</body>
</html>
